<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.24" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.94" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Gathering LXC and Docker containers metricsDocker","image":["https://docker.com/app/uploads/2013/08/jerome_docker_in_docker_squ.jpg"],"datePublished":"2013-10-09T00:00:00.000Z","dateModified":null,"author":[{"@type":"Person","name":"Jérôme Petazzoni","url":"https://docker.com/author/jerome/"}]}</script><meta property="og:url" content="https://chanhi2000.github.io/bookshelf/docker.com/gathering-lxc-docker-containers-metrics.html"><meta property="og:site_name" content="📚Bookshelf"><meta property="og:title" content="Gathering LXC and Docker containers metricsDocker"><meta property="og:description" content="Article(s) > Gathering LXC and Docker containers metricsDocker"><meta property="og:type" content="article"><meta property="og:image" content="https://docker.com/app/uploads/2013/08/jerome_docker_in_docker_squ.jpg"><meta property="og:locale" content="en-US"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image:src" content="https://docker.com/app/uploads/2013/08/jerome_docker_in_docker_squ.jpg"><meta name="twitter:image:alt" content="Gathering LXC and Docker containers metricsDocker"><meta property="article:author" content="Jérôme Petazzoni"><meta property="article:tag" content="docker"><meta property="article:tag" content="devops"><meta property="article:tag" content="docker.com"><meta property="article:tag" content="blog"><meta property="article:published_time" content="2013-10-09T00:00:00.000Z"><link rel="icon" href="/bookshelf/assets/icon/favicon.svg"><title>Gathering LXC and Docker containers metricsDocker | 📚Bookshelf</title><meta name="description" content="Article(s) > Gathering LXC and Docker containers metricsDocker">
    <link rel="preload" href="/bookshelf/assets/style-DmRYlEXZ.css" as="style"><link rel="stylesheet" href="/bookshelf/assets/style-DmRYlEXZ.css">
    
    
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><a class="route-link vp-brand" href="/bookshelf/" aria-label="Take me home"><img class="vp-nav-logo" src="/bookshelf/assets/icon/favicon.svg" alt><!----><span class="vp-site-name hide-in-pad">📚Bookshelf</span></a><!--]--></div><div class="vp-navbar-center"><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/bookshelf/news.html" aria-label><!--[--><i class="vp-icon fas fa-rss" sizing="height"></i><!--]--><!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label><!--[--><i class="vp-icon fas fa-keyboard" sizing="height"></i><!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/hackingwithswift.com/" aria-label="hackingwithswift.com"><!--[--><img class="vp-icon" src="https://hackingwithswift.com/favicon.svg" alt aria-hidden no-view sizing="both"><!--]-->hackingwithswift.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/fcc/" aria-label="freecodecamp.org"><!--[--><img class="vp-icon" src="https://cdn.freecodecamp.org/universal/favicons/favicon.ico" alt aria-hidden no-view sizing="both"><!--]-->freecodecamp.org<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/kodeco.com/" aria-label="kodeco.com"><!--[--><img class="vp-icon" src="https://kodeco.com/favicon.ico" alt aria-hidden no-view sizing="both"><!--]-->kodeco.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/blog.kotzilla.io/" aria-label="blog.kotzilla.io"><!--[--><img class="vp-icon" src="https://blog.kotzilla.io/hubfs/favicon.png" alt aria-hidden no-view sizing="both"><!--]-->blog.kotzilla.io<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/kt.academy/" aria-label="kt.academy"><!--[--><img class="vp-icon" src="https://kt.academy/logo.png" alt aria-hidden no-view sizing="both"><!--]-->kt.academy<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/droidcon.com/" aria-label="droidcon.com"><!--[--><img class="vp-icon" src="https://droidcon.com/wp-content/uploads/2021/07/favicon-300x300.png" alt aria-hidden no-view sizing="both"><!--]-->droidcon.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/outcomeschool.com/" aria-label="outcomeschool.com"><!--[--><img class="vp-icon" src="https://outcomeschool.com/static/favicons/apple-touch-icon.png" alt aria-hidden no-view sizing="both"><!--]-->outcomeschool.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/frontendmasters.com/" aria-label="frontendmasters.com"><!--[--><img class="vp-icon" src="https://frontendmasters.com/favicon.ico" alt aria-hidden no-view sizing="both"><!--]-->frontendmasters.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/css-tricks.com/" aria-label="css-tricks.com"><!--[--><img class="vp-icon" src="https://css-tricks.com/favicon.svg" alt aria-hidden no-view sizing="both"><!--]-->css-tricks.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/smashingmagazine.com/" aria-label="smashingmagazine.com"><!--[--><img class="vp-icon" src="https://smashingmagazine.com/images/favicon/favicon.svg" alt aria-hidden no-view sizing="both"><!--]-->smashingmagazine.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/blog.logrocket.com/" aria-label="blog.logrocket.com"><!--[--><img class="vp-icon" src="/bookshelf/assets/image/blog.logrocket.com/favicon.png" alt aria-hidden no-view sizing="both"><!--]-->blog.logrocket.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/realpython.com/" aria-label="realpython.com"><!--[--><img class="vp-icon" src="https://realpython.com/static/favicon.68cbf4197b0c.png" alt aria-hidden no-view sizing="both"><!--]-->realpython.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/digitalocean.com/" aria-label="digitalocean.com"><!--[--><img class="vp-icon" src="https://digitalocean.com/_next/static/media/favicon.594d6067.ico" alt aria-hidden no-view sizing="both"><!--]-->digitalocean.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/antonioleiva.com/" aria-label="antonioleiva.com"><!--[--><img class="vp-icon" src="/bookshelf/assets/image/antonioleiva.com/favicon.png" alt aria-hidden no-view sizing="both"><!--]-->antonioleiva.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/johnnyreilly.com/" aria-label="johnnyreilly.com"><!--[--><img class="vp-icon" src="https://johnnyreilly.com/favicon.ico" alt aria-hidden no-view sizing="both"><!--]-->johnnyreilly.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/code-maze.com/" aria-label="code-maze.com"><!--[--><img class="vp-icon" src="/bookshelf/assets/image/code-maze.com/favicon.png" alt aria-hidden no-view sizing="both"><!--]-->code-maze.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/milanjovanovic.tech/" aria-label="milanjovanovic.tech"><!--[--><img class="vp-icon" src="https://milanjovanovic.tech/profile_favicon.png" alt aria-hidden no-view sizing="both"><!--]-->milanjovanovic.tech<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/shopify.engineering/" aria-label="shopify.engineering"><!--[--><img class="vp-icon" src="https://cdn.shopify.com/static/shopify-favicon.png" alt aria-hidden no-view sizing="both"><!--]-->shopify.engineering<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/devtoolstips.org/" aria-label="devtoolstips.org"><!--[--><img class="vp-icon" src="https://devtoolstips.org/assets/favicon.ico" alt aria-hidden no-view sizing="both"><!--]-->devtoolstips.org<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/piccalil.li/" aria-label="piccalil.li"><!--[--><img class="vp-icon" src="https://piccalil.li/favicons/apple-touch-icon.png" alt aria-hidden no-view sizing="both"><!--]-->piccalil.li<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/sitepoint.com/" aria-label="sitepoint.com"><!--[--><img class="vp-icon" src="https://sitepoint.com/favicons/512x512.png" alt aria-hidden no-view sizing="both"><!--]-->sitepoint.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/event-driven.io/" aria-label="event-driven.io"><!--[--><img class="vp-icon" src="/bookshelf/assets/image/event-driven.io/favicon.jfif" alt aria-hidden no-view sizing="both"><!--]-->event-driven.io<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/packagemain.tech/" aria-label="packagemain.tech"><!--[--><img class="vp-icon" src="https://substack-post-media.s3.amazonaws.com/public/images/2ea54e25-eaa6-4630-bfc0-10b8cfdce894/apple-touch-icon-1024x1024.png" alt aria-hidden no-view sizing="both"><!--]-->packagemain.tech<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/gosolve.io/" aria-label="gosolve.io"><!--[--><img class="vp-icon" src="https://gosolve.io/wp-content/uploads/2022/03/cropped-ikona1-192x192.png" alt aria-hidden no-view sizing="both"><!--]-->gosolve.io<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/towardsdatascience.com/" aria-label="towardsdatascience.com"><!--[--><img class="vp-icon" src="https://cdn-images-1.medium.com/v2/resize:fill:128:128/1*VzTUkfeGymHP4Bvav-T-lA.png" alt aria-hidden no-view sizing="both"><!--]-->towardsdatascience.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/douggregor.net/" aria-label="douggregor.net"><!--[--><i class="vp-icon fas fa-globe" sizing="both"></i><!--]-->douggregor.net<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/d2.naver.com/" aria-label="d2.naver.com"><!--[--><img class="vp-icon" src="/bookshelf/assets/image/d2.naver.com/favicon.ico" alt aria-hidden no-view sizing="both"><!--]-->d2.naver.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/tech.kakao.com/" aria-label="tech.kakao.com"><!--[--><img class="vp-icon" src="https://www.kakaocorp.com/page/favicon.ico" alt aria-hidden no-view sizing="both"><!--]-->tech.kakao.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/tech.kakaopay.com/" aria-label="tech.kakaopay.com"><!--[--><img class="vp-icon" src="https://tech.kakaopay.com/favicon.ico" alt aria-hidden no-view sizing="both"><!--]-->tech.kakaopay.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/fe-developers.kakaoent.com/" aria-label="fe-developers.kakaoent.com"><!--[--><img class="vp-icon" src="https://fe-developers.kakaoent.com/favicon-32x32.png?v=44803cb16c1e2debd3984cf2e8cb2ded" alt aria-hidden no-view sizing="both"><!--]-->fe-developers.kakaoent.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/yozm.wishket.com/" aria-label="yozm.wishket.com"><!--[--><img class="vp-icon" src="https://yozm.wishket.com/favicon.ico" alt aria-hidden no-view sizing="both"><!--]-->yozm.wishket.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/popit.kr/" aria-label="popit.kr"><!--[--><img class="vp-icon" src="https://popit.kr/wp-content/uploads/2016/08/favicon_32x32.png" alt aria-hidden no-view sizing="both"><!--]-->popit.kr<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/devkuma.com/" aria-label="devkuma.com"><!--[--><img class="vp-icon" src="https://devkuma.com/favicons/favicon.ico" alt aria-hidden no-view sizing="both"><!--]-->devkuma.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/blog.gangnamunni.com/" aria-label="blog.gangnamunni.com"><!--[--><img class="vp-icon" src="https://blog.gangnamunni.com/favicon.ico" alt aria-hidden no-view sizing="both"><!--]-->blog.gangnamunni.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/codingeverybody.kr/" aria-label="codingeverybody.kr"><!--[--><img class="vp-icon" src="https://codingeverybody.kr/wp-content/uploads/cropped-favicon-origin-192x192.png" alt aria-hidden no-view sizing="both"><!--]-->codingeverybody.kr<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label><!--[--><i class="vp-icon fas fa-network-wired" sizing="height"></i><!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/tecmint.com/" aria-label="tecmint.com"><!--[--><img class="vp-icon" src="https://tecmint.com/wp-content/uploads/2020/07/favicon.ico" alt aria-hidden no-view sizing="both"><!--]-->tecmint.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link route-link-active auto-link" href="/bookshelf/docker.com/" aria-label="docker.com"><!--[--><img class="vp-icon" src="https://docker.com/app/uploads/2024/02/cropped-docker-logo-favicon-192x192.png" alt aria-hidden no-view sizing="both"><!--]-->docker.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/learnk8s.io/" aria-label="learnk8s.io"><!--[--><img class="vp-icon" src="https://static.learnk8s.io/f7e5160d4744cf05c46161170b5c11c9.svg" alt aria-hidden no-view sizing="both"><!--]-->learnk8s.io<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/itsfoss.com/" aria-label="itsfoss.com"><!--[--><img class="vp-icon" src="https://itsfoss.com/content/images/size/w256h256/2022/12/android-chrome-192x192.png" alt aria-hidden no-view sizing="both"><!--]-->itsfoss.com<!----></a></li></ul></button></div></div></nav><!--]--></div><div class="vp-navbar-end"><!--[--><!----><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/chanhi2000/articles" target="_blank" rel="noopener noreferrer" aria-label="Github"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-appearance-button" tabindex="-1" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" class="icon outlook-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="outlook icon" name="outlook"><path d="M224 800c0 9.6 3.2 44.8 6.4 54.4 6.4 48-48 76.8-48 76.8s80 41.6 147.2 0 134.4-134.4 38.4-195.2c-22.4-12.8-41.6-19.2-57.6-19.2C259.2 716.8 227.2 761.6 224 800zM560 675.2l-32 51.2c-51.2 51.2-83.2 32-83.2 32 25.6 67.2 0 112-12.8 128 25.6 6.4 51.2 9.6 80 9.6 54.4 0 102.4-9.6 150.4-32l0 0c3.2 0 3.2-3.2 3.2-3.2 22.4-16 12.8-35.2 6.4-44.8-9.6-12.8-12.8-25.6-12.8-41.6 0-54.4 60.8-99.2 137.6-99.2 6.4 0 12.8 0 22.4 0 12.8 0 38.4 9.6 48-25.6 0-3.2 0-3.2 3.2-6.4 0-3.2 3.2-6.4 3.2-6.4 6.4-16 6.4-16 6.4-19.2 9.6-35.2 16-73.6 16-115.2 0-105.6-41.6-198.4-108.8-268.8C704 396.8 560 675.2 560 675.2zM224 419.2c0-28.8 22.4-51.2 51.2-51.2 28.8 0 51.2 22.4 51.2 51.2 0 28.8-22.4 51.2-51.2 51.2C246.4 470.4 224 448 224 419.2zM320 284.8c0-22.4 19.2-41.6 41.6-41.6 22.4 0 41.6 19.2 41.6 41.6 0 22.4-19.2 41.6-41.6 41.6C339.2 326.4 320 307.2 320 284.8zM457.6 208c0-12.8 12.8-25.6 25.6-25.6 12.8 0 25.6 12.8 25.6 25.6 0 12.8-12.8 25.6-25.6 25.6C470.4 233.6 457.6 220.8 457.6 208zM128 505.6C128 592 153.6 672 201.6 736c28.8-60.8 112-60.8 124.8-60.8-16-51.2 16-99.2 16-99.2l316.8-422.4c-48-19.2-99.2-32-150.4-32C297.6 118.4 128 291.2 128 505.6zM764.8 86.4c-22.4 19.2-390.4 518.4-390.4 518.4-22.4 28.8-12.8 76.8 22.4 99.2l9.6 6.4c35.2 22.4 80 12.8 99.2-25.6 0 0 6.4-12.8 9.6-19.2 54.4-105.6 275.2-524.8 288-553.6 6.4-19.2-3.2-32-19.2-32C777.6 76.8 771.2 80 764.8 86.4z"></path></svg><div class="vp-appearance-dropdown"><!----></div></button></div><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><img class="vp-icon" src="https://docker.com/app/uploads/2024/02/cropped-docker-logo-favicon-192x192.png" alt aria-hidden no-view sizing="both"><span class="vp-sidebar-title">docker.com</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">2025</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">2024</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">2023</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">2022</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">2021</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">2020</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">2019</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">2018</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">2017</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">2016</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">2015</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">2013</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/bookshelf/docker.com/gathering-lxc-docker-containers-metrics.html" aria-label="Gathering LXC and Docker containers metricsDocker"><!--[--><i class="vp-icon fa-brands fa-docker" sizing="both"></i><!--]-->Gathering LXC and Docker containers metricsDocker<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/bookshelf/docker.com/docker-can-now-run-within-docker.html" aria-label="Docker can now run within DockerDocker"><!--[--><i class="vp-icon fa-brands fa-docker" sizing="both"></i><!--]-->Docker can now run within DockerDocker<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/bookshelf/docker.com/how-to-use-your-own-registry.html" aria-label="How to use your own private local registry with Docker"><!--[--><i class="vp-icon fa-brands fa-docker" sizing="both"></i><!--]-->How to use your own private local registry with Docker<!----></a></li></ul></section></li></ul></section></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><div class="page-cover"><img src="https://docker.com/app/uploads/2013/08/jerome_docker_in_docker_squ.jpg" alt no-view></div><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><i class="vp-icon fa-brands fa-docker" sizing="height"></i>Gathering LXC and Docker containers metricsDocker</h1><div class="page-info"><span class="page-author-info" aria-label="Author🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://docker.com/author/jerome/" target="_blank" rel="noopener noreferrer">Jérôme Petazzoni</a></span><span property="author" content="Jérôme Petazzoni"></span></span><!----><span class="page-date-info" aria-label="Writing Date📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">10/9/13</span><meta property="datePublished" content="2013-10-09T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="Reading Time⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 15 min</span><meta property="timeRequired" content="PT15M"></span><span class="page-category-info" aria-label="Category🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item color2" role>DevOps</span><span class="page-category-item color8" role>Docker</span><span class="page-category-item color8" role>Article(s)</span><!--]--><meta property="articleSection" content="DevOps,Docker,Article(s)"></span><span class="page-tag-info" aria-label="Tag🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon" name="tag"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item color8" role>blog</span><span class="page-tag-item color5" role>docker.com</span><span class="page-tag-item color7" role>devops</span><span class="page-tag-item color2" role>docker</span><!--]--><meta property="keywords" content="blog,docker.com,devops,docker"></span></div><hr></div><!----><div class="" vp-content><!----><div id="markdown-content"><h1 id="frontmatter-title-관련" tabindex="-1"><a class="header-anchor" href="#frontmatter-title-관련"><span>Gathering LXC and Docker containers metricsDocker 관련</span></a></h1><a class="route-link vp-card" href="/bookshelf/devops/docker/articles/" style="background:rgba(10,10,10,0.2);"><img class="vp-card-logo" src="/bookshelf/images/ico-wind.svg" loading="lazy" no-view><div class="vp-card-content"><div class="vp-card-title">Docker > Article(s)</div><hr><div class="vp-card-desc">Article(s)</div></div></a><nav class="table-of-contents"><ul><li><a aria-current="page" href="/bookshelf/docker.com/gathering-lxc-docker-containers-metrics.html#locate-your-control-groups" class="router-link-active router-link-exact-active">Locate your control groups</a><ul><li><a aria-current="page" href="/bookshelf/docker.com/gathering-lxc-docker-containers-metrics.html#control-groups-hierarchies" class="router-link-active router-link-exact-active">Control groups hierarchies</a></li><li><a aria-current="page" href="/bookshelf/docker.com/gathering-lxc-docker-containers-metrics.html#enumerating-our-cgroups" class="router-link-active router-link-exact-active">Enumerating our cgroups</a></li><li><a aria-current="page" href="/bookshelf/docker.com/gathering-lxc-docker-containers-metrics.html#finding-the-cgroup-for-a-given-container" class="router-link-active router-link-exact-active">Finding the cgroup for a given container</a></li></ul></li><li><a aria-current="page" href="/bookshelf/docker.com/gathering-lxc-docker-containers-metrics.html#collecting-memory-cpu-block-i-o-metrics" class="router-link-active router-link-exact-active">Collecting memory, CPU, block I/O metrics</a><ul><li><a aria-current="page" href="/bookshelf/docker.com/gathering-lxc-docker-containers-metrics.html#memory-metrics" class="router-link-active router-link-exact-active">Memory metrics</a></li><li><a aria-current="page" href="/bookshelf/docker.com/gathering-lxc-docker-containers-metrics.html#cpu-metrics" class="router-link-active router-link-exact-active">CPU metrics</a></li><li><a aria-current="page" href="/bookshelf/docker.com/gathering-lxc-docker-containers-metrics.html#block-i-o-metrics" class="router-link-active router-link-exact-active">Block I/O metrics</a></li></ul></li><li><a aria-current="page" href="/bookshelf/docker.com/gathering-lxc-docker-containers-metrics.html#collecting-network-metrics" class="router-link-active router-link-exact-active">Collecting network metrics</a><ul><li><a aria-current="page" href="/bookshelf/docker.com/gathering-lxc-docker-containers-metrics.html#iptables" class="router-link-active router-link-exact-active">Iptables</a></li><li><a aria-current="page" href="/bookshelf/docker.com/gathering-lxc-docker-containers-metrics.html#interface-level-counters" class="router-link-active router-link-exact-active">Interface-level counters</a></li></ul></li><li><a aria-current="page" href="/bookshelf/docker.com/gathering-lxc-docker-containers-metrics.html#collecting-metrics-when-a-container-exits" class="router-link-active router-link-exact-active">Collecting metrics when a container exits</a></li><li><a aria-current="page" href="/bookshelf/docker.com/gathering-lxc-docker-containers-metrics.html#wrapping-it-up" class="router-link-active router-link-exact-active">Wrapping it up</a></li></ul></nav><hr><div class="vp-site-info" data-name="Gathering LXC and Docker containers metricsDocker"><a class="vp-site-info-navigator no-external-link-icon" title="Gathering LXC and Docker containers metricsDocker" href="https://docker.com/blog/gathering-lxc-docker-containers-metrics" target="_blank"></a><div class="vp-site-info-preview" style="background:url(https://docker.com/app/uploads/2013/08/jerome_docker_in_docker_squ.jpg) center/cover no-repeat;"></div><div class="vp-site-info-detail"><img class="vp-site-info-logo" src="https://docker.com/app/uploads/2024/02/cropped-docker-logo-favicon-192x192.png" alt loading="lazy" no-view><div class="vp-site-info-name">Gathering LXC and Docker containers metricsDocker</div><div class="vp-site-info-desc">Learn from Docker experts to simplify and advance your app development and management with Docker. Stay up to date on Docker events and new version</div></div><!----></div><p>Linux Containers rely on control groups which not only track groups of processes, but also expose a lot of metrics about CPU, memory, and block I/O usage. We will see how to access those metrics, and how to obtain network usage metrics as well. This is relevant for “pure” <a href="http://lxc.sourceforge.net/" target="_blank" rel="noopener noreferrer"><i class="vp-icon fas fa-globe" sizing="height"></i>LXC containers</a>, as well as for <a href="http://docker.io" target="_blank" rel="noopener noreferrer"><i class="vp-icon fa-brands fa-docker" sizing="height"></i>Docker</a> containers.</p><hr><h2 id="locate-your-control-groups" tabindex="-1"><a class="header-anchor" href="#locate-your-control-groups"><span>Locate your control groups</span></a></h2><p>Control groups are exposed through a pseudo-filesystem. In recent distros, you should find this filesystem under <code>/sys/fs/cgroup</code>. Under that directory, you will see multiple sub-directories, called <code>devices</code>, <code>freezer</code>, <code>blkio</code>, etc.; each sub-directory actually corresponds to a different cgroup <em>hierarchy</em>.</p><p>On older systems, the control groups might be mounted on <code>/cgroup</code>, without distinct hierarchies. In that case, instead of seeing the sub-directories, you will see a bunch of files in that directory, and possibly some directories corresponding to existing containers.</p><p>To figure out where your control groups are mounted, you can run:</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code class="language-bash"><span class="line"><span class="token function">grep</span> cgroup /proc/mounts</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="control-groups-hierarchies" tabindex="-1"><a class="header-anchor" href="#control-groups-hierarchies"><span>Control groups hierarchies</span></a></h3><p>The fact that different control groups can be in different hierarchies mean that you can use completely different groups (and policies) for e.g. CPU allocation and memory allocation. Let’s make up a completely imaginary example: you have a 2-CPU system running Python webapps with Gunicorn, a PostgreSQL database, and accepting SSH logins. You can put each webapp and each SSH session in their own memory control group (to make sure that a single app or user doesn’t use up the memory of the whole system), and at the same time, stick the webapps and database on a CPU, and the SSH logins on another CPU.</p><p>Of course, if you run LXC containers, each hierarchy will have one group per container, and all hierarchies will look the same.</p><p>Merging or splitting hierarchies is achieved by using special options when mounting the cgroup pseudo-filesystems. Note that if you want to change that, you will have to remove all existing cgroups in the hierarchies that you want to split or merge.</p><h3 id="enumerating-our-cgroups" tabindex="-1"><a class="header-anchor" href="#enumerating-our-cgroups"><span>Enumerating our cgroups</span></a></h3><p>You can look into <code>/proc/cgroups</code> to see the different control group subsystems known to the system, the hierarchy they belong to, and how many groups they contain.</p><p>You can also look at <code>/proc/&lt;pid&gt;/cgroup</code> to see which control groups a process belongs to. The control group will be shown as a path relative to the root of the hierarchy mountpoint; e.g. <code>/</code> means “this process has not been assigned into a particular group”, while <code>/lxc/pumpkin</code> means that the process is likely to be a member of a container named <code>pumpkin</code>.</p><h3 id="finding-the-cgroup-for-a-given-container" tabindex="-1"><a class="header-anchor" href="#finding-the-cgroup-for-a-given-container"><span>Finding the cgroup for a given container</span></a></h3><p>For each container, one cgroup will be created in each hierarchy. On older systems with older versions of the LXC userland tools, the name of the cgroup will be the name of the container. With more recent versions of the LXC tools, the cgroup will be <code>lxc/&lt;container_name&gt;</code>.</p><p>Additional note for Docker users: the container name will be the <em>full ID</em> or <em>long ID</em> of the container. If a container shows up as <code>ae836c95b4c3</code> in <code>docker ps</code>, its long ID might be something like <code>ae836c95b4c3c9e9179e0e91015512da89fdec91612f63cebae57df9a5444c79</code>. You can look it up with <code>docker inspect</code> or <code>docker ps -notrunc</code>.</p><p>Putting everything together: on my system, if I want to look at the memory metrics for a Docker container, I have to look at <code>/sys/fs/cgroup/memory/lxc/&lt;longid&gt;/</code>.</p><hr><h2 id="collecting-memory-cpu-block-i-o-metrics" tabindex="-1"><a class="header-anchor" href="#collecting-memory-cpu-block-i-o-metrics"><span>Collecting memory, CPU, block I/O metrics</span></a></h2><p>For each subsystem, we will find one pseudo-file (in some cases, multiple) containing statistics about used memory, accumulated CPU cycles, or number of I/O completed. Those files are easy to parse, as we will see.</p><h3 id="memory-metrics" tabindex="-1"><a class="header-anchor" href="#memory-metrics"><span>Memory metrics</span></a></h3><p>Those will be found in the <code>memory</code> cgroup (duh!). Note that the memory control group adds a little overhead, because it does very fine-grained accounting of the memory usage on your system. Therefore, many distros chose to <em>not</em> enable it by default. Generally, to enable it, all you have to do is to add some kernel command-line parameters: <code>cgroup_enable=memory swapaccount=1</code>.</p><p>The metrics are in the pseudo-file <code>memory.stat</code>. Here is what it will look like:</p><div class="code-block-with-title"><div class="code-block-title-bar" data-title="memory.stat"><span>memory.stat</span></div><div class="language-plaintext line-numbers-mode" data-highlighter="prismjs" data-ext="plaintext"><pre><code class="language-plaintext"><span class="line">cache 11492564992</span>
<span class="line">rss 1930993664</span>
<span class="line">mapped_file 306728960</span>
<span class="line">pgpgin 406632648</span>
<span class="line">pgpgout 403355412</span>
<span class="line">swap 0</span>
<span class="line">pgfault 728281223</span>
<span class="line">pgmajfault 1724</span>
<span class="line">inactive_anon 46608384</span>
<span class="line">active_anon 1884520448</span>
<span class="line">inactive_file 7003344896</span>
<span class="line">active_file 4489052160</span>
<span class="line">unevictable 32768</span>
<span class="line">hierarchical_memory_limit 9223372036854775807</span>
<span class="line">hierarchical_memsw_limit 9223372036854775807</span>
<span class="line">total_cache 11492564992</span>
<span class="line">total_rss 1930993664</span>
<span class="line">total_mapped_file 306728960</span>
<span class="line">total_pgpgin 406632648</span>
<span class="line">total_pgpgout 403355412</span>
<span class="line">total_swap 0</span>
<span class="line">total_pgfault 728281223</span>
<span class="line">total_pgmajfault 1724</span>
<span class="line">total_inactive_anon 46608384</span>
<span class="line">total_active_anon 1884520448</span>
<span class="line">total_inactive_file 7003344896</span>
<span class="line">total_active_file 4489052160</span>
<span class="line">total_unevictable 32768</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></div><p>The first half (without the <code>total_</code> prefix) contains statistics relevant to the processes within the cgroup, excluding sub-cgroups. The second half (with the <code>total_</code> prefix) includes sub-cgroups as well.</p><p>Some metrics are “gauges”, i.e. values that can increase or decrease (e.g. <code>swap</code>, the amount of swap space used by the members of the cgroup). Some others are “counters”, i.e. values that can only go up, because they represent occurrences of a specific event (e.g. <code>pgfault</code>, which indicates the number of page faults which happened since the creation of the cgroup; this number can never decrease).</p><p>Let’s see what those metrics stand for. All memory amounts are in bytes (except for event counters).</p><ul><li><strong>cache</strong> is the amount of memory used by the processes of this control group that can be associated precisely with a block on a block device. When you read and write files from and to disk, this amount will increase. This will be the case if you use “conventional” I/O (<code>open</code>, <code>read</code>, <code>write</code> syscalls) as well as mapped files (with <code>mmap</code>). It also accounts for the memory used by <code>tmpfs</code> mounts. I don’t know exactly why; it might be because <code>tmpfs</code> filesystems work directly with the page cache.</li><li><strong>rss</strong> is the amount of memory that <em>doesn’t</em> correspond to anything on disk: stacks, heaps, and anonymous memory maps.</li><li><strong>mapped_file</strong> indicates the amount of memory mapped by the processes in the control group. In my humble opinion, it doesn’t give you an information about <em>how much</em> memory is used; it rather tells you <em>how</em> it is used.</li><li><strong>pgpgin</strong> and <strong>pgpgout</strong> are a bit tricky. If you are used to <code>vmstat</code>, you might think that they indicate the number of times that a page had to be read and written (respectively) by a process of the cgroup, and that they should reflect both file I/O and swap activity. Wrong! In fact, they correspond to <em>charging events</em>. Each time a page is “charged” (=added to the accounting) to a cgroup, <strong>pgpgin</strong> increases. When a page is “uncharged” (=no longer “billed” to a cgroup), <strong>pgpgout</strong> increases.</li><li><strong>pgfault</strong> and <strong>pgmajfault</strong> indicate the number of times that a process of the cgroup triggered a “page fault” and a “major fault”, respectively. A page fault happens when a process accesses a part of its virtual memory space which is inexistent or protected. The former can happen if the process is buggy and tries to access an invalid address (it will then be sent a <code>SIGSEGV</code> signal, typically killing it with the famous <code>Segmentation fault</code> message). The latter can happen when the process reads from a memory zone which has been swapped out, or which corresponds to a mapped file: in that case, the kernel will load the page from disk, and let the CPU complete the memory access. It can also happen when the process writes to a copy-on-write memory zone: likewise, the kernel will preempt the process, duplicate the memory page, and resume the write operation on the process’ own copy of the page. “Major” faults happen when the kernel actually has to read the data from disk. When it just has to duplicate an existing page, or allocate an empty page, it’s a regular (or “minor”) fault.</li><li><strong>swap</strong> is (as expected) the amount of swap currently used by the processes in this cgroup.</li><li><strong>active_anon</strong> and <strong>inactive_anon</strong> is the amount of <em>anonymous</em> memory that has been identified has respectively <em>active</em> and <em>inactive</em> by the kernel. “Anonymous” memory is the memory that is <em>not</em> linked to disk pages. In other words, that’s the equivalent of the <strong>rss</strong> counter described above. In fact, the very definition of the <strong>rss</strong> counter is <strong>active_anon</strong>+<strong>inactive_anon</strong>-<strong>tmpfs</strong> (where <strong>tmpfs</strong> is the amount of memory used up by <code>tmpfs</code> filesystems mounted by this control group). Now, what’s the difference between “active” and “inactive”? Pages are initially “active”; and at regular intervals, the kernel sweeps over the memory, and tags some pages as “inactive”. Whenever they are accessed again, they are immediately retagged “active”. When the kernel is almost out of memory, and time comes to swap out to disk, the kernel will swap “inactive” pages.</li><li>Likewise, the <strong>cache</strong> memory is broken down into <strong>active_file</strong> and <strong>inactive_file</strong>. The exact formula is <strong>cache</strong>=<strong>active_file</strong>+<strong>inactive_file</strong>+<strong>tmpfs</strong>. The exact rules used by the kernel to move memory pages between active and inactive sets are different from the ones used for anonymous memory, but the general principle is the same. Note that when the kernel needs to reclaim memory, it is cheaper to reclaim a clean (=non modified) page from this pool, since it can be reclaimed immediately (while anonymous pages and dirty/modified pages have to be written to disk first).</li><li><strong>unevictable</strong> is the amount of memory that cannot be reclaimed; generally, it will account for memory that has been “locked” with <code>mlock</code>. It is often used by crypto frameworks to make sure that secret keys and other sensitive material never gets swapped out to disk.</li><li>Last but not least, the <strong>memory</strong> and <strong>memsw</strong> limits are not really metrics, but a reminder of the limits applied to this cgroup. The first one indicates the maximum amount of physical memory that can be used by the processes of this control group; the second one indicates the maximum amount of RAM+swap.</li></ul><p>Accounting for memory in the page cache is very complex. If two processes in different control groups both read the same file (ultimately relying on the same blocks on disk), the corresponding memory charge will be split between the control groups. It’s nice, but it also means that when a cgroup is terminated, it could increase the memory usage of another cgroup, because they are not splitting the cost anymore for those memory pages.</p><h3 id="cpu-metrics" tabindex="-1"><a class="header-anchor" href="#cpu-metrics"><span>CPU metrics</span></a></h3><p>Now that we’ve covered memory metrics, everything else will look very simple in comparison. CPU metrics will be found in the <code>cpuacct</code> controller.</p><p>For each container, you will find a pseudo-file <code>cpuacct.stat</code>, containing the CPU usage accumulated by the processes of the container, broken down between <code>user</code> and <code>system</code> time. If you’re not familiar with the distinction, <code>user</code> is the time during which the processes were in direct control of the CPU (i.e. executing process code), and <code>system</code> is the time during which the CPU was executing system calls on behalf of those processes.</p><p>Those times are expressed in ticks of 1/100th of second. (Actually, they are expressed in “user jiffies”. There are <code>USER_HZ</code> <em>“jiffies”</em> per second, and on x86 systems, <code>USER_HZ</code> is 100. This used to map exactly to the number of scheduler “ticks” per second; but with the advent of higher frequency scheduling, as well as <a href="http://lwn.net/Articles/549580/" target="_blank" rel="noopener noreferrer"><i class="vp-icon fas fa-globe" sizing="height"></i>tickless kernels</a>, the number of kernel ticks wasn’t relevant anymore. It stuck around anyway, mainly for legacy and compatibility reasons.)</p><h3 id="block-i-o-metrics" tabindex="-1"><a class="header-anchor" href="#block-i-o-metrics"><span>Block I/O metrics</span></a></h3><p>Block I/O is accounted in the <code>blkio</code> controller. Different metrics are scattered across different files. While you can find in-depth details in the blkio-controller file in the kernel documentation, here is a short list of the most relevant ones:</p><ul><li><strong>blkio.sectors</strong> contains the number of 512-bytes sectors read and written by the processes member of the cgroup, device by device. Reads and writes are merged in a single counter.</li><li><strong>blkio.io_service_bytes</strong> indicates the number of bytes read and written by the cgroup. It has 4 counters per device, because for each device, it differentiates between synchronous vs. asynchronous I/O, and reads vs. writes.</li><li><strong>blkio.io_serviced</strong> is similar, but instead of showing byte counters, it will show the number of I/O operations performed, regardless of their size. It also has 4 counters per device.</li><li><strong>blkio.io_queued</strong> indicates the number of I/O operations currently queued for this cgroup. In other words, if the cgroup isn’t doing any I/O, this will be zero. Note that the opposite is not true. In other words, if there is no I/O queued, it does not mean that the cgroup is idle (I/O-wise). It could be doing purely synchronous reads on an otherwise quiescent device, which is therefore able to handle them immediately, without queuing. Also, while it is helpful to figure out which cgroup is putting stress on the I/O subsystem, keep in mind that is is a relative quantity. Even if a process group does not perform more I/O, its queue size can increase just because the device load increases because of other devices.</li></ul><p>For each file, there is a <code>_recursive</code> variant, that aggregates the metrics of the control group and all its sub-cgroups.</p><p>Also, it’s worth mentioning that in most cases, if the processes of a control group have not done any I/O on a given block device, the block device will not appear in the pseudo-files. In other words, you have to be careful each time you parse one of those files, because new entries might have appeared since the previous time.</p><hr><h2 id="collecting-network-metrics" tabindex="-1"><a class="header-anchor" href="#collecting-network-metrics"><span>Collecting network metrics</span></a></h2><p>Interestingly, network metrics are not exposed directly by control groups. There is a good explanation for that: network interfaces exist within the context of <em>network namespaces</em>. The kernel could probably accumulate metrics about packets and bytes sent and received by a group of processes, but those metrics wouldn’t be very useful. You want (at least!) per-interface metrics (because traffic happening on the local <code>lo</code> interface doesn’t really count). But since processes in a single cgroup can belong to multiple network namespaces, those metrics would be harder to interpret: multiple network namespaces means multiple <code>lo</code> interfaces, potentially multiple <code>eth0</code> interfaces, etc.; so this is why there is no easy way to gather network metrics with control groups.</p><p>So what shall we do? Well, we have multiple options.</p><h3 id="iptables" tabindex="-1"><a class="header-anchor" href="#iptables"><span>Iptables</span></a></h3><p>When people think about <code>iptables</code>, they usually think about firewalling, and maybe NAT scenarios. But <code>iptables</code> (or rather, the <code>netfilter</code> framework for which <code>iptables</code> is just an interface) can also do some serious accounting.</p><p>For instance, you can setup a rule to account for the outbound HTTP traffic on a web server:</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code class="language-bash"><span class="line">iptables <span class="token parameter variable">-I</span> OUTPUT <span class="token parameter variable">-p</span> tcp <span class="token parameter variable">--sport</span> <span class="token number">80</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>There is no <code>-j</code> or <code>-g</code> flag, so the rule will just count matched packets and go to the following rule.</p><p>Later, you can check the values of the counters, with:</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code class="language-bash"><span class="line">iptables <span class="token parameter variable">-nxvL</span> OUTPUT</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>(Technically, <code>-n</code> is not required, but it will prevent iptables from doing DNS reverse lookups, which are probably useless in this scenario.)</p><p>Counters include packets and bytes. If you want to setup metrics for container traffic like this, you could execute a <code>for</code> loop to add two <code>iptables</code> rules per container IP address (one in each direction), in the <code>FORWARD</code> chain. This will only meter traffic going through the NAT layer; you will also have to add traffic going through the userland proxy.</p><p>Then, you will need to check those counters on a regular basis. If you happen to use <a href="http://collectd.org/" target="_blank" rel="noopener noreferrer"><i class="vp-icon fas fa-globe" sizing="height"></i>collectd</a>, there is a nice plugin to automate iptables counters collection.</p><h3 id="interface-level-counters" tabindex="-1"><a class="header-anchor" href="#interface-level-counters"><span>Interface-level counters</span></a></h3><p>Since each container has a virtual Ethernet interface, you might want to check directly the TX and RX counters of this interface. However, this is not as easy as it sounds. If you use Docker (as of current version 0.6) or <code>lxc-start</code>, then you will notice that each container is associated to a virtual Ethernet interface in your host, with a name like <code>vethKk8Zqi</code>. Figuring out which interface corresponds to which container is, unfortunately, difficult. (If you know an easy way, let me know.)</p><p>In the long run, Docker will probably take over the setup of those virtual interfaces. It will keep track of their names, and make sure that it can easily associate containers with their respective interfaces.</p><p>But for now, the best way is to check the metrics <em>from within the containers</em>. I’m not talking about running a special agent in the container, or anything like that. We are going to run an executable from the host environment, but within the network namespace of a container.</p><h4 id="ip-netns-magic" tabindex="-1"><a class="header-anchor" href="#ip-netns-magic"><span>ip-netns magic</span></a></h4><p>To do that, we will use the <code>ip netns exec</code> command. This command will let you execute any program (present in the host system) within any network namespace visible to the current process. This means that your host will be able to enter the network namespace of your containers, but your containers won’t be able to access the host, nor their sibling containers. Containers will be able to “see” and affect their sub-containers, though.</p><p>The exact format of the command is:</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code class="language-bash"><span class="line"><span class="token function">ip</span> netns <span class="token builtin class-name">exec</span> <span class="token operator">&lt;</span>nsname<span class="token operator">&gt;</span> <span class="token operator">&lt;</span>command<span class="token punctuation">..</span>.<span class="token operator">&gt;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>For instance:</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code class="language-bash"><span class="line"><span class="token function">ip</span> netns <span class="token builtin class-name">exec</span> mycontainer <span class="token function">netstat</span> <span class="token parameter variable">-i</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>How does the naming system work? How does <code>ip netns</code> find <code>mycontainer</code>? Answer: by using the namespaces pseudo-files. Each process belongs to one network namespace, one PID namespace, one <code>mnt</code> namespace, etc.; and those namespaces are materialized under <code>/proc/&lt;pid&gt;/ns/</code>. For instance, the network namespace of PID 42 is materialized by the pseudo-file <code>/proc/42/ns/net</code>.</p><p>When you run <code>ip netns exec mycontainer ...</code>, it expects <code>/var/run/netns/mycontainer</code> to be one of those pseudo-files. (Symlinks are accepted.)</p><p>In other words, to execute a command within the network namespace of a container, we need to:</p><ul><li>find out the PID of any process within the container that we want to investigate;</li><li>create a symlink from <code>/var/run/netns/&lt;somename&gt;</code> to <code>/proc/&lt;thepid&gt;/ns/net</code>;</li><li>execute <code>ip netns exec &lt;somename&gt; ...</code>.</li></ul><p>Now, we need to figure out a way to find the PID of a process (any process!) running in the container that we want to investigate. This is actually very easy. You have to locate one of the control groups corresponding to the container. We explained how to locate those cgroups in the beginning of this post, so we won’t cover that again.</p><p>On my machine, a control group will typically be located in <code>/sys/fs/cgroup/devices/lxc/&lt;containerid&gt;</code>. Within that directory, you will find a pseudo-file called <code>tasks</code>. It contains the list of the PIDs that are in the control group, i.e., in the container. We can take any of them; so the first one will do.</p><p>Putting everything together, if the “short ID” of a container is held in the environment variable <code>$CID</code>, here is a small shell snippet to put everything together:</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code class="language-bash"><span class="line"><span class="token assign-left variable">TASKS</span><span class="token operator">=</span>/sys/fs/cgroup/devices/<span class="token variable">$CID</span>*/tasks</span>
<span class="line"><span class="token assign-left variable">PID</span><span class="token operator">=</span><span class="token variable"><span class="token variable">$(</span><span class="token function">head</span> <span class="token parameter variable">-n</span> <span class="token number">1</span> $TASKS<span class="token variable">)</span></span></span>
<span class="line"><span class="token function">mkdir</span> <span class="token parameter variable">-p</span> /var/run/netns</span>
<span class="line"><span class="token function">ln</span> <span class="token parameter variable">-sf</span> /proc/<span class="token variable">$PID</span>/ns/net /var/run/netns/<span class="token variable">$CID</span></span>
<span class="line"><span class="token function">ip</span> netns <span class="token builtin class-name">exec</span> <span class="token variable">$CID</span> <span class="token function">netstat</span> <span class="token parameter variable">-i</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>The same mechanism is used in <a href="https://github.com/jpetazzo/pipework" target="_blank" rel="noopener noreferrer">Pipework (<i class="vp-icon iconfont icon-github" sizing="height"></i><code>jpetazzo/pipework</code>)</a> to setup network interfaces within containers <em>from outside</em> the containers.</p><h4 id="tips-for-high-performance-metric-collection" tabindex="-1"><a class="header-anchor" href="#tips-for-high-performance-metric-collection"><span>Tips for high-performance metric collection</span></a></h4><p>Note that running a new process each time you want to update metrics is (relatively) expensive. If you want to collect metrics at high resolutions, and/or over a large number of containers (think 1000 containers on a single host), you do not want to fork a new process each time.</p><p>Here is how to collect metrics from a single process. You will have to write your metric collector in C (or any language that lets you do low-level system calls). You need to use a special system call, <code>setns()</code>, which lets the current process enter any arbitrary namespace. It requires, however, an open file descriptor to the namespace pseudo-file (remember: that’s the pseudo-file in <code>/proc/&lt;pid&gt;/ns/net</code>).</p><p>However, there is a catch: you must not keep this file descriptor open. If you do, when the last process of the control group exits, the namespace will not be destroyed, and its network resources (like the virtual interface of the container) will stay around for ever (or until you close that file descriptor).</p><p>The right approach would be to keep track of the first PID of each container, and re-open the namespace pseudo-file each time.</p><hr><h2 id="collecting-metrics-when-a-container-exits" tabindex="-1"><a class="header-anchor" href="#collecting-metrics-when-a-container-exits"><span>Collecting metrics when a container exits</span></a></h2><p>Sometimes, you do not care about real time metric collection, but when a container exits, you want to know how much CPU, memory, etc. it has used.</p><p>The current implementation of Docker (as of 0.6) makes this particularly challenging, because it relies on <code>lxc-start</code>, and when a container stops, <code>lxc-start</code> carefully cleans up behind it. If you really want to collect the metrics anyway, here is how. For each container, start a collection process, and move it to the control groups that you want to monitor by writing its PID to the <code>tasks</code> file of the cgroup. The collection process should periodically re-read the <code>tasks</code> file to check if it’s the last process of the control group. (If you also want to collect network statistics as explained in the previous section, you should also move the process to the appropriate network namespace.)</p><p>When the container exits, <code>lxc-start</code> will try to delete the control groups. It will fail, since the control group is still in use; but that’s fine. You process should now detect that it is the only one remaining in the group. Now is the right time to collect all the metrics you need!</p><p>Finally, your process should move itself back to the root control group, and remove the container control group. To remove a control group, just <code>rmdir</code> its directory. It’s counter-intuitive to <code>rmdir</code> a directory as it still contains files; but remember that this is a pseudo-filesystem, so usual rules don’t apply. After the cleanup is done, the collection process can exit safely.</p><p>As you can see, collecting metrics when a container exits can be tricky; for this reason, it is usually easier to collect metrics at regular intervals (e.g. every minute, with the collectd LXC plugin) and rely on that instead.</p><hr><h2 id="wrapping-it-up" tabindex="-1"><a class="header-anchor" href="#wrapping-it-up"><span>Wrapping it up</span></a></h2><p>To recap, we covered:</p><ul><li>how to locate the control groups for containers;</li><li>reading and interpreting compute metrics for containers;</li><li>different ways to obtain network metrics for containers;</li><li>a technique to gather overall metrics when a container exits.</li></ul><p>As we have seen, metrics collection is not insanely difficult, but still involves many complicated steps, with special cases like those for the network subsystem. Docker will take care of this, or at least expose hooks to make it more straightforward. It is one of the reasons why we repeat over and over “Docker is not production ready yet”: it’s fine to skip metrics for development, continuous testing, or staging environments, but it’s definitely <em>not fine</em> to run production services without metrics!</p><p>Last but not least, note that even with all that information, you will still need a storage and graphing system for those metrics. There are many such systems out there. If you want something that you can deploy on your own, you can check e.g. <a href="http://collectd.org/" target="_blank" rel="noopener noreferrer"><i class="vp-icon fas fa-globe" sizing="height"></i>collectd</a> or <a href="http://graphite.wikidot.com/" target="_blank" rel="noopener noreferrer"><i class="vp-icon fas fa-globe" sizing="height"></i>Graphite</a>. There are also “-as-a-Service” offerings. Those services will store your metrics and let you query them in various ways, for a given price. Some examples include <a href="https://metrics.librato.com/" target="_blank" rel="noopener noreferrer"><i class="vp-icon fas fa-globe" sizing="height"></i>Librato</a>, <a href="http://aws.amazon.com/cloudwatch/" target="_blank" rel="noopener noreferrer"><i class="vp-icon fa-brands fa-aws" sizing="height"></i>AWS CloudWatch</a>, <a href="http://newrelic.com/server-monitoring" target="_blank" rel="noopener noreferrer"><i class="vp-icon fas fa-globe" sizing="height"></i>New Relic Server Monitoring</a>, and many more.</p><div class="hint-container info"><p class="hint-container-title">About Jérôme Petazzoni</p><figure><img src="https://docker.com/app/uploads/2013/08/jerome_docker_in_docker_squ.jpg" alt="Jérôme Petazzoni" tabindex="0" loading="lazy"><figcaption>Jérôme Petazzoni</figcaption></figure><p>Jérôme is a senior engineer at dotCloud, where he rotates between Ops, Support and Evangelist duties and has earned the nickname of “master Yoda”. In a previous life he built and operated large scale Xen hosting back when EC2 was <a href="http://en.wikipedia.org/wiki/Cessna_EC-2" target="_blank" rel="noopener noreferrer"><i class="vp-icon fa-brands fa-wikipedia-w" sizing="height"></i>just the name of a plane</a>, supervized the deployment of fiber interconnects through the French subway, built a specialized GIS to visualize fiber infrastructure, specialized in commando deployments of large-scale computer systems in bandwidth-constrained environments such as conference centers, and various other feats of technical wizardry. He cares for the servers powering dotCloud, helps our users feel at home on the platform, and documents the many ways to use dotCloud in articles, tutorials and sample applications. He’s also an avid dotCloud power user who has deployed just about anything on dotCloud - look for one of his many custom services on our Github repository.</p><p><em>Connect with Jérôme on Twitter! <a href="https://x.com/jpetazzo" target="_blank" rel="noopener noreferrer"><i class="vp-icon fa-brands fa-x-twitter" sizing="height"></i><code>@jpetazzo</code></a></em></p></div><!-- TODO: add ARTICLE CARD --><a class="vp-card" href="https://chanhi2000.github.io/bookshelf/docker.com/gathering-lxc-docker-containers-metrics.html" target="_blank" style="background:rgba(29,99,237,0.2);"><img class="vp-card-logo" src="https://docker.com/app/uploads/2024/02/cropped-docker-logo-favicon-192x192.png" loading="lazy" no-view><div class="vp-card-content"><div class="vp-card-title">Gathering LXC and Docker containers metricsDocker</div><hr><div class="vp-card-desc">Learn from Docker experts to simplify and advance your app development and management with Docker. Stay up to date on Docker events and new version</div></div></a></div><!----><!----><!----></div><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/chanhi2000/articles/edit/main/src/docker.com/gathering-lxc-docker-containers-metrics.md" aria-label="Edit this page on GitHub" rel="noopener noreferrer" target="_blank"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->Edit this page on GitHub<!----></a></div><div class="vp-meta-item git-info"><!----><!----></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/bookshelf/devops/docker/articles/" aria-label="/devops/docker/articles/"><div class="hint"><span class="arrow start"></span>Prev</div><div class="link"><!---->/devops/docker/articles/</div></a><a class="route-link auto-link next" href="/bookshelf/docker.com/docker-can-now-run-within-docker.html" aria-label="Docker can now run within DockerDocker"><div class="hint">Next<span class="arrow end"></span></div><div class="link">Docker can now run within DockerDocker<i class="vp-icon fa-brands fa-docker" sizing="height"></i></div></a></nav><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><div class="vp-footer">MIT Licensed | Copyright © 2022-present <a href="https://github.com/chanhi2000">Chan Hee Lee</a></div><div class="vp-copyright">Copyright © 2025 Jérôme Petazzoni </div></footer></div><!--]--><!--[--><!----><!--[--><!--]--><!--[--><!--]--><!--]--><!--]--></div>
    <script type="module" src="/bookshelf/assets/app-BVguHYKu.js" defer></script>
  </body>
</html>
