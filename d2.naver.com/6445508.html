<!doctype html>
<html lang="ko-KR" data-theme="dark">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.26" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.99" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"HDFS 쓰기 파이프라인을 활용한 HBase의 WAL 쓰기 최적화","image":["https://blog.cloudera.com/apache-hbase-write-path","https://chanhi2000.github.io/bookshelf/assets/image/d2.naver.com/6445508/2.png","https://chanhi2000.github.io/bookshelf/assets/image/d2.naver.com/6445508/3.png","https://issues.apache.org/jira/secure/attachment/12445209/appendDesign3.pdf","https://chanhi2000.github.io/bookshelf/assets/image/d2.naver.com/6445508/5a.png","https://chanhi2000.github.io/bookshelf/assets/image/d2.naver.com/6445508/5b.png","https://chanhi2000.github.io/bookshelf/assets/image/d2.naver.com/6445508/6.png"],"datePublished":"2023-12-19T00:00:00.000Z","dateModified":null,"author":[]}</script><meta property="og:url" content="https://chanhi2000.github.io/bookshelf/d2.naver.com/6445508.html"><meta property="og:site_name" content="📚Bookshelf"><meta property="og:title" content="HDFS 쓰기 파이프라인을 활용한 HBase의 WAL 쓰기 최적화"><meta property="og:description" content="Article(s) > HDFS 쓰기 파이프라인을 활용한 HBase의 WAL 쓰기 최적화"><meta property="og:type" content="article"><meta property="og:image" content="https://chanhi2000.github.io/bookshelf/assets/image/d2.naver.com/6445508/banner.png"><meta property="og:locale" content="ko-KR"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image:src" content="https://chanhi2000.github.io/bookshelf/assets/image/d2.naver.com/6445508/banner.png"><meta name="twitter:image:alt" content="HDFS 쓰기 파이프라인을 활용한 HBase의 WAL 쓰기 최적화"><meta property="article:tag" content="protobuf"><meta property="article:tag" content="hbase"><meta property="article:tag" content="hdfs"><meta property="article:tag" content="hadoop"><meta property="article:tag" content="java"><meta property="article:tag" content="d2.naver.com"><meta property="article:tag" content="blog"><meta property="article:published_time" content="2023-12-19T00:00:00.000Z"><link rel="icon" href="/bookshelf/assets/icon/favicon.svg"><title>HDFS 쓰기 파이프라인을 활용한 HBase의 WAL 쓰기 최적화 | 📚Bookshelf</title><meta name="description" content="Article(s) > HDFS 쓰기 파이프라인을 활용한 HBase의 WAL 쓰기 최적화">
    <link rel="preload" href="/bookshelf/assets/style-Bhb-QcDa.css" as="style"><link rel="stylesheet" href="/bookshelf/assets/style-Bhb-QcDa.css">
    
    
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><a class="route-link vp-brand" href="/bookshelf/" aria-label="Take me home"><img class="vp-nav-logo" src="/bookshelf/assets/icon/favicon.svg" alt><!----><span class="vp-site-name hide-in-pad">📚Bookshelf</span></a><!--]--></div><div class="vp-navbar-center"><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/bookshelf/news.html" aria-label><!--[--><i class="vp-icon fas fa-rss" sizing="height"></i><!--]--><!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label><!--[--><i class="vp-icon fas fa-keyboard" sizing="height"></i><!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/hackingwithswift.com/" aria-label="hackingwithswift.com"><!--[--><img class="vp-icon" src="https://hackingwithswift.com/favicon.svg" alt aria-hidden no-view sizing="both"><!--]-->hackingwithswift.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/fcc/" aria-label="freecodecamp.org"><!--[--><img class="vp-icon" src="https://cdn.freecodecamp.org/universal/favicons/favicon.ico" alt aria-hidden no-view sizing="both"><!--]-->freecodecamp.org<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/kodeco.com/" aria-label="kodeco.com"><!--[--><img class="vp-icon" src="https://kodeco.com/favicon.ico" alt aria-hidden no-view sizing="both"><!--]-->kodeco.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/blog.kotzilla.io/" aria-label="blog.kotzilla.io"><!--[--><img class="vp-icon" src="https://blog.kotzilla.io/hubfs/favicon.png" alt aria-hidden no-view sizing="both"><!--]-->blog.kotzilla.io<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/kt.academy/" aria-label="kt.academy"><!--[--><img class="vp-icon" src="https://kt.academy/logo.png" alt aria-hidden no-view sizing="both"><!--]-->kt.academy<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/droidcon.com/" aria-label="droidcon.com"><!--[--><img class="vp-icon" src="https://droidcon.com/wp-content/uploads/2021/07/favicon-300x300.png" alt aria-hidden no-view sizing="both"><!--]-->droidcon.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/outcomeschool.com/" aria-label="outcomeschool.com"><!--[--><img class="vp-icon" src="https://outcomeschool.com/static/favicons/apple-touch-icon.png" alt aria-hidden no-view sizing="both"><!--]-->outcomeschool.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/frontendmasters.com/" aria-label="frontendmasters.com"><!--[--><img class="vp-icon" src="https://frontendmasters.com/favicon.ico" alt aria-hidden no-view sizing="both"><!--]-->frontendmasters.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/css-tricks.com/" aria-label="css-tricks.com"><!--[--><img class="vp-icon" src="https://css-tricks.com/favicon.svg" alt aria-hidden no-view sizing="both"><!--]-->css-tricks.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/smashingmagazine.com/" aria-label="smashingmagazine.com"><!--[--><img class="vp-icon" src="https://smashingmagazine.com/images/favicon/favicon.svg" alt aria-hidden no-view sizing="both"><!--]-->smashingmagazine.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/smashingmagazine.com/" aria-label="oddbird.net"><!--[--><img class="vp-icon" src="https://oddbird.net/safari-pinned-tab.svg" alt aria-hidden no-view sizing="both"><!--]-->oddbird.net<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/zeroheight.com/" aria-label="zeroheight.com"><!--[--><img class="vp-icon" src="https://zeroheight.com/favicon.ico" alt aria-hidden no-view sizing="both"><!--]-->zeroheight.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/typescript.tv/" aria-label="typescript.tv"><!--[--><img class="vp-icon" src="https://typescript.tv/_astro/android-chrome-192x192.BhQ8hcWh.png" alt aria-hidden no-view sizing="both"><!--]-->typescript.tv<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/blog.logrocket.com/" aria-label="blog.logrocket.com"><!--[--><img class="vp-icon" src="/bookshelf/assets/image/blog.logrocket.com/favicon.png" alt aria-hidden no-view sizing="both"><!--]-->blog.logrocket.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/realpython.com/" aria-label="realpython.com"><!--[--><img class="vp-icon" src="https://realpython.com/static/favicon.68cbf4197b0c.png" alt aria-hidden no-view sizing="both"><!--]-->realpython.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/digitalocean.com/" aria-label="digitalocean.com"><!--[--><img class="vp-icon" src="https://digitalocean.com/_next/static/media/favicon.594d6067.ico" alt aria-hidden no-view sizing="both"><!--]-->digitalocean.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/antonioleiva.com/" aria-label="antonioleiva.com"><!--[--><img class="vp-icon" src="/bookshelf/assets/image/antonioleiva.com/favicon.png" alt aria-hidden no-view sizing="both"><!--]-->antonioleiva.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/johnnyreilly.com/" aria-label="johnnyreilly.com"><!--[--><img class="vp-icon" src="https://johnnyreilly.com/favicon.ico" alt aria-hidden no-view sizing="both"><!--]-->johnnyreilly.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/code-maze.com/" aria-label="code-maze.com"><!--[--><img class="vp-icon" src="/bookshelf/assets/image/code-maze.com/favicon.png" alt aria-hidden no-view sizing="both"><!--]-->code-maze.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/milanjovanovic.tech/" aria-label="milanjovanovic.tech"><!--[--><img class="vp-icon" src="https://milanjovanovic.tech/profile_favicon.png" alt aria-hidden no-view sizing="both"><!--]-->milanjovanovic.tech<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/shopify.engineering/" aria-label="shopify.engineering"><!--[--><img class="vp-icon" src="https://cdn.shopify.com/static/shopify-favicon.png" alt aria-hidden no-view sizing="both"><!--]-->shopify.engineering<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/devtoolstips.org/" aria-label="devtoolstips.org"><!--[--><img class="vp-icon" src="https://devtoolstips.org/assets/favicon.ico" alt aria-hidden no-view sizing="both"><!--]-->devtoolstips.org<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/piccalil.li/" aria-label="piccalil.li"><!--[--><img class="vp-icon" src="https://piccalil.li/favicons/apple-touch-icon.png" alt aria-hidden no-view sizing="both"><!--]-->piccalil.li<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/sitepoint.com/" aria-label="sitepoint.com"><!--[--><img class="vp-icon" src="https://sitepoint.com/favicons/512x512.png" alt aria-hidden no-view sizing="both"><!--]-->sitepoint.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/event-driven.io/" aria-label="event-driven.io"><!--[--><img class="vp-icon" src="/bookshelf/assets/image/event-driven.io/favicon.jfif" alt aria-hidden no-view sizing="both"><!--]-->event-driven.io<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/packagemain.tech/" aria-label="packagemain.tech"><!--[--><img class="vp-icon" src="https://substack-post-media.s3.amazonaws.com/public/images/2ea54e25-eaa6-4630-bfc0-10b8cfdce894/apple-touch-icon-1024x1024.png" alt aria-hidden no-view sizing="both"><!--]-->packagemain.tech<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/gosolve.io/" aria-label="gosolve.io"><!--[--><img class="vp-icon" src="https://gosolve.io/wp-content/uploads/2022/03/cropped-ikona1-192x192.png" alt aria-hidden no-view sizing="both"><!--]-->gosolve.io<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/bram.us/" aria-label="bram.us"><!--[--><img class="vp-icon" src="https://bram.us/favicon.ico" alt aria-hidden no-view sizing="both"><!--]-->bram.us<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/una.im/" aria-label="una.im"><!--[--><img class="vp-icon" src="https://una.im/favicon.svg" alt aria-hidden no-view sizing="both"><!--]-->una.im<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/joshwcomeau.com/" aria-label="joshwcomeau.com"><!--[--><img class="vp-icon" src="https://joshwcomeau.com/favicon.png" alt aria-hidden no-view sizing="both"><!--]-->joshwcomeau.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/css-tip.com/" aria-label="css-tip.com"><!--[--><img class="vp-icon" src="https://css-tip.com/img/fav.png" alt aria-hidden no-view sizing="both"><!--]-->css-tip.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/nerdy.dev/" aria-label="nerdy.dev"><!--[--><img class="vp-icon" src="https://nerdy.dev/favicon.svg" alt aria-hidden no-view sizing="both"><!--]-->nerdy.dev<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/towardsdatascience.com/" aria-label="towardsdatascience.com"><!--[--><img class="vp-icon" src="https://cdn-images-1.medium.com/v2/resize:fill:128:128/1*VzTUkfeGymHP4Bvav-T-lA.png" alt aria-hidden no-view sizing="both"><!--]-->towardsdatascience.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/douggregor.net/" aria-label="douggregor.net"><!--[--><i class="vp-icon fas fa-globe" sizing="both"></i><!--]-->douggregor.net<!----></a></li><li class="vp-dropdown-item"><a class="route-link route-link-active auto-link" href="/bookshelf/d2.naver.com/" aria-label="d2.naver.com"><!--[--><img class="vp-icon" src="/bookshelf/assets/image/d2.naver.com/favicon.ico" alt aria-hidden no-view sizing="both"><!--]-->d2.naver.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/tech.kakao.com/" aria-label="tech.kakao.com"><!--[--><img class="vp-icon" src="https://www.kakaocorp.com/page/favicon.ico" alt aria-hidden no-view sizing="both"><!--]-->tech.kakao.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/tech.kakaopay.com/" aria-label="tech.kakaopay.com"><!--[--><img class="vp-icon" src="https://tech.kakaopay.com/favicon.ico" alt aria-hidden no-view sizing="both"><!--]-->tech.kakaopay.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/fe-developers.kakaoent.com/" aria-label="fe-developers.kakaoent.com"><!--[--><img class="vp-icon" src="https://fe-developers.kakaoent.com/favicon-32x32.png?v=44803cb16c1e2debd3984cf2e8cb2ded" alt aria-hidden no-view sizing="both"><!--]-->fe-developers.kakaoent.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/yozm.wishket.com/" aria-label="yozm.wishket.com"><!--[--><img class="vp-icon" src="https://yozm.wishket.com/favicon.ico" alt aria-hidden no-view sizing="both"><!--]-->yozm.wishket.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/popit.kr/" aria-label="popit.kr"><!--[--><img class="vp-icon" src="https://popit.kr/wp-content/uploads/2016/08/favicon_32x32.png" alt aria-hidden no-view sizing="both"><!--]-->popit.kr<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/devkuma.com/" aria-label="devkuma.com"><!--[--><img class="vp-icon" src="https://devkuma.com/favicons/favicon.ico" alt aria-hidden no-view sizing="both"><!--]-->devkuma.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/blog.gangnamunni.com/" aria-label="blog.gangnamunni.com"><!--[--><img class="vp-icon" src="https://blog.gangnamunni.com/favicon.ico" alt aria-hidden no-view sizing="both"><!--]-->blog.gangnamunni.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/codingeverybody.kr/" aria-label="codingeverybody.kr"><!--[--><img class="vp-icon" src="https://codingeverybody.kr/wp-content/uploads/cropped-favicon-origin-192x192.png" alt aria-hidden no-view sizing="both"><!--]-->codingeverybody.kr<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label><!--[--><i class="vp-icon fas fa-network-wired" sizing="height"></i><!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/tecmint.com/" aria-label="tecmint.com"><!--[--><img class="vp-icon" src="https://tecmint.com/wp-content/uploads/2020/07/favicon.ico" alt aria-hidden no-view sizing="both"><!--]-->tecmint.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/docker.com/" aria-label="docker.com"><!--[--><img class="vp-icon" src="https://docker.com/app/uploads/2024/02/cropped-docker-logo-favicon-192x192.png" alt aria-hidden no-view sizing="both"><!--]-->docker.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/learnkube.com/" aria-label="learnkube.com"><!--[--><img class="vp-icon" src="https://static.learnkube.com/f7e5160d4744cf05c46161170b5c11c9.svg" alt aria-hidden no-view sizing="both"><!--]-->learnkube.com<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/bookshelf/itsfoss.com/" aria-label="itsfoss.com"><!--[--><img class="vp-icon" src="https://itsfoss.com/content/images/size/w256h256/2022/12/android-chrome-192x192.png" alt aria-hidden no-view sizing="both"><!--]-->itsfoss.com<!----></a></li></ul></button></div></div></nav><!--]--></div><div class="vp-navbar-end"><!--[--><!----><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/chanhi2000/bookshelf" target="_blank" rel="noopener noreferrer" aria-label="Github"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><!----></div><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><img class="vp-icon" src="/bookshelf/assets/image/d2.naver.com/favicon.ico" alt aria-hidden no-view sizing="both"><span class="vp-sidebar-title">d2.naver.com</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">2025</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">2024</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">2023</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/bookshelf/d2.naver.com/6445508.html" aria-label="HDFS 쓰기 파이프라인을 활용한 HBase의 WAL 쓰기 최적화"><!--[--><i class="vp-icon fa-brands fa-java" sizing="both"></i><!--]-->HDFS 쓰기 파이프라인을 활용한 HBase의 WAL 쓰기 최적화<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">2022</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">2021</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">2020</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">2019</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">2018</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">2017</span><span class="vp-arrow end"></span></button><!----></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/bookshelf/d2.naver.com/1329.html" aria-label="Java Garbage Collection"><!--[--><i class="vp-icon fa-brands fa-java" sizing="both"></i><!--]-->Java Garbage Collection<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/bookshelf/d2.naver.com/1336.html" aria-label="WebSocket과 Socket.io"><!--[--><i class="vp-icon fa-brands fa-java" sizing="both"></i><!--]-->WebSocket과 Socket.io<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/bookshelf/d2.naver.com/1341.html" aria-label="Spring-Test-MVC 프로젝트 소개"><!--[--><i class="vp-icon iconfont icon-spring" sizing="both"></i><!--]-->Spring-Test-MVC 프로젝트 소개<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/bookshelf/d2.naver.com/994.html" aria-label="AMIGO - 행위 기반 악성코드 탐지"><!--[--><i class="vp-icon fas fa-shield-halved" sizing="both"></i><!--]-->AMIGO - 행위 기반 악성코드 탐지<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/bookshelf/d2.naver.com/1011.html" aria-label="Git vs. Mercurial"><!--[--><i class="vp-icon iconfont icon-git" sizing="both"></i><!--]-->Git vs. Mercurial<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/bookshelf/d2.naver.com/1016.html" aria-label="Hadoop과 MongoDB를 이용한 로그분석시스템"><!--[--><i class="vp-icon iconfont icon-hadoop" sizing="both"></i><!--]-->Hadoop과 MongoDB를 이용한 로그분석시스템<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/bookshelf/d2.naver.com/1039.html" aria-label="NoSQL 가용성과 운영 안정성"><!--[--><i class="vp-icon iconfont icon-apachecassandra" sizing="both"></i><!--]-->NoSQL 가용성과 운영 안정성<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/bookshelf/d2.naver.com/1042.html" aria-label="분산 고속 저장소 nStore"><!--[--><i class="vp-icon fas fa-database" sizing="both"></i><!--]-->분산 고속 저장소 nStore<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/bookshelf/d2.naver.com/1052.html" aria-label="RTCS 실시간 웹 서비스를 위한 도전"><!--[--><i class="vp-icon fa-brands fa-js" sizing="both"></i><!--]-->RTCS 실시간 웹 서비스를 위한 도전<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/bookshelf/d2.naver.com/1062.html" aria-label="uMon의 이해"><!--[--><i class="vp-icon fas fa-pen-ruler" sizing="both"></i><!--]-->uMon의 이해<!----></a></li></ul></section></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><div class="page-cover"><img src="/bookshelf/assets/image/d2.naver.com/6445508/banner.png" alt no-view></div><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><i class="vp-icon fa-brands fa-java" sizing="height"></i>HDFS 쓰기 파이프라인을 활용한 HBase의 WAL 쓰기 최적화</h1><div class="page-info"><!----><!----><span class="page-date-info" aria-label="Writing Date📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">23. 12. 19.</span><meta property="datePublished" content="2023-12-19T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="Reading Time⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 6 min</span><meta property="timeRequired" content="PT6M"></span><span class="page-category-info" aria-label="Category🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item color8" role>Java</span><span class="page-category-item color0" role>Hadoop</span><span class="page-category-item color8" role>Article(s)</span><!--]--><meta property="articleSection" content="Java,Hadoop,Article(s)"></span><span class="page-tag-info" aria-label="Tag🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon" name="tag"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item color8" role>blog</span><span class="page-tag-item color8" role>d2.naver.com</span><span class="page-tag-item color8" role>java</span><span class="page-tag-item color6" role>hadoop</span><span class="page-tag-item color4" role>hdfs</span><span class="page-tag-item color0" role>hbase</span><span class="page-tag-item color0" role>protobuf</span><!--]--><meta property="keywords" content="blog,d2.naver.com,java,hadoop,hdfs,hbase,protobuf"></span></div><hr></div><!----><div class="" vp-content><!----><div id="markdown-content"><h1 id="frontmatter-title-관련" tabindex="-1"><a class="header-anchor" href="#frontmatter-title-관련"><span>HDFS 쓰기 파이프라인을 활용한 HBase의 WAL 쓰기 최적화 관련</span></a></h1><a class="route-link vp-card" href="/bookshelf/programming/java/articles/" style="background:rgba(10,10,10,0.2);"><img class="vp-card-logo" src="https://chanhi2000.github.io/images/ico-wind.svg" loading="lazy" no-view><div class="vp-card-content"><div class="vp-card-title">Java > Article(s)</div><hr><div class="vp-card-desc">Article(s)</div></div></a><a class="route-link vp-card" href="/bookshelf/data-science/hadoop/articles/" style="background:rgba(10,10,10,0.2);"><img class="vp-card-logo" src="https://chanhi2000.github.io/images/ico-wind.svg" loading="lazy" no-view><div class="vp-card-content"><div class="vp-card-title">Hadoop > Article(s)</div><hr><div class="vp-card-desc">Article(s)</div></div></a><nav class="table-of-contents"><ul><li><a aria-current="page" href="/bookshelf/d2.naver.com/6445508.html#파이프라인-복구-실패로-인한-장애-상황" class="router-link-active router-link-exact-active">파이프라인 복구 실패로 인한 장애 상황</a></li><li><a aria-current="page" href="/bookshelf/d2.naver.com/6445508.html#hdfs-쓰기-파이프라인" class="router-link-active router-link-exact-active">HDFS 쓰기 파이프라인</a><ul><li><a aria-current="page" href="/bookshelf/d2.naver.com/6445508.html#새로운-파일-항목-생성" class="router-link-active router-link-exact-active">새로운 파일 항목 생성</a></li><li><a aria-current="page" href="/bookshelf/d2.naver.com/6445508.html#datanode-할당" class="router-link-active router-link-exact-active">DataNode 할당</a></li><li><a aria-current="page" href="/bookshelf/d2.naver.com/6445508.html#파이프라인-구성-및-데이터-쓰기" class="router-link-active router-link-exact-active">파이프라인 구성 및 데이터 쓰기</a></li><li><a aria-current="page" href="/bookshelf/d2.naver.com/6445508.html#hdfs-쓰기-파이프라인의-특징" class="router-link-active router-link-exact-active">HDFS 쓰기 파이프라인의 특징</a></li></ul></li><li><a aria-current="page" href="/bookshelf/d2.naver.com/6445508.html#fan-out-dfsoutputstream를-통한-wal-쓰기-최적화" class="router-link-active router-link-exact-active">Fan-out DFSOutputStream를 통한 WAL 쓰기 최적화</a></li><li><a aria-current="page" href="/bookshelf/d2.naver.com/6445508.html#마치며" class="router-link-active router-link-exact-active">마치며</a></li><li><a aria-current="page" href="/bookshelf/d2.naver.com/6445508.html#참고-자료" class="router-link-active router-link-exact-active">참고 자료</a></li></ul></nav><hr><div class="vp-site-info" data-name="HDFS 쓰기 파이프라인을 활용한 HBase의 WAL 쓰기 최적화 | NAVER D2"><a class="vp-site-info-navigator no-external-link-icon" title="HDFS 쓰기 파이프라인을 활용한 HBase의 WAL 쓰기 최적화 | NAVER D2" href="https://d2.naver.com/helloworld/6445508" target="_blank"></a><div class="vp-site-info-preview" style="background:url(/bookshelf/assets/image/d2.naver.com/6445508/banner.png) center/cover no-repeat;"></div><div class="vp-site-info-detail"><img class="vp-site-info-logo" src="/assets/image/d2.naver.com/favicon.ico" alt loading="lazy" no-view><div class="vp-site-info-name">HDFS 쓰기 파이프라인을 활용한 HBase의 WAL 쓰기 최적화 | NAVER D2</div><div class="vp-site-info-desc">HDFS 쓰기 파이프라인을 활용한 HBase의 WAL 쓰기 최적화</div></div><!----></div><!-- 
https://tv.naver.com/embed/48598255?autoPlay=true
--><p>네이버 검색에서는 검색 서비스 제공에 필요한 대규모 데이터를 HBase 기반의 데이터 저장소인 <a href="https://deview.kr/2017/schedule/188" target="_blank" rel="noopener noreferrer"><i class="vp-icon fas fa-globe" sizing="height"></i>Cuve</a>에 저장하고 있습니다. HBase는 Java 기반의 오픈 소스 NoSQL 분산 데이터베이스입니다. HDFS와 함께 사용되며 내구성(durability)과 지속성(persistence)을 보장합니다. 지연 시간이 매우 짧고 거의 실시간에 가까운 랜덤 읽기와 랜덤 쓰기를 지원합니다.</p><p>HBase 쓰기 경로는 다음과 같습니다.</p><figure><img src="/bookshelf/assets/image/d2.naver.com/6445508/1.png" alt="그림 1 HBase 쓰기 경로(원본 출처: &lt;VPIcon icon=&quot;fas fa-globe&quot;/&gt;Apache HBase Write Path)" tabindex="0" loading="lazy"><figcaption>그림 1 HBase 쓰기 경로(원본 출처: <a href="https://blog.cloudera.com/apache-hbase-write-path" target="_blank" rel="noopener noreferrer"><i class="vp-icon fas fa-globe" sizing="height"></i>Apache HBase Write Path</a>)</figcaption></figure><p>HBase는 쓰기 요청을 처리할 때 HDFS에 데이터를 바로 쓰지 않고 RegionServer의 MemStore라고 불리는 메모리 영역에 데이터를 먼저 저장합니다. MemStore에 저장된 데이터는 Flush 과정을 통해서 주기적으로 HDFS에 저장됩니다. HDFS에 데이터를 저장하기 전에 서버에 장애가 발생한다면 메모리 영역인 MemStore에 저장된 데이터는 유실될 수 있습니다. HBase는 데이터 유실을 방지하기 위해 WAL(Write-Ahead Log)에 모든 변경 사항을 기록합니다.</p><p>WAL은 MySQL의 BIN 로그와 비슷하게 모든 변경 사항을 로그에 기록하여 데이터 내구성을 보장하는 방법입니다. 변경 사항은 일반적으로 영구적인 데이터 저장 장치(예: HDD, SSD 등)에 저장하는데 HBase는 HDFS에 저장합니다. 서버에 장애가 발생하여 메모리의 모든 데이터가 유실되어도 WAL을 이용해 복구할 수 있습니다.</p><p>HBase 버전 1에서는 HDFS가 제공하는 <code>DFSOutputStream</code>을 통해서 WAL 데이터를 HDFS에 저장했습니다. 하지만 HDFS 쓰기 파이프라인을 따라 데이터가 3개의 DataNode에 쓰이다 보니 지연 시간이 증가하는 문제와 WAL 데이터를 쓰는 과정에서 오류가 발생했을 때 파이프라인 복구 실패로 인해 사용자 요청 처리가 지연되는 문제가 있었습니다. Cuve에서도 HBase 버전 1 클러스터에서 WAL 데이터 쓰기 파이프라인 복구 실패로 사용자의 요청을 처리하지 못하여 SLA를 위반하는 장애가 발생했었습니다. HBase 버전 2에서는 HBase에 WAL 쓰기 전용 Fan-out DFSOutputStream이 구현되어 이러한 문제가 해결되었습니다.</p><p>이 글에서는 Cuve에서 HBase 버전 1 기반으로 운영하던 HBase 클러스터에서 어떤 오류가 발생했는지 알아보고 HDFS 쓰기 파이프라인과 HBase의 Fan-out DFSOutputStream에서 HDFS 프로토콜을 어떻게 활용했는지 알아보겠습니다.</p><p>이 글은 HDFS와 HBase에 대한 기본적인 개념과 사용법에 익숙하다고 가정하고 있습니다. HDFS와 HBase의 구성 요소와 특징은 Hadoop 문서 <a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html" target="_blank" rel="noopener noreferrer"><i class="vp-icon iconfont icon-hadoop" sizing="height"></i>HDFS Architecture</a>와 HBase 문서 <a href="https://hbase.apache.org/book.html#arch.overview" target="_blank" rel="noopener noreferrer"><i class="vp-icon iconfont icon-hadoop" sizing="height"></i>Architecture Overview</a>를 참고하기 바랍니다.</p><hr><h2 id="파이프라인-복구-실패로-인한-장애-상황" tabindex="-1"><a class="header-anchor" href="#파이프라인-복구-실패로-인한-장애-상황"><span>파이프라인 복구 실패로 인한 장애 상황</span></a></h2><p>HBase 버전 1의 RegionServer는 HDFS가 제공하는 <code>DFSOutputStream</code>을 통해 WAL 데이터를 쓴다. HDFS 클라이언트는 데이터를 쓰다가 DataNode에서 오류가 발생하면 클라이언트가 파일에 데이터를 계속 쓸 수 있도록 파이프라인을 복구한다. 네트워크 상태가 좋지 않거나 DataNode의 디스크가 고장 나는 경우 DataNode에서 오류가 발생할 수 있다.</p><p>WAL 데이터를 쓰는 도중 DataNode에 오류가 발생하면 파이프라인 복구가 시작되는데, 파이프라인 복구가 실패하여 RegionServer가 사용자의 요청을 처리하지 못하는 현상이 발생했었다. 파이프라인 복구에 실패했을 때 어떤 현상이 발생하는지 Cuve 사례를 통해 알아보겠다.</p><p>Cuve에서 운영하던 HBase 버전 1 클러스터의 RegionServer에서 WAL 데이터를 쓰는 도중 아래 RegionServer 오류 로그같이 <code>IOException</code> 오류가 발생했었다.</p><blockquote><p>RegionServer 오류 로그</p></blockquote><div class="language-yaml line-numbers-mode" data-highlighter="prismjs" data-ext="yml"><pre><code class="language-yaml"><span class="line">2023<span class="token punctuation">-</span>XX<span class="token punctuation">-</span>XX XX<span class="token punctuation">:</span>XX<span class="token punctuation">:</span>XX<span class="token punctuation">,</span>XXX WARN  <span class="token punctuation">[</span>DataStreamer for file <span class="token punctuation">...</span><span class="token punctuation">:</span>blk_<span class="token punctuation">...</span><span class="token punctuation">]</span> hdfs.DFSClient<span class="token punctuation">:</span> DataStreamer Exception  </span>
<span class="line"><span class="token key atrule">java.io.IOException</span><span class="token punctuation">:</span> Broken pipe  </span>
<span class="line">        at org.apache.hadoop.hdfs.DFSPacket.writeTo(DFSPacket.java)</span>
<span class="line">        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java)</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>파이프라인에서 오류가 발생하면 파이프라인 복구를 위해 오류가 발생한 DataNode는 파이프라인에서 제외되는데, 위와 같이 <code>OutputStream</code>에 데이터를 쓸 때 오류가 발생한 경우 오류가 발생한 DataNode를 식별할 수 없다. HDFS 클라이언트는 <code>OutputStream</code>에 데이터를 쓸 때 오류가 발생하면 아래 <code>DFSOutputStream</code> 코드 일부와 같이 <code>tryMarkPrimaryDatanodeFailed()</code> 메서드를 호출한다.</p><p><code>DFSOutputStream</code> 코드 일부</p><div class="language-java line-numbers-mode" data-highlighter="prismjs" data-ext="java"><pre><code class="language-java"><span class="line"><span class="token keyword">try</span> <span class="token punctuation">{</span>  </span>
<span class="line">  one<span class="token punctuation">.</span><span class="token function">writeTo</span><span class="token punctuation">(</span>blockStream<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// IOException이 발생한 위치</span></span>
<span class="line">  blockStream<span class="token punctuation">.</span><span class="token function">flush</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line"><span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">IOException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span></span>
<span class="line">  <span class="token function">tryMarkPrimaryDatanodeFailed</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line">  <span class="token keyword">throw</span> e<span class="token punctuation">;</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><code>tryMarkPrimaryDatanodeFailed()</code> 메서드는 아래 <code>tryMarkPrimaryDatanodeFailed</code> 메서드 구현 내용과 같이 오류가 발생한 DataNode가 식별되지 않은 경우 항상 파이프라인의 첫 번째 DataNode를 오류가 발생한 DataNode로 설정한다. 그 이유는 클라이언트에서 오류가 발생했을 때 <code>errorIndex</code>가 없으면 DataNode 오류가 아닌 클라이언트의 오류로 취급되는데, 클라이언트 오류로 취급되면 더 이상 재시도하지 않고 클라이언트가 종료될 수 있기 때문이다. <code>OutputStream</code>에서 데이터를 쓰다가 발생한 오류는 클라이언트 오류가 아닌 DataNode 오류이기 때문에, 오류가 발생한 DataNode가 식별되지 않은 경우 첫 번째 DataNode를 오류가 발생한 DataNode로 설정함으로써 오류가 DataNode 오류로 처리되고 파이프라인을 복구하게 한다.</p><p><code>tryMarkPrimaryDatanodeFailed</code> 메서드 구현 내용</p><div class="language-java line-numbers-mode" data-highlighter="prismjs" data-ext="java"><pre><code class="language-java"><span class="line"><span class="token keyword">synchronized</span> <span class="token keyword">void</span> <span class="token function">tryMarkPrimaryDatanodeFailed</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>  </span>
<span class="line">  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>errorIndex <span class="token operator">==</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span> <span class="token punctuation">(</span>restartingNodeIndex<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span></span>
<span class="line">    errorIndex <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> <span class="token comment">// errorIndex = 오류가 발생한 DataNode의 인덱스</span></span>
<span class="line">  <span class="token punctuation">}</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><code>tryMarkPrimaryDatanodeFailed()</code> 메서드에 의해 첫 번째 DataNode를 오류가 발생한 DataNode로 인식한 HDFS 클라이언트는 파이프라인 복구를 위해 첫 번째 DataNode를 제외하고 새 파이프라인을 구성하려고 시도했다.</p><p>첫 번째 DataNode를 오류가 발생한 DataNode로 인식한 로그</p><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text"><pre><code class="language-text"><span class="line">Error Recovery for block ... in pipeline DatanodeInfoWithStorage[...], DatanodeInfoWithStorage[...], DatanodeInfoWithStorage[...]: datanode 0(DatanodeInfoWithStorage[...]) is bad.  </span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>하지만 파이프라인 구성에 실패했다. 이후 계속해서 파이프라인 복구를 다시 시도했지만 파이프라인 복구에 성공하지 못했다. 계속된 파이프라인 복구 실패로 인해 해당 RegionServer는 그림 2와 같이 RPC Handler가 꽉 차서 사용자의 요청을 제대로 처리하지 못했다.</p><figure><img src="/bookshelf/assets/image/d2.naver.com/6445508/2.png" alt="그림 2 장애 상황 일 때  지표" tabindex="0" loading="lazy"><figcaption>그림 2 장애 상황 일 때 <code>hbase.regionserver.ipc.numActiveHandler</code> 지표</figcaption></figure><p>장애 상황 이후 NameNode, DataNode, RegionServer의 로그를 확인해 보니 실제 오류가 발생했던 DataNode는 파이프라인의 마지막 DataNode였다. 오류가 발생한 DataNode를 잘못 식별하여 파이프라인 복구가 계속 실패했던 것으로 추정된다.</p><p>위와 같은 오류가 발생하면 운영자가 개입하여 해당 RegionServer를 재시작해야 오류가 해결되었다. 매번 운영자가 개입할 수 없기 때문에 자동화 처리도 했지만 근본적인 문제 해결은 아니었다. 따라서 장애 상황에 대한 이해를 높이고 해결 방법을 모색하고자 HDFS 쓰기 파이프라인과 동일한 문제가 상위 버전에서는 혹시 해결되었는지 알아보았다.</p><hr><h2 id="hdfs-쓰기-파이프라인" tabindex="-1"><a class="header-anchor" href="#hdfs-쓰기-파이프라인"><span>HDFS 쓰기 파이프라인</span></a></h2><p>HDFS는 Hadoop의 기본(default) 파일 시스템이다. HDFS는 파일을 블록(Block)으로 나누어 DataNode에 저장하고 메타데이터는 NameNode에 저장한다. 데이터의 내결함성(fault tolerance)을 제공하기 위해 블록은 여러 DataNode에 복제되는데, 복제본의 수를 Replication Factor라고 하며 기본값은 3이다. DataNode에 물리적으로 저장된 블록은 Replica라고 부른다.</p><p>Replica에는 다음과 같은 5가지 상태가 존재한다.</p><div class="vp-tabs"><div class="vp-tabs-nav" role="tablist"><button type="button" class="vp-tab-nav active" role="tab" aria-controls="v-0" aria-selected="true">Finalized</button><button type="button" class="vp-tab-nav" role="tab" aria-controls="v-1" aria-selected="false">RBW</button><button type="button" class="vp-tab-nav" role="tab" aria-controls="v-2" aria-selected="false">RWR</button><button type="button" class="vp-tab-nav" role="tab" aria-controls="v-3" aria-selected="false">RUR</button><button type="button" class="vp-tab-nav" role="tab" aria-controls="v-4" aria-selected="false">Temporary</button></div><!--[--><div class="vp-tab active" id="v-0" role="tabpanel" aria-expanded="true"><div class="vp-tab-title">Finalized</div><!--[--><ul><li>Replica의 데이터가 변경되지 않는 상태이다.</li><li>Append를 위해 다시 Replica를 열지 않으면, 새로운 데이터가 Replica에 기록되지 않는다.</li><li>Generation stamp(단조롭게 증가하는 숫자로, 블록의 오래된 Replica를 감지하기 위한 용도)가 동일한 Finalized Replica는 동일한 데이터를 가지고 있다.</li></ul><!--]--></div><div class="vp-tab" id="v-1" role="tabpanel" aria-expanded="false"><div class="vp-tab-title">RBW</div><!--[--><blockquote><p><strong>R</strong>eplica <strong>B</strong>eing <strong>W</strong>ritten to</p></blockquote><ul><li>생성되거나 Append에 의해 데이터가 쓰이고 있는 Replica이다.</li><li>열린 파일의 마지막 블록은 항상 RBW이다.</li></ul><!--]--></div><div class="vp-tab" id="v-2" role="tabpanel" aria-expanded="false"><div class="vp-tab-title">RWR</div><!--[--><blockquote><p><strong>R</strong>eplica <strong>W</strong>aiting to be <strong>R</strong>ecovered</p></blockquote><ul><li>DataNode가 죽었다가 다시 시작된 경우 모든 RBW Replica는 RWR 상태로 변경된다.</li><li>RWR Replica는 더 이상 쓸모가 없어져서 버려지거나 복구 과정에 참여한다.</li></ul><!--]--></div><div class="vp-tab" id="v-3" role="tabpanel" aria-expanded="false"><div class="vp-tab-title">RUR</div><!--[--><blockquote><p><strong>R</strong>eplica <strong>U</strong>nder <strong>R</strong>ecovery</p></blockquote><ul><li>복구 과정에 참여한 Replica이다.</li></ul><!--]--></div><div class="vp-tab" id="v-4" role="tabpanel" aria-expanded="false"><div class="vp-tab-title">Temporary</div><!--[--><ul><li>블록 복제(Replication 모니터나 Cluster Balancer에 의해 생성)를 위해 생성된 Replica이다.</li></ul><!--]--></div><!--]--></div><p>다음 그림은 HDFS 쓰기 파이프라인과 컴포넌트들이 서로 통신할 때 사용하는 프로토콜을 보여준다.</p><figure><img src="/bookshelf/assets/image/d2.naver.com/6445508/3.png" alt="HDFS 쓰기 파이프라인과 프로토콜" tabindex="0" loading="lazy"><figcaption>HDFS 쓰기 파이프라인과 프로토콜</figcaption></figure><p>컴포넌트들은 TCP/IP 위에 설계된 프로토콜을 사용해서 서로 통신한다. <a href="https://github.com/apache/hadoop/blob/1019dde65bcf12e05ef48ac71e84550d589e5d9a/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/ClientProtocol.java" target="_blank" rel="noopener noreferrer">Client Protocol (<i class="vp-icon iconfont icon-globe" sizing="height"></i><code>apache/hadoop</code>)</a>은 클라이언트와 NameNode 간의 통신을 위해 정의된 프로토콜이다. 클라이언트는 Client Protocol을 사용하여 새로운 파일을 만들거나 기존 파일을 관리(예: 블록 할당, 이름 변경, 삭제, 권한 설정 등)할 수 있다. 클라이언트가 데이터를 읽거나 쓰기 위해서는 DataNode와 통신을 해야 하는데 DataNode와 통신할 때는 <a href="https://github.com/apache/hadoop/blob/1019dde65bcf12e05ef48ac71e84550d589e5d9a/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/DataTransferProtocol.java" target="_blank" rel="noopener noreferrer">DataTransfer Protocol (<i class="vp-icon iconfont icon-globe" sizing="height"></i><code>apache/hadoop</code>)</a>을 사용한다. <a href="https://github.com/apache/hadoop/blob/1019dde65bcf12e05ef48ac71e84550d589e5d9a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.java" target="_blank" rel="noopener noreferrer">Datanode Protocol (<i class="vp-icon iconfont icon-github" sizing="height"></i><code>apache/hadoop</code>)</a>은 DataNode와 NameNode 간의 통신을 위해 정의된 프로토콜이다. DataNode에서 NameNode로 블록 리포트 등을 보낼 때 사용된다.</p><p>각 Protocol의 요청과 응답 데이터는 Protocol Buffer를 통해 직렬화, 역직렬화된다. Protocol Buffer는 구조화된 데이터를 직렬화, 역직렬화하는 방법을 제공한다. <code>.proto</code> 파일에 데이터가 어떻게 구조화되어 있는지 정의하고 Protobuf Compiler로 컴파일하면 데이터를 직렬화, 역직렬화할 수 있는 특수한 코드를 다양한 언어별로 생성할 수 있다. Protobuf Compiler가 생성한 코드를 사용하면 다양한 플랫폼과 언어에서 쉽게 데이터를 직렬화, 역직렬화가 가능하다.</p><blockquote><p>Protocol 별 주요 기능</p></blockquote><div class="vp-tabs"><div class="vp-tabs-nav" role="tablist"><button type="button" class="vp-tab-nav active" role="tab" aria-controls="v-5" aria-selected="true">Client Protocol</button><button type="button" class="vp-tab-nav" role="tab" aria-controls="v-6" aria-selected="false">DataTransfer Protocol</button><button type="button" class="vp-tab-nav" role="tab" aria-controls="v-7" aria-selected="false">DataNode Protocol</button></div><!--[--><div class="vp-tab active" id="v-5" role="tabpanel" aria-expanded="true"><div class="vp-tab-title">Client Protocol</div><!--[--><ul><li>파일 관련 <ul><li><code>create</code>: 네임스페이스에 새로운 파일 항목(Entry)을 만든다.</li><li><code>append</code>: 파일 끝에 추가한다.</li><li><code>setPermission</code>: 파일이나 디렉터리에 권한을 설정한다.</li><li><code>setOwner</code>: 경로(파일이나 디렉터리)에 소유자를 설정한다.</li><li><code>addBlock</code>: 쓰기를 위해 열려있는 파일에 블록을 쓰기 위해 호출한다. 새로운 블록과 블록을 복제할 DataNode를 할당받는다.</li><li><code>complete</code>: 클라이언트가 파일에 데이터 쓰기를 완료했을 때 호출한다.</li></ul></li><li>네임스페이스 관련 <ul><li><code>rename</code>: 네임스페이스의 파일이나 디렉터리 이름을 바꾼다.</li><li><code>delete</code>: 파일이나 디렉터리를 삭제한다.</li><li><code>mkdirs</code>: 새로운 디렉터리를 만든다.</li></ul></li><li>시스템 관련 <ul><li><code>renewLease</code>: 파일에 대한 변경 권한을 잃지 않기 위해 NameNode에 살아있다고 보고한다.</li><li><code>recoverLease</code>: Lease를 복구한다.</li></ul></li></ul><!--]--></div><div class="vp-tab" id="v-6" role="tabpanel" aria-expanded="false"><div class="vp-tab-title">DataTransfer Protocol</div><!--[--><ul><li><code>readBlock</code>: 블록을 읽는다.</li><li><code>writeBlock</code>: DataNode 파이프라인에 블록을 쓴다.</li></ul><!--]--></div><div class="vp-tab" id="v-7" role="tabpanel" aria-expanded="false"><div class="vp-tab-title">DataNode Protocol</div><!--[--><ul><li><code>registerDatanode</code>: DataNode를 등록한다.</li><li><code>sendHeartbeat</code>: NameNode에 DataNode가 살아있음을 알리기 위해 Heartbeat 요청을 보낸다.</li><li><code>blockReport</code>: 블록 리포트를 보낸다.</li></ul><!--]--></div><!--]--></div><h3 id="새로운-파일-항목-생성" tabindex="-1"><a class="header-anchor" href="#새로운-파일-항목-생성"><span>새로운 파일 항목 생성</span></a></h3><p>클라이언트가 HDFS에 새로운 파일을 생성하여 데이터를 쓰기 위해서는 먼저 네임스페이스에 새로운 파일 항목을 만들어야 한다. 새로운 파일 항목을 만들기 위해 클라이언트는 NameNode에 <code>create</code> 요청(그림 3의 1)을 보낸다.</p><blockquote><p><a href="https://github.com/apache/hadoop/blob/1e877761e8dadd71effef30e592368f7fe66a61b/hadoop-hdfs-project/hadoop-hdfs-client/src/main/proto/ClientNamenodeProtocol.proto#L75" target="_blank" rel="noopener noreferrer"><code>create</code> 요청 (<i class="vp-icon iconfont icon-github" sizing="height"></i><code>apache/hadoop</code>)</a> 예</p></blockquote><div class="language-protobuf line-numbers-mode" data-highlighter="prismjs" data-ext="protobuf"><pre><code class="language-protobuf"><span class="line"><span class="token keyword">message</span> <span class="token class-name">CreateRequestProto</span> <span class="token punctuation">{</span>  </span>
<span class="line">  <span class="token comment">// 파일 경로</span></span>
<span class="line">  src<span class="token punctuation">:</span> <span class="token string">&quot;/test_dir/file.txt&quot;</span></span>
<span class="line">  <span class="token comment">// 클라이언트명</span></span>
<span class="line">  clientName<span class="token punctuation">:</span> <span class="token string">&quot;DFSClient_...&quot;</span></span>
<span class="line">  <span class="token comment">// File create semantic (CreateFlag)</span></span>
<span class="line">  createFlag<span class="token punctuation">:</span> <span class="token number">3</span></span>
<span class="line">  <span class="token comment">// 부모 디렉터리 생성 여부</span></span>
<span class="line">  createParent<span class="token punctuation">:</span> <span class="token boolean">true</span></span>
<span class="line">  <span class="token comment">// block replication factor (dfs.replication)</span></span>
<span class="line">  replication<span class="token punctuation">:</span> <span class="token number">3</span></span>
<span class="line">  <span class="token comment">// maximum block size (dfs.blocksize)</span></span>
<span class="line">  blockSize<span class="token punctuation">:</span> <span class="token number">5242880</span></span>
<span class="line">  <span class="token comment">// Crypto protocol version</span></span>
<span class="line">  cryptoProtocolVersion<span class="token punctuation">:</span> ENCRYPTION_ZONES</span>
<span class="line">  <span class="token comment">// Permision</span></span>
<span class="line">  masked <span class="token punctuation">{</span></span>
<span class="line">    perm<span class="token punctuation">:</span> <span class="token number">420</span></span>
<span class="line">  <span class="token punctuation">}</span></span>
<span class="line">  unmasked <span class="token punctuation">{</span></span>
<span class="line">    perm<span class="token punctuation">:</span> <span class="token number">438</span></span>
<span class="line">  <span class="token punctuation">}</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>NameNode는 <code>fileId</code>(Inode ID)가 포함된 파일 상태 정보를 클라이언트에게 응답으로 보낸다.</p><blockquote><p><a href="https://github.com/apache/hadoop/blob/1e877761e8dadd71effef30e592368f7fe66a61b/hadoop-hdfs-project/hadoop-hdfs-client/src/main/proto/ClientNamenodeProtocol.proto#L88" target="_blank" rel="noopener noreferrer"><code>create</code> 응답 (<i class="vp-icon iconfont icon-github" sizing="height"></i><code>apache/hadoop</code>)</a> 예</p></blockquote><div class="language-protobuf line-numbers-mode" data-highlighter="prismjs" data-ext="protobuf"><pre><code class="language-protobuf"><span class="line"><span class="token keyword">message</span> <span class="token class-name">CreateResponseProto</span> <span class="token punctuation">{</span>  </span>
<span class="line">  <span class="token comment">// 파일 상태</span></span>
<span class="line">  fs<span class="token punctuation">:</span> <span class="token keyword">message</span> <span class="token class-name">HdfsFileStatusProto</span> <span class="token punctuation">{</span></span>
<span class="line">    fileType<span class="token punctuation">:</span> IS_FILE</span>
<span class="line">    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span></span>
<span class="line">    owner<span class="token punctuation">:</span> <span class="token string">&quot;owner&quot;</span></span>
<span class="line">    group<span class="token punctuation">:</span> <span class="token string">&quot;group&quot;</span></span>
<span class="line">    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span></span>
<span class="line">    block_replication<span class="token punctuation">:</span> <span class="token number">3</span></span>
<span class="line">    blocksize<span class="token punctuation">:</span> <span class="token number">5242880</span></span>
<span class="line">    <span class="token comment">// Inode ID</span></span>
<span class="line">    fileId<span class="token punctuation">:</span> <span class="token number">17434</span></span>
<span class="line">  <span class="token punctuation">}</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="datanode-할당" tabindex="-1"><a class="header-anchor" href="#datanode-할당"><span>DataNode 할당</span></a></h3><p>NameNode로부터 <code>create</code> 응답을 받은 후 클라이언트는 데이터를 쓸 DataNode를 할당받아야 한다. 클라이언트는 DataNode를 할당받기 위해 NameNode에 <code>addBlock</code> 요청(그림 3의 2)을 보낸다. 클라이언트는 <code>addBlock</code> 요청 시 <code>create</code> 응답으로 받았던 <code>fileId</code>(Inode ID)와 블록 할당을 위한 힌트 정보를 보낸다.</p><blockquote><p><a href="https://github.com/apache/hadoop/blob/1e877761e8dadd71effef30e592368f7fe66a61b/hadoop-hdfs-project/hadoop-hdfs-client/src/main/proto/ClientNamenodeProtocol.proto#L174" target="_blank" rel="noopener noreferrer"><code>addBlock</code> 요청 (<i class="vp-icon iconfont icon-github" sizing="height"></i><code>apache/hadoop</code>)</a> 예</p></blockquote><div class="language-protobuf line-numbers-mode" data-highlighter="prismjs" data-ext="protobuf"><pre><code class="language-protobuf"><span class="line"><span class="token keyword">message</span> <span class="token class-name">AddBlockRequestProto</span> <span class="token punctuation">{</span>  </span>
<span class="line">  <span class="token comment">// 파일 경로</span></span>
<span class="line">  src<span class="token punctuation">:</span> <span class="token string">&quot;/test_dir/file.txt&quot;</span></span>
<span class="line">  <span class="token comment">// 클라이언트명</span></span>
<span class="line">  clientName<span class="token punctuation">:</span> <span class="token string">&quot;DFSClient_...&quot;</span></span>
<span class="line">  <span class="token comment">// 블록 할당 시 제외하고 싶은 노드</span></span>
<span class="line">  excludeNodes<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></span>
<span class="line">  <span class="token comment">// Inode ID</span></span>
<span class="line">  fileId<span class="token punctuation">:</span> <span class="token number">17434</span></span>
<span class="line">  <span class="token comment">// 클라이언트가 선호하는 노드</span></span>
<span class="line">  favoredNodes<span class="token punctuation">:</span> <span class="token string">&quot;&quot;</span></span>
<span class="line">  <span class="token comment">// 블록 할당에 대한 힌트(AddBlockFlag)</span></span>
<span class="line">  flags<span class="token punctuation">:</span> <span class="token string">&quot;&quot;</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>NameNode는 <code>addBlock</code> 응답으로 클라이언트에 블록 정보와 파이프라인 대상 DataNode 정보를 보낸다.</p><blockquote><p><a href="https://github.com/apache/hadoop/blob/1e877761e8dadd71effef30e592368f7fe66a61b/hadoop-hdfs-project/hadoop-hdfs-client/src/main/proto/ClientNamenodeProtocol.proto#L184" target="_blank" rel="noopener noreferrer"><code>addBlock</code> 응답 (<i class="vp-icon iconfont icon-github" sizing="height"></i><code>apache/hadoop</code>)</a> 예</p></blockquote><div class="language-protobuf line-numbers-mode" data-highlighter="prismjs" data-ext="protobuf"><pre><code class="language-protobuf"><span class="line"><span class="token keyword">message</span> <span class="token class-name">AddBlockResponseProto</span> <span class="token punctuation">{</span>  </span>
<span class="line">  block<span class="token punctuation">:</span> <span class="token keyword">message</span> <span class="token class-name">LocatedBlockProto</span> <span class="token punctuation">{</span></span>
<span class="line">    <span class="token comment">// 블록 정보</span></span>
<span class="line">    b<span class="token punctuation">:</span> <span class="token keyword">message</span> <span class="token class-name">ExtendedBlockProto</span> <span class="token punctuation">{</span></span>
<span class="line">      <span class="token comment">// Block Pool ID</span></span>
<span class="line">      poolId<span class="token punctuation">:</span> <span class="token string">&quot;BP-...&quot;</span></span>
<span class="line">      <span class="token comment">// Block ID</span></span>
<span class="line">      blockId<span class="token punctuation">:</span> <span class="token number">1073742133</span></span>
<span class="line">      generationStamp<span class="token punctuation">:</span> <span class="token number">1309</span></span>
<span class="line">      numBytes<span class="token punctuation">:</span> <span class="token number">0</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">    <span class="token comment">// 파일에서 블록의 첫 번째 바이트 오프셋</span></span>
<span class="line">    offset<span class="token punctuation">:</span> <span class="token number">0</span></span>
<span class="line">    <span class="token comment">// 파이프라인 대상 DataNode 정보</span></span>
<span class="line">    locs<span class="token punctuation">:</span> <span class="token punctuation">[</span>DatanodeInfoProto<span class="token punctuation">,</span> DatanodeInfoProto<span class="token punctuation">,</span> <span class="token keyword">message</span> <span class="token class-name">DatanodeInfoProto</span> <span class="token punctuation">{</span></span>
<span class="line">      <span class="token comment">// DataNode IP 주소, 호스트명, 포트 정보</span></span>
<span class="line">      id<span class="token punctuation">:</span> <span class="token keyword">message</span> <span class="token class-name">DatanodeIDProto</span> <span class="token punctuation">{</span></span>
<span class="line">        ipAddr<span class="token punctuation">:</span> <span class="token string">&quot;x.x.x.x&quot;</span></span>
<span class="line">        hostName<span class="token punctuation">:</span> <span class="token string">&quot;example&quot;</span></span>
<span class="line">        datanodeUuid<span class="token punctuation">:</span> <span class="token string">&quot;...&quot;</span></span>
<span class="line">        xferPort<span class="token punctuation">:</span> <span class="token number">0</span></span>
<span class="line">        infoPort<span class="token punctuation">:</span> <span class="token number">0</span></span>
<span class="line">        ipcPort<span class="token punctuation">:</span> <span class="token number">0</span></span>
<span class="line">        infoSecurePort<span class="token punctuation">:</span> <span class="token number">0</span></span>
<span class="line">      <span class="token punctuation">}</span></span>
<span class="line">      <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span></span>
<span class="line">    <span class="token punctuation">}</span><span class="token punctuation">]</span></span>
<span class="line">    storageTypes<span class="token punctuation">:</span> <span class="token punctuation">[</span>DISK<span class="token punctuation">,</span> DISK<span class="token punctuation">,</span> DISK<span class="token punctuation">]</span></span>
<span class="line">    storageIDs<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span></span>
<span class="line">    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span></span>
<span class="line">  <span class="token punctuation">}</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="파이프라인-구성-및-데이터-쓰기" tabindex="-1"><a class="header-anchor" href="#파이프라인-구성-및-데이터-쓰기"><span>파이프라인 구성 및 데이터 쓰기</span></a></h3><p>NameNode로부터 파이프라인 대상 DataNode 정보를 획득한 클라이언트는 데이터를 쓰기 위해 파이프라인 대상 DataNode들로 블록 생성 파이프라인을 구성하고 블록을 패킷(네트워크 패킷이 아니라 HDFS 데이터 쓰기에서 사용되는 클래스를 의미)으로 나누어 파이프라인의 DataNode에 데이터를 쓴다. 파이프라인을 구성하고 데이터를 쓰는 과정은 그림 4와 같이 3 단계로 이루어진다.</p><figure><img src="/bookshelf/assets/image/d2.naver.com/6445508/4.png" alt="그림 4 블록 생성 파이프라인 단계(원본 출처: HDFS &lt;VPIcon icon=&quot;iconfont icon-Apache&quot;/&gt;Append/Hflush/Read 디자인 문서)" tabindex="0" loading="lazy"><figcaption>그림 4 블록 생성 파이프라인 단계(원본 출처: HDFS <a href="https://issues.apache.org/jira/secure/attachment/12445209/appendDesign3.pdf" target="_blank" rel="noopener noreferrer"><i class="vp-icon iconfont icon-Apache" sizing="height"></i>Append/Hflush/Read 디자인 문서</a>)</figcaption></figure><h4 id="_1-단계-파이프라인-설정" tabindex="-1"><a class="header-anchor" href="#_1-단계-파이프라인-설정"><span>1 단계: 파이프라인 설정</span></a></h4><p>그림 4의 T0~T1은 파이프라인 설정 단계이다. 파이프라인을 따라 다운스트림 DataNode에게 <code>WRITE_BLOCK</code> 요청을 전송한다.(그림 3의 3)</p><blockquote><p><a href="https://github.com/apache/hadoop/blob/1e877761e8dadd71effef30e592368f7fe66a61b/hadoop-hdfs-project/hadoop-hdfs-client/src/main/proto/datatransfer.proto#L88" target="_blank" rel="noopener noreferrer"><code>writeBlock</code> 응답 (<i class="vp-icon iconfont icon-github" sizing="height"></i><code>apache/hadoop</code>)</a> 예</p></blockquote><div class="language-protobuf line-numbers-mode" data-highlighter="prismjs" data-ext="protobuf"><pre><code class="language-protobuf"><span class="line"><span class="token keyword">message</span> <span class="token class-name">OpWriteBlockProto</span> <span class="token punctuation">{</span>  </span>
<span class="line">  header<span class="token punctuation">:</span> <span class="token keyword">message</span> <span class="token class-name">ClientOperationHeaderProto</span> <span class="token punctuation">{</span></span>
<span class="line">    baseHeader<span class="token punctuation">:</span> <span class="token keyword">message</span> <span class="token class-name">ClientOperationHeaderProto</span> <span class="token punctuation">{</span></span>
<span class="line">      <span class="token comment">// 블록 정보</span></span>
<span class="line">      block<span class="token punctuation">:</span> <span class="token keyword">message</span> ExtendedBlockProto</span>
<span class="line">      <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">    <span class="token comment">// 클라이언트명</span></span>
<span class="line">    clientName<span class="token punctuation">:</span> <span class="token string">&quot;DFSClient_...&quot;</span></span>
<span class="line">  <span class="token punctuation">}</span></span>
<span class="line">  <span class="token comment">// 파이프라인 대상 DataNode 정보(IP 주소, 호스트명, 포트 정보, ...)</span></span>
<span class="line">  targets<span class="token punctuation">:</span> <span class="token punctuation">[</span>DatanodeInfoProto<span class="token punctuation">,</span> DatanodeInfoProto<span class="token punctuation">]</span></span>
<span class="line">  <span class="token comment">// 파이프라인 스테이지(BlockConstructionStage)</span></span>
<span class="line">  stage<span class="token punctuation">:</span> <span class="token function">PIPELINE_SETUP_CREATE</span><span class="token punctuation">(</span>블록 생성을 위한 파이프라인 설정<span class="token punctuation">)</span></span>
<span class="line">  <span class="token comment">// 파이프라인 크기</span></span>
<span class="line">  pipelineSize<span class="token punctuation">:</span> <span class="token number">3</span></span>
<span class="line">  <span class="token comment">// minimum number of bytes received.</span></span>
<span class="line">  minBytesRcvd<span class="token punctuation">:</span> <span class="token number">0</span></span>
<span class="line">  <span class="token comment">// maximum number of bytes received.</span></span>
<span class="line">  maxBytesRcvd<span class="token punctuation">:</span> <span class="token number">0</span></span>
<span class="line">  <span class="token comment">// 블록의 latest Generation Stamp</span></span>
<span class="line">  latestGenerationStamp<span class="token punctuation">:</span> <span class="token number">0</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>마지막 DataNode가 요청을 받은 후 파이프라인 업스트림으로 ACK가 전송된다.(그림 3의 4)</p><blockquote><p><a href="https://github.com/apache/hadoop/blob/1e877761e8dadd71effef30e592368f7fe66a61b/hadoop-hdfs-project/hadoop-hdfs-client/src/main/proto/datatransfer.proto#L288" target="_blank" rel="noopener noreferrer"><code>ack</code> (<i class="vp-icon iconfont icon-github" sizing="height"></i><code>apache/hadoop</code>)</a> 예</p></blockquote><div class="language-protobuf line-numbers-mode" data-highlighter="prismjs" data-ext="protobuf"><pre><code class="language-protobuf"><span class="line"><span class="token keyword">message</span> <span class="token class-name">BlockOpResponseProto</span> <span class="token punctuation">{</span>  </span>
<span class="line">  <span class="token comment">// 파이프라인 상태</span></span>
<span class="line">  status<span class="token punctuation">:</span> SUCCESS</span>
<span class="line">  <span class="token comment">// 연결 설정에 실패한 첫 번째 DataNode</span></span>
<span class="line">  firstBadLink<span class="token punctuation">:</span> <span class="token string">&quot;&quot;</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>파이프라인 설정 단계가 끝나면 파이프라인을 따라 네트워크 연결이 설정되고 DataNode에 Replica가 준비된다.</p><ul><li><code>writeBlock</code> 요청에서 <code>stage</code>가 <code>PIPELINE_SETUP_CREATE</code>인 경우 DataNode는 새로운 RBW Replica를 만든다. <ul><li><code>writeBlock</code> 요청에서 <code>stage</code>가 <code>PIPELINE_SETUP_APPEND</code>인 경우 append를 위해 DataNode는 Finalized Replica를 RBW Replica로 바꾼다.</li></ul></li></ul><h4 id="_2-단계-데이터-스트리밍" tabindex="-1"><a class="header-anchor" href="#_2-단계-데이터-스트리밍"><span>2 단계: 데이터 스트리밍</span></a></h4><p>그림 4의 T2~T5는 데이터 스트리밍 단계이다. 그림 4의 T2에서 첫 번째 패킷이 전송되었고 T5에서 마지막 패킷의 ACK를 수신했다.</p><p>파이프라인 설정이 완료되면 클라이언트는 파이프라인에 데이터를 쓰는데, 데이터는 먼저 클라이언트 버퍼에 저장된다. 버퍼가 꽉 차면 파이프라인으로 데이터가 전송된다.(그림 3의 5)</p><p>이전 패킷의 ACK를 받기 전이라도 파이프라인을 통해 다음 패킷이 전송될 수 있다. 그림 4의 T3에서 <code>hflush</code>가 호출되었다. <code>hflush</code>가 명시적으로 호출된 경우에는 패킷이 채워지지 않았어도 파이프라인으로 전송된다. <code>hflush</code>는 동기 작업이기 때문에 flush된 패킷의 ACK를 받기 전에는 데이터를 쓸 수 없다. 그림 4의 packet 2는 packet 1의 ACK를 수신한 그림 4의 T4 이후에 전송된다.</p><h4 id="_3-단계-파이프라인-종료" tabindex="-1"><a class="header-anchor" href="#_3-단계-파이프라인-종료"><span>3 단계: 파이프라인 종료</span></a></h4><p>그림 3의 T6~T7은 파이프라인 종료 단계이다. 클라이언트는 모든 패킷의 ACK을 받은 후에 종료(close) 요청을 보낸다. 파이프라인의 모든 DataNode는 해당 Replica를 Finalized 상태로 변경하고 NameNode에 보고한다. NameNode는 Replica의 상태가 Finalized라고 보고한 DataNode의 수가 최소 복제 수 이상인 경우 블록의 상태를 완료(Complete)로 바꾼다. 파일을 닫으려면 파일의 모든 블록이 완료된 상태여야 한다</p><p>모든 데이터를 다 쓴 클라이언트는 해당 파일에 쓰기 작업이 완료되었다는 것을 NameNode로 알리고 파일을 닫기 위해 NameNode에 <code>complete</code> 요청(그림 3의 7)을 보낸다.</p><blockquote><p><a href="https://github.com/apache/hadoop/blob/1e877761e8dadd71effef30e592368f7fe66a61b/hadoop-hdfs-project/hadoop-hdfs-client/src/main/proto/datatransfer.proto#L88" target="_blank" rel="noopener noreferrer"><code>complete</code> 요청 (<i class="vp-icon iconfont icon-github" sizing="height"></i><code>apache/hadoop</code>)</a> 예</p></blockquote><div class="language-protobuf line-numbers-mode" data-highlighter="prismjs" data-ext="protobuf"><pre><code class="language-protobuf"><span class="line"><span class="token keyword">message</span> <span class="token class-name">CompleteResponseProto</span> <span class="token punctuation">{</span>  </span>
<span class="line">  <span class="token comment">// 파일 경로</span></span>
<span class="line">  src<span class="token punctuation">:</span> <span class="token string">&quot;/test_dir/file.txt&quot;</span></span>
<span class="line">  <span class="token comment">// 클라이언트명</span></span>
<span class="line">  clientName<span class="token punctuation">:</span> <span class="token string">&quot;DFSClient_...&quot;</span></span>
<span class="line">  <span class="token comment">// 마지막 블록 정보</span></span>
<span class="line">  last<span class="token punctuation">:</span> <span class="token keyword">message</span> <span class="token class-name">ExtendedBlockProto</span> <span class="token punctuation">{</span></span>
<span class="line">    poolId<span class="token punctuation">:</span> <span class="token string">&quot;...&quot;</span></span>
<span class="line">    blockId<span class="token punctuation">:</span> <span class="token string">&quot;...&quot;</span></span>
<span class="line">    generationStamp<span class="token punctuation">:</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span></span>
<span class="line">  <span class="token punctuation">}</span></span>
<span class="line">  <span class="token comment">// Inode ID</span></span>
<span class="line">  fileId<span class="token punctuation">:</span> <span class="token number">17434</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><blockquote><p><a href="https://github.com/apache/hadoop/blob/1e877761e8dadd71effef30e592368f7fe66a61b/hadoop-hdfs-project/hadoop-hdfs-client/src/main/proto/ClientNamenodeProtocol.proto#L210" target="_blank" rel="noopener noreferrer"><code>complete</code> 응답 (<i class="vp-icon iconfont icon-github" sizing="height"></i><code>apache/hadoop</code>)</a> 예</p></blockquote><div class="language-protobuf line-numbers-mode" data-highlighter="prismjs" data-ext="protobuf"><pre><code class="language-protobuf"><span class="line"><span class="token keyword">message</span> <span class="token class-name">CompleteResponseProto</span> <span class="token punctuation">{</span>  </span>
<span class="line">  <span class="token comment">// 성공 여부</span></span>
<span class="line">  result<span class="token punctuation">:</span> <span class="token boolean">true</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="hdfs-쓰기-파이프라인의-특징" tabindex="-1"><a class="header-anchor" href="#hdfs-쓰기-파이프라인의-특징"><span>HDFS 쓰기 파이프라인의 특징</span></a></h3><p>지금까지 HDFS 쓰기 파이프라인에 대해 알아보았다. HDFS 쓰기 파이프라인은 각 노드의 네트워크 대역폭을 최대한 활용하여 모든 데이터를 복제하는 데 걸리는 시간을 최소화하는 방식이다. 왜 HDFS 쓰기 파이프라인이 각 노드의 네트워크 대역폭을 최대한 활용하는 방식인지 그림 5와 그림 6의 비교를 통해 알아보겠다.</p><figure><img src="/bookshelf/assets/image/d2.naver.com/6445508/5a.png" alt="그림 5 파이프라인을 통해 데이터를 전달하는 방식" tabindex="0" loading="lazy"><figcaption>그림 5 파이프라인을 통해 데이터를 전달하는 방식</figcaption></figure><figure><img src="/bookshelf/assets/image/d2.naver.com/6445508/5b.png" alt="그림 6 클라이언트가 모든 데이터를 전달하는 방식" tabindex="0" loading="lazy"><figcaption>그림 6 클라이언트가 모든 데이터를 전달하는 방식</figcaption></figure><p>HDFS 클라이언트를 포함하여 각 노드의 사용 가능한 대역폭이 1Gbps라고 가정하면 그림 5의 경우 복제본 데이터를 포함하여 전송하는 전체 데이터의 양은 3Gbps가 된다. 실제로는 DataNode 2와 DataNode 3가 동일 Rack 안에 있기 때문에 지연 시간이 짧고 사용 가능한 대역폭도 더 커서 더 빠르게 데이터가 전송될 것이다.</p><p>하지만 그림 6과 같이 클라이언트가 데이터를 모든 DataNode에 전송하면 전송하는 전체 데이터의 양은 1Gbps가 된다. 일반적으로 HDFS에 저장하는 파일은 크기가 크다. 저장해야 하는 파일의 크기가 크기 때문에 복제를 위해 네트워크를 통해 전송해야 하는 데이터의 양도 많아진다.</p><p>즉, 각 노드의 대역폭을 최대한 활용하는 파이프라인 방식이 큰 파일을 저장하는 HDFS에서 효율적이다.</p><hr><h2 id="fan-out-dfsoutputstream를-통한-wal-쓰기-최적화" tabindex="-1"><a class="header-anchor" href="#fan-out-dfsoutputstream를-통한-wal-쓰기-최적화"><span>Fan-out DFSOutputStream를 통한 WAL 쓰기 최적화</span></a></h2><p>HBase는 아래와 같이 4가지의 WAL Durability 설정을 제공하며, <code>SYNC_WAL</code>이 기본값이다.</p><div class="vp-tabs"><div class="vp-tabs-nav" role="tablist"><button type="button" class="vp-tab-nav active" role="tab" aria-controls="v-8" aria-selected="true">SKIP_WAL</button><button type="button" class="vp-tab-nav" role="tab" aria-controls="v-9" aria-selected="false">ASYNC_WAL</button><button type="button" class="vp-tab-nav" role="tab" aria-controls="v-10" aria-selected="false">SYNC_WAL (기본값)</button><button type="button" class="vp-tab-nav" role="tab" aria-controls="v-11" aria-selected="false">FSYNC_WAL</button></div><!--[--><div class="vp-tab active" id="v-8" role="tabpanel" aria-expanded="true"><div class="vp-tab-title">SKIP_WAL</div><!--[--><ul><li>WAL을 비활성화한다.</li><li>데이터 손실이 발생할 수 있는 옵션이다.</li></ul><!--]--></div><div class="vp-tab" id="v-9" role="tabpanel" aria-expanded="false"><div class="vp-tab-title">ASYNC_WAL</div><!--[--><ul><li>클라이언트가 WAL에 쓴 데이터가 sync되는 것을 기다리지 않는다.</li><li>데이터 손실이 발생할 수 있는 옵션이다.</li></ul><!--]--></div><div class="vp-tab" id="v-10" role="tabpanel" aria-expanded="false"><div class="vp-tab-title">SYNC_WAL (기본값)</div><!--[--><ul><li>클라이언트에 리턴하기 전에 데이터가 sync되길 기다린다.(HDFS의 <code>hflush</code> 호출)</li></ul><!--]--></div><div class="vp-tab" id="v-11" role="tabpanel" aria-expanded="false"><div class="vp-tab-title">FSYNC_WAL</div><!--[--><ul><li>클라이언트에 리턴하기 전에 데이터가 fsync되길 기다린다.(HDFS의 <code>hsync</code> 호출)</li></ul><!--]--></div><!--]--></div><p>WAL Durability 설정이 <code>SYNC_WAL</code>인 경우 HBase는 WAL에 데이터를 쓰고 데이터 손실을 방지하기 위해 HDFS의 <code>hflush</code>를 호출해 데이터가 sync되길 기다린다. <code>hflush</code>는 동기 작업으로, 클라이언트는 전송한 패킷의 ACK가 오길 기다린다.(<a href="#2-%EB%8B%A8%EA%B3%84-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8A%A4%ED%8A%B8%EB%A6%AC%EB%B0%8D">2 단계: 데이터 스트리밍</a> 참고)</p><p>WAL 데이터는 상대적으로 데이터의 크기가 작기 때문에 WAL 쓰기는 네트워크 대역폭의 영향은 덜 받지만, 전송한 패킷의 ACK가 오길 기다려야 하기 때문에 지연 시간이 긴 경우 WAL 쓰기 성능이 낮아질 수 있다. 따라서 WAL 쓰기 성능을 높이기 위해서는 지연 시간을 감소시키는 게 중요한데, 그림 5와 같이 파이프라인을 통해 데이터를 전달하면 ACK가 여러 노드를 거쳐서 클라이언트로 전달되기 때문에 지연 시간이 길어질 수 있다. 그림 6과 같이 클라이언트가 동시에 모든 데이터를 전송하고 ACK를 직접 받으면 지연 시간을 줄일 수 있다.</p><p>HBase는 WAL 쓰기 성능을 개선하기 위해 Netty 기반으로 그림 6처럼 DataNode에 데이터를 동시에 쓰는 WAL 쓰기용 Fan-out DFSOutputStream을 개발했다. HBase는 다음과 같이 <code>hbase.wal.provider</code>를 설정하여 WAL 구현체를 지정할 수 있는데 <code>hbase.wal.provider</code>를 <code>asyncfs</code>(HBase 2에서 기본값)로 설정한 경우 Fan-out DFSOutputStream이 사용된다.</p><div class="vp-tabs"><div class="vp-tabs-nav" role="tablist"><button type="button" class="vp-tab-nav active" role="tab" aria-controls="v-12" aria-selected="true">asyncfs</button><button type="button" class="vp-tab-nav" role="tab" aria-controls="v-13" aria-selected="false">filesystem</button><button type="button" class="vp-tab-nav" role="tab" aria-controls="v-14" aria-selected="false">multiwal</button></div><!--[--><div class="vp-tab active" id="v-12" role="tabpanel" aria-expanded="true"><div class="vp-tab-title">asyncfs</div><!--[--><ul><li>HBase 2에서 기본값이다.</li><li>HBase 2에서 추가되었으며 WAL 데이터를 블록 생성 파이프라인을 따라서 쓰지 않고 동시에(Fan-out) 쓰기 때문에 지연 시간을 줄일 수 있다.</li></ul><!--]--></div><div class="vp-tab" id="v-13" role="tabpanel" aria-expanded="false"><div class="vp-tab-title">filesystem</div><!--[--><ul><li>HBase 1에서 기본값이다.</li><li>DFSClient를 기반으로 만들어졌으며 블록 생성 파이프라인을 따라 데이터를 쓴다.</li></ul><!--]--></div><div class="vp-tab" id="v-14" role="tabpanel" aria-expanded="false"><div class="vp-tab-title">multiwal</div><!--[--><ul><li>여러 개의 <code>asyncfs</code> 또는 여러 개의 <code>filesystem</code>을 사용하는 설정이다.</li><li>RegionServer에서 단일 WAL을 사용하면 병목 현상이 생길 수 있는데 여러 개의 WAL을 병렬로 쓸 수 있게 하여 총 처리량을 증가시킬 수 있는 방법이다.</li></ul><!--]--></div><!--]--></div><p>Fan-out DFSOutputStream은 모든 DataNode에 동시에 데이터 쓰기를 진행하기 때문에 일반적으로 대기 시간이 단축된다. 또한 오류가 발생했을 때 파이프라인 복구를 수행하지 않고 새로운 WAL 파일을 만들어서 데이터를 다시 쓴다. 파이프라인 복구를 수행하지 않기 때문에 앞에서 언급한 파이프라인 복구 실패로 인한 문제가 발생하지 않는다. Fan-out DFSOutputStream의 구조는 다음과 같다.</p><figure><img src="/bookshelf/assets/image/d2.naver.com/6445508/6.png" alt="그림 7 Fan-out DFSOutputStream 구조" tabindex="0" loading="lazy"><figcaption>그림 7 Fan-out DFSOutputStream 구조</figcaption></figure><p>새로운 WAL 파일이 요청되면 <code>FanOutOneBlockAsyncDFSOutputHelper</code>는 HDFS 쓰기 파이프라인와 동일하게 Client Protocol의 <code>create</code> 요청(그림 7의 1)을 보내 네임스페이스에 새로운 WAL 파일 항목을 만든다. 각 Protocol의 요청과 응답 데이터가 Protocol Buffer를 통해 직렬화, 역직렬화되기 때문에 HBase는 HDFS의 Protocol Buffer 코드를 통해 쉽게 동일한 요청을 만들고 응답을 파싱할 수 있다.</p><p>NameNode로부터 응답을 받은 후 블록을 쓸 DataNode를 할당받기 위해 <code>FanOutOneBlockAsyncDFSOutputHelper</code>는 <code>addBlock</code> 요청(그림 7의 2)을 NameNode로 보낸다. NameNode로부터 블록을 쓸 DataNode를 할당받은 후에는 Netty Channel을 사용해서 DataNode와 연결을 맺고 <code>writeBlock</code> 요청(그림 7의 3)을 보낸다. <code>FanOutOneBlockAsyncDFSOutputHelper</code>가 보내는 <code>writeBlock</code> 요청은 다음과 같다.</p><p><code>FanOutOneBlockAsyncDFSOutputHelper</code>에서 보내는 <code>writeBlock</code> 요청 예</p><div class="language-protobuf line-numbers-mode" data-highlighter="prismjs" data-ext="protobuf"><pre><code class="language-protobuf"><span class="line"><span class="token keyword">message</span> <span class="token class-name">OpWriteBlockProto</span> <span class="token punctuation">{</span>  </span>
<span class="line">  header<span class="token punctuation">:</span> <span class="token keyword">message</span> <span class="token class-name">ClientOperationHeaderProto</span> <span class="token punctuation">{</span></span>
<span class="line">    <span class="token comment">// 블록 정보</span></span>
<span class="line">    block<span class="token punctuation">:</span> <span class="token keyword">message</span> ExtendedBlockProto</span>
<span class="line">    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span></span>
<span class="line">  <span class="token punctuation">}</span></span>
<span class="line">  <span class="token comment">// 클라이언트명</span></span>
<span class="line">  clientName<span class="token punctuation">:</span> <span class="token string">&quot;DFSClient_...&quot;</span></span>
<span class="line">  <span class="token comment">// 파이프라인 대상 DataNode 정보(IP 주소, 호스트명, 포트 정보, ...)</span></span>
<span class="line">  targets<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></span>
<span class="line">  <span class="token comment">// 파이프라인 스테이지(BlockConstructionStage)</span></span>
<span class="line">  stage<span class="token punctuation">:</span> PIPELINE_SETUP_CREATE</span>
<span class="line">  <span class="token comment">// 파이프라인 크기</span></span>
<span class="line">  pipelineSize<span class="token punctuation">:</span> <span class="token number">1</span></span>
<span class="line">  <span class="token comment">// ...</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><code>FanOutOneBlockAsyncDFSOutputHelper</code>가 보내는 <code>writeBlock</code> 요청을 살펴보면 HDFS 쓰기 파이프라인에서 보내는 <code>writeBlock</code> 요청과 다르게 파이프라인 대상 DataNode 정보가 없고 파이프라인 크기가 1이다. 이 요청을 받은 DataNode는 파이프라인 대상 DataNode 정보가 없기 때문에 자신을 파이프라인의 마지막 DataNode로 인식하고 다른 DataNode와 추가적인 연결을 만들지 않는다. 즉, DataNode끼리 블록 생성 파이프라인을 만들지 않는다.</p><p>하지만 이 방식은 HDFS의 가시성(visibility)이 보장되지 않는다. 데이터를 쓰고 있는 파일의 경우 HDFS의 가시성 보장에 따라 파이프라인의 마지막 DataNode에 쓰인 데이터까지 클라이언트에서 사용 가능한 데이터가 되는데, Fan-out DFSOutputStream은 모든 DataNode가 파이프라인의 마지막 DataNode로 취급되기 때문에 아직 데이터를 쓰고 있는 WAL 파일을 읽을 경우 데이터 불일치가 발생할 수 있다. HBase는 이 문제를 해결하기 위하여 HDFS에 sync된 파일의 길이를 별도로 관리하여 내부 프로세스에서 데이터를 읽을 때 해당 길이까지만 데이터를 읽을 수 있도록 제한한다.</p><p>DataNode와 기존 HDFS 쓰기 파이프라인에 파이프라인 설정 단계까지 마친 <code>FanOutOneBlockAsyncDFSOutputHelper</code>는 클라이언트가 데이터를 쓸 수 있도록 <code>FanOutOneBlockAsyncDFSOutput</code>을 생성한다.(그림 7의 4) 이후 <code>FanOutOneBlockAsyncDFSOutput</code>은 Netty Channel을 이용하여 모든 DataNode에 동시에 WAL 데이터를 쓴다.(그림 7의 5)</p><p>HBase는 데이터를 쓰고 있는 WAL의 파일 크기가 HDFS 블록 크기(<code>hbase.regionserver.hlog.blocksize</code> 설정)의 50%(<code>hbase.regionserver.logroll.multiplier</code> 설정)가 되거나 기존 파일에 데이터를 쓰다 오류가 발생하면 기존 WAL 파일을 닫고 새로운 WAL 파일을 만든다.</p><div class="vp-tabs"><div class="vp-tabs-nav" role="tablist"><button type="button" class="vp-tab-nav active" role="tab" aria-controls="v-15" aria-selected="true">hbase.regionserver.hlog.blocksize</button><button type="button" class="vp-tab-nav" role="tab" aria-controls="v-16" aria-selected="false">hbase.regionserver.logroll.multiplier</button></div><!--[--><div class="vp-tab active" id="v-15" role="tabpanel" aria-expanded="true"><div class="vp-tab-title">hbase.regionserver.hlog.blocksize</div><!--[--><ul><li>WAL 파일의 HDFS 블록 크기(기본값: HDFS 기본 블록 크기의 2배)</li></ul><!--]--></div><div class="vp-tab" id="v-16" role="tabpanel" aria-expanded="false"><div class="vp-tab-title">hbase.regionserver.logroll.multiplier</div><!--[--><ul><li>WAL 파일의 크기가 HDFS 블록 크기의 multiplier만큼 도달하면 새로운 WAL 파일을 만든다.(기본값: 0.5)</li></ul><!--]--></div><!--]--></div><p>기존 WAL 파일을 닫고 새로운 WAL 파일을 만들 때 기존 <code>FanOutOneBlockAsyncDFSOutput</code>은 닫고 새로운 <code>FanOutOneBlockAsyncDFSOutput</code>을 만드는데, <code>FanOutOneBlockAsyncDFSOutput</code>이 닫힐 때 <code>FanOutOneBlockAsyncDFSOutput</code>은 DataNode와 연결을 정리하고 NameNode에 <code>complete</code> 요청(그림 7의6)을 보내 현재 WAL 파일에 쓰기 작업이 완료되었다는 것을 알린다.</p><hr><h2 id="마치며" tabindex="-1"><a class="header-anchor" href="#마치며"><span>마치며</span></a></h2><p>이 글에서는 HDFS 쓰기 파이프라인과 HBase가 WAL 쓰기 최적화를 위해 개발한 Fan-out DFSOutputStream에 대해 알아보았다.</p><p>Fan-out DFSOutputStream은 아직 일반적인 쓰기 작업에서는 사용할 수 없다. 일반적인 쓰기 작업에서 사용하기 위해서는 Fan-out DFSOutputStream이 여러 블록을 쓸 수 있도록 개선하고 HDFS 가시성이 보장되지 않는 문제를 해결해야 한다. 또한 추후 해당 기능을 적용하려면 그 전에 쓰기 작업이 네트워크 대역폭을 최대로 활용하는 것이 중요한지, 아니면 지연 시간을 줄이는 것이 중요한지 먼저 판단할 필요가 있다.</p><p>HBase에서 WAL 성능은 사용자 요청 처리 시간에 영향을 많이 준다. 따라서 HBase는 WAL 성능을 높이기 위해서는 지연 시간을 줄이는 것이 필요했다. 이를 위해 HBase는 HDFS 프로토콜을 사용하여 Fan-out DFSOutputStream을 개발했다. 2.5.0 버전에는 패킷 처리 시간이 느린 DataNode를 빠르게 탐지하여 OutputStream에서 제거하는 기능이 추가되었는데(<a href="https://issues.apache.org/jira/browse/HBASE-26347" target="_blank" rel="noopener noreferrer"><i class="vp-icon iconfont icon-Apache" sizing="height"></i>HBASE-26347</a> Support detect and exclude slow DNs in fan-out of WAL) 이러한 기능은 자체 개발한 Fan-out DFSOutputStream에서 ACK가 돌아오는 시간을 측정할 수 있었기 때문에 가능했다. 만약 HDFS 프로토콜에 대한 이해가 없었다면 이러한 기능을 추가하기 어려웠을 것이다.</p><p>추후 기회가 된다면 각 컴포넌트가 프로토콜을 어떻게 처리하는지 알아보겠다. 이 글이 HDFS 쓰기 과정을 이해하는 데 조금이나마 도움이 되길 바란다.</p><hr><h2 id="참고-자료" tabindex="-1"><a class="header-anchor" href="#참고-자료"><span>참고 자료</span></a></h2><a class="vp-card" href="https://issues.apache.org/jira/browse/HDFS-265" target="_blank" style="background:rgba(0,101,255,0.2);"><img class="vp-card-logo" src="https://issues.apache.org/jira/s/xd9jlf/820010/13pdxe5/_/images/fav-jsw.png" loading="lazy" no-view><div class="vp-card-content"><div class="vp-card-title">[HDFS-265] Revisit append - ASF JIRA</div><hr><div class="vp-card-desc">...</div></div></a><div class="pdf-viewer-wrapper" style="width:100%;height:auto;"><div></div><button class="pdf-fullscreen-button"><svg xmlns="http://www.w3.org/2000/svg" class="pdf-fullscreen-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="enter-fullscreen icon" name="enter-fullscreen"><path d="M762.773 90.24h-497.28c-96.106 0-174.4 78.293-174.4 174.4v497.28c0 96.107 78.294 174.4 174.4 174.4h497.28c96.107 0 175.04-78.293 174.4-174.4V264.64c0-96.213-78.186-174.4-174.4-174.4zm-387.2 761.173H215.04c-21.867 0-40.427-17.92-41.067-41.066V649.92c0-22.507 17.92-40.427 40.427-40.427 11.307 0 21.227 4.694 28.48 11.947 7.253 7.253 11.947 17.92 11.947 28.48v62.293l145.28-145.28c15.893-15.893 41.813-15.893 57.706 0 15.894 15.894 15.894 41.814 0 57.707l-145.28 145.28h62.294c22.506 0 40.426 17.92 40.426 40.427s-17.173 41.066-39.68 41.066zM650.24 165.76h160.427c21.866 0 40.426 17.92 41.066 41.067v160.426c0 22.507-17.92 40.427-40.426 40.427-11.307 0-21.227-4.693-28.48-11.947-7.254-7.253-11.947-17.92-11.947-28.48v-62.186L625.6 450.347c-15.893 15.893-41.813 15.893-57.707 0-15.893-15.894-15.893-41.814 0-57.707l145.28-145.28H650.88c-22.507 0-40.427-17.92-40.427-40.427s17.174-41.173 39.787-41.173z"></path></svg></button></div><!-- TODO: 파일처리 --><a class="vp-card" href="https://issues.apache.org/jira/browse/HBASE-14790" target="_blank" style="background:rgba(0,101,255,0.2);"><img class="vp-card-logo" src="https://issues.apache.org/jira/s/xd9jlf/820010/13pdxe5/_/images/fav-jsw.png" loading="lazy" no-view><div class="vp-card-content"><div class="vp-card-title">[HBASE-14790] Implement a new DFSOutputStream for logging WAL only - ASF JIRA</div><hr><div class="vp-card-desc">...</div></div></a><div class="vp-site-info" data-name="Apache HBase Write Path - Cloudera Blog"><a class="vp-site-info-navigator no-external-link-icon" title="Apache HBase Write Path - Cloudera Blog" href="https://blog.cloudera.com/apache-hbase-write-path/" target="_blank"></a><div class="vp-site-info-preview" style="background:url(https://blog.cloudera.com/wp-content/themes/cloudera/assets/images/default-banner/GettyImages-1287640296-1382x400.jpg) center/cover no-repeat;"></div><div class="vp-site-info-detail"><img class="vp-site-info-logo" src="https://blog.cloudera.com/wp-content/themes/cloudera/assets/images/favicon/favicon.ico" alt loading="lazy" no-view><div class="vp-site-info-name">Apache HBase Write Path - Cloudera Blog</div><div class="vp-site-info-desc">Apache HBase is the Hadoop database, and is based on the Hadoop Distributed File System (HDFS). HBase makes it possible to randomly access and update data stored in HDFS, but files in HDFS can only be appended to and are immutable after they are created.  So you may ask, how does HBase provide low-latency reads […]</div></div><!----></div><a class="vp-card" href="https://hadoop.apache.org" target="_blank" style="background:rgba(235,231,134,0.2);"><img class="vp-card-logo" src="https://hadoop.apache.org/favicon.ico" loading="lazy" no-view><div class="vp-card-content"><div class="vp-card-title">Apache Hadoop</div><hr><div class="vp-card-desc">The Apache® Hadoop® project develops open-source software for reliable, scalable, distributed computing.</div></div></a><a class="vp-card" href="https://hbase.apache.org" target="_blank" style="background:rgba(186,22,12,0.2);"><img class="vp-card-logo" src="https://hbase.apache.org/images/favicon.ico" loading="lazy" no-view><div class="vp-card-content"><div class="vp-card-title">Apache HBase - Apache HBase™ Home</div><hr><div class="vp-card-desc">Apache HBase™ is the Hadoop database, a distributed, scalable, big data store.</div></div></a></div><!----><!----><!----></div><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/chanhi2000/bookshelf/edit/main/src/d2.naver.com/6445508.md" aria-label="Edit this page on GitHub" rel="noopener noreferrer" target="_blank"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->Edit this page on GitHub<!----></a></div><div class="vp-meta-item git-info"><!----><!----></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/bookshelf/programming/java/articles/" aria-label="/programming/java/articles/"><div class="hint"><span class="arrow start"></span>Prev</div><div class="link"><!---->/programming/java/articles/</div></a><!----></nav><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><div class="vp-footer">MIT Licensed | Copyright © 2022-present <a href="https://github.com/chanhi2000">Chan Hee Lee</a></div><!----></footer></div><!--]--><!--[--><!----><!--[--><!--]--><!--[--><!--]--><!--]--><!--]--></div>
    <script type="module" src="/bookshelf/assets/app-BItykJLQ.js" defer></script>
  </body>
</html>
