---
lang: ko-KR
title: "더 빨라진 대화형 AI, ‘gpt-realtime’ 직접 써봤습니다"
description: "Article(s) > 더 빨라진 대화형 AI, ‘gpt-realtime’ 직접 써봤습니다"
icon: iconfont icon-openai
category:
  - AI
  - LLM
  - OpenAI
  - Article(s)
tag:
  - blog
  - yozm.wishket.com
  - ai
  - artificial-intelligence
  - llm
  - large-language-models
  - openai
head:
  - - meta:
    - property: og:title
      content: "Article(s) > 더 빨라진 대화형 AI, ‘gpt-realtime’ 직접 써봤습니다"
    - property: og:description
      content: "더 빨라진 대화형 AI, ‘gpt-realtime’ 직접 써봤습니다"
    - property: og:url
      content: https://chanhi2000.github.io/bookshelf/yozm.wishket.com/3444.html
prev: /ai/openai/articles/README.md
date: 2025-11-12
isOriginal: false
author:
  - name: 테크유람
    url : https://yozm.wishket.com/magazine/@techtrip/
cover: https://yozm.wishket.com/media/news/3444/oai_realtime-api-ga_blog-header.webp
---

# {{ $frontmatter.title }} 관련

```component VPCard
{
  "title": "OpenAI > Article(s)",
  "desc": "Article(s)",
  "link": "/ai/openai/articles/README.md",
  "logo": "/images/ico-wind.svg",
  "background": "rgba(10,10,10,0.2)"
}
```

[[toc]]

---

<SiteInfo
  name="더 빨라진 대화형 AI, ‘gpt-realtime’ 직접 써봤습니다"
  desc="지난 2025년 8월 28일, OpenAI는 음성 기반의 AI 에이전트에 사용할 수 있는 모델 ‘gpt-realtime’과 ‘Realtime API’의 최신 업데이트 버전을 공개했습니다. 이번 글에서는 gpt-realtime의 기술적 배경을 살펴보고, 직접 테스트한 경험을 바탕으로 기존 음성 인식 방식과 어떤 차이를 보이는지 분석해 보고자 합니다."
  url="https://yozm.wishket.com/magazine/detail/3444/"
  logo="https://yozm.wishket.com/favicon.ico"
  preview="https://yozm.wishket.com/media/news/3444/oai_realtime-api-ga_blog-header.webp"/>

지난 2025년 8월 28일, OpenAI는 음성 기반의 AI 에이전트에 사용할 수 있는 모델 ‘gpt-realtime’과 ‘Realtime API’의 최신 업데이트 버전을 공개했습니다. 이번 글에서는 gpt-realtime의 기술적 배경을 살펴보고, 직접 테스트한 경험을 바탕으로 기존 음성 인식 방식과 어떤 차이를 보이는지 분석해 보고자 합니다.

---

## 기존 음성 인식 방식과의 차이점

기존의 음성 에이전트 구축 방식은 여러 개의 개별 모델을 연결하는 파이프라인 형태였습니다. 개발자들은 음성을 텍스트로 변환하기 위해 음성-텍스트 모델(예: Whisper)을 사용하고, 이 텍스트를 추론이나 판단을 위해 텍스트 모델(LLM)에 전달하며, 최종적으로 모델의 텍스트 출력을 사용자에게 재생하기 위해 다시 텍스트-음성 변환(TTS) 모델을 사용해야 했습니다. 이 방식은 요청을 전송하고 응답을 기다리는 구조로 인해 실제 음성 대화에서는 미세한 끊김이 발생했습니다. 그 결과 음성 대화는 인간처럼 즉각적이고 자연스럽게 반응하는 상호 작용형 대화를 지원하기엔 다소 아쉬운 수준이었습니다.

Realtime API는 gpt-realtime 계열의 음성-음성(Speech-to-Speech) 모델과 한 번의 API 호출을 통해 오디오를 직접 처리하고 생성하여 음성-음성 대화를 구현합니다. 이러한 통합은 개발자가 더 이상 여러 모델을 연결하여 경험을 구축할 필요가 없게 만들었습니다.

::: info 기존 음성 입력의 해석과 출력 방식

> 오디오 입력 -> STT(Speech-to-Text) -> LLM -> Text-to-Speech -> 오디오 출력

:::

:::: info Speech-to-Speech 모델 방식

> 오디오 입력 -> gpt-realtime(Speech-to-Speech) -> 오디오 출력

:::

기존 파이프라인 방식의 가장 큰 문제점 중 하나는 각 단계에서 발생하는 지연(latency)이었습니다. STT, LLM 추론, TTS 변환 등 단계를 거치면서 지연이 발생하여 실제 인간의 대화보다 느린 경험을 제공했습니다. Realtime API는 지속적인 WebSocket 연결을 설정하고 오디오 입력과 출력을 직접 스트리밍함으로써 이 단계에서 발생하던 지연을 획기적으로 줄이고, 더 자연스러운 대화 경험을 가능하게 합니다.

기존 방식은 오디오를 텍스트로 변환하는 과정에서 대화에 섞여 있는 감정, 강세, 억양과 같은 인간 발화의 중요한 요소를 많이 상실했습니다. gpt-realtime 모델은 오디오를 직접 처리하고 생성하므로, 발화의 뉘앙스가 보존되고 더 자연스럽고 표현력이 높은 응답이 생성됩니다. 이 모델은 말할 때 인간의 억양, 감정, 속도를 반영하며, 웃음과 같은 비언어적 신호를 포착할 수 있습니다.

이번에 발표한 gpt-realtime은 2024년에 1차 공개한 realtime 모델의 베타 버전을 베타 테스트에 참석한 개발자들의 피드백을 반영하여 정식 버전으로 출시한 것으로, 고객 지원 및 교육 등 실제 프로덕션 환경의 작업에서 뛰어난 성능을 보이도록 베타 고객과 긴밀히 협력하여 학습됐습니다. 개발자들이 음성 에이전트를 빌드하고 배포하는 방식에 맞게 학습된 것이죠.

gpt-realtime 모델과 Realtime API는 실시간 음성-음성 에이전트 경험을 제공하기 위해 설계된 핵심적인 두 축으로, 상호 보완적인 관계를 맺고 있습니다. Realtime API는 모델의 기능을 개발자가 프로덕션 환경에서 활용할 수 있도록 지원하는 인터페이스이자 인프라 역할을 하며, gpt-realtime 모델은 기존 음성 인식 모델과 함께 API가 제공하는 실시간 대화 기능을 구동하는 핵심 모델 역할을 수행합니다.

---

## gpt-realtime의 비약적인 성능 향상

새로운 gpt-realtime 모델은 현존하는 가장 발전된 음성-음성 모델로, 프로덕션에 즉시 배포할 수 있도록 설계되었습니다. 특히 복잡한 지침 준수, 도구 호출 정확성, 자연스럽고 표현력이 풍부한 음성 생성 능력에서 두드러진 개선을 보입니다.

![시스템 지침이 주어졌을 때 음성 기반 대화의 흐름 예제](https://wishket.com/media/news/3444/image3.png)

### 1. 향상된 오디오 품질과 자연스러운 발화

gpt-realtime은 인간의 억양, 감정, 속도를 반영하는 더 높은 품질의 음성을 생성합니다. 사용자는 '빠르고 전문적으로 말해 줘' 또는 '프랑스어 언어로 더 공감하듯이 말해 줘'와 같이 상세한 지침을 통해 모델의 발화 스타일을 제어할 수 있습니다. 또한 최상의 어시스턴트 음성 품질을 위해 마린(*Marin*)과 세다(*Cedar*)라는 두 가지 새로운 성우 캐릭터의 음성이 릴리스되었습니다. 모델은 웃음과 같은 비언어적 신호를 포착하고, 문장 중간에 언어를 바꾸거나 특정 어조를 적용하는 데 능숙합니다.

### 2. 강력한 지침 준수 및 추론 능력

개발자가 시스템 메시지나 프롬프트에 제공하는 사소한 지침이라도 이제 모델에게 더 강력한 신호로 작용합니다. 이전 모델에서 모호하게 처리되었을 수 있는 구체적인 지침들(예: "Y일 때 항상 X라고 말해")도 새로운 모델에서는 강력하게 준수될 것으로 예상해야 합니다.

지침 준수 정확도를 측정하는 *MultiChallenge* 오디오 벤치마크에서 gpt-realtime은 이전 모델(20.6%)보다 크게 향상된 30.5%를 기록했습니다. 또한, 고급 추론 능력을 측정하는 *Big Bench Audio* 평가에서도 82.8%의 정확도를 보여 이전 모델(65.6%)을 뛰어넘었습니다.

시스템 지침을 다음과 같이 설정하였을 때 gpt-realtime을 사용하는 애플리케이션과의 대화 예제입니다.

> **역할**: 당신은 A전자의 고객 상담 센터를 대표하는 콜센터 봇입니다. 모든 고객과의 대화에서 신뢰, 공감, 그리고 문제 해결 의지를 보여야 합니다.
>
> **기본 응대 원칙**
>
> - 공손하고 따뜻한 말투를 사용합니다.  
> - 고객의 말을 중간에 끊지 않고 충분히 이해한 뒤 답변합니다.  
> - 고객의 불만이나 실망감에 먼저 공감 표현을 사용합니다.  
> - 환불은 절대로 수락하지 않습니다. 대신 다음과 같은 대안 제시를 합니다. (제품 교환, 포인트 또는 쿠폰 보상, 추가 서비스 제공 등)
>
> 정책상 환불이 불가능한 이유를 이해하기 쉽게 설명하고, 고객이 납득할 수 있도록 차분히 안내합니다. 고객이 계속 환불을 요구하거나 감정이 격한 경우에는 담당 고객 응대 매니저가 곧 연락드려 자세히 도와드릴 예정이라도 응대하며 통화를 자연스럽게 종료하도록 유도합니다.

데모 영상에서는 지침을 최대한 준수하며 컴플레인 고객을 최대한 친절하게 응대하는 에이전트의 모습을 확인할 수 있습니다. 고객의 감정을 읽어 “아, 고객님,”과 같은 추임새도 사용합니다. 특히 고객이 에이전트의 말을 중간에 끊고 자신의 이야기를 일방적으로 이어갈 때, 에이전트가 즉시 발화를 멈추고 경청으로 전환하는 자연스러운 대화 흐름도 볼 수 있습니다.

<VidStack src="youtube/JtTNqKWvYfM" />

### 3. 프로그래밍 방식의 함수 호출 기능

음성 에이전트를 구축하기 위해서는 적시에 또 다른 적절한 도구를 호출하는 능력이 필요합니다. LLM이 내부 혹은 외부에 존재하는 함수나 API를 직접 호출할 수 있게 하는 인터페이스를 Function Calling이라고 하며, gpt-realtime에선 비동기 함수 호출(async function calling) 기능이 기본으로 사용 가능해져, 길게 실행되는 함수 호출 중에도 세션의 흐름을 방해하지 않고 자연스럽게 대화를 이어갈 수 있습니다.

![날씨 정보를 가져오는 시뮬레이션을 보여주는 Function Calling 예제 ](https://wishket.com/media/news/3444/image2.png)

---

## Realtime API의 개선된 프로덕션급 기능들

Realtime API의 정식 버전(General Availability)이 출시되면서 개발자들이 음성 애플리케이션을 구축할 수 있도록 지원하는 다양한 새로운 기능들을 도입했습니다.

### 1. API 구조 업데이트 및 마이그레이션

Realtime API는 정식 버전 출시와 함께 인터페이스 형태가 업데이트되었습니다. 해당 버전의 인터페이스에서는 모델 사용 시 매개변수 중 temperature가 제거되었는데, 이는 이 모델 아키텍처에서 temperature가 다르게 작동하며 권장값인 0.8로 설정하는 것이 가장 좋다고 관찰되었기 때문입니다.

### 2. 긴 대화 및 컨텍스트 관리

Realtime API 세션은 기존 30분에서 이제 최대 60분 동안 지속될 수 있으며 gpt-realtime 모델은 32,768 토큰의 컨텍스트 윈도와 최대 입력은 28,672 토큰을 지원합니다.

- **자동 길이 조정**: 대화 컨텍스트가 28,672 토큰 한도에 도달하면, Realtime API는 가장 오래된 메시지부터 메시지를 자동으로 절단합니다.
- **캐시 친화적인 길이 조정**: 토큰 프롬프트 캐시의 무효화 영향을 줄이기 위해, 오래된 메시지 절단 시 필요한 것보다 더 많이 잘라내는 보존 비율 설정이 구현되었습니다.

### 3. 멀티 모달 및 이기종 시스템 통합 기능 확장

- **이미지 입력**: gpt-realtime 모델은 이미지 입력을 지원하여, 오디오나 텍스트와 함께 이미지, 사진, 스크린숏을 Realtime API 세션에 추가할 수 있습니다. 개발자는 이제 시각적 정보를 활용하는 대화형 에이전트를 구축할 수 있습니다. 예를 들어, 사용자는 "뭐가 보여?" 또는 "이 스크린숏의 텍스트를 읽어 줘"와 같은 질문이나 요청을 할 수 있으며, 모델은 사용자가 실제로 보고 있는 것을 기반으로 대화를 이어갈 수 있습니다. 기존의 음성 비서가 청각 정보에만 의존했다면, 이제는 주변의 시각적 정보 및 물리적 환경 설명 등을 포함하는 훨씬 풍부한 고객 지원, 교육, 또는 개인 비서 애플리케이션을 개발할 수 있습니다.

- **SIP 지원**: Realtime API 내에서 세션 시작 프로토콜(SIP: Session Initiation Protocol)이 직접 지원되어, 애플리케이션을 공용 전화망, 기업 내선 시스템(PBX: Private Branch eXchange), 기타 SIP 엔드 포인트에 연결할 수 있습니다. 다양한 통화 기반의 서비스 등 전통적인 음성 통신 채널에서 Realtime API 기반 에이전트를 활용하여 고객 서비스나 비즈니스 운영을 자동화할 수 있음을 알 수 있으며 이는 레거시 시스템과의 통합 시 복잡성을 줄여준다는 의미로 해석됩니다.

- **원격 MCP 서버 지원**: 세션 구성에 원격 MCP(Model Context Protocol) 서버의 URL을 전달하여 MCP 지원을 사용할 수 있으며, API가 자동으로 사용자 대신 도구 호출을 처리합니다. MCP 서버는 복잡한 외부 비즈니스 서비스 로직을 처리하는 역할을 합니다. 원격 MCP 서버 지원은 개발자가 에이전트의 도메인 지식과 액션 기능을 중앙 집중화하고 쉽게 확장할 수 있게 하며, Realtime API와의 통합 시 발생하는 번거로운 수동 설정을 제거하여 개발 효율성을 높일 것으로 예상됩니다.

![Gmail MCP 서버를 연결하여 요즘IT에서 보낸 메일을 요약해서 읽어 달라는 요청 예제](https://wishket.com/media/news/3444/image1.png)

### 4. 개발자 편의 기능 및 안정성

- **비동기 함수 호출(async function calling)**: 함수 호출이 진행 중인 동안 모델이 "아직 기다리고 있습니다"와 같은 자리 표시자 응답을 제공하여 사용자 경험을 개선합니다.
- **대화 유휴 시간 초과(conversation idle timeouts)**: 사용자 입력이 오랫동안 없을 때 (예: 전화 통화 중) 모델이 자동으로 "아직 계신가요?"와 같은 발화를 유발하도록 설정할 수 있습니다.
- **호스팅 프롬프트/프롬프트 재사용**: Realtime API 세션에서 프롬프트를 저장하고 ID로 참조하여 재사용할 수 있습니다. 프롬프트에는 지침과 턴 감지 설정 같은 세션 구성이 포함됩니다.
- **추적(tracing) 기능**: 실시간 세션 중 주요 이벤트(예: "Session updated," "Output text generation")를 기록하는 추적이 개발자 콘솔에 로깅되어 디버깅에 유용합니다.
- **EU 데이터 상주**: 데이터 상주 제어는 OpenAI가 서비스를 제공하는 데 사용하는 인프라의 위치를 ​​구성할 수 있는 프로젝트 구성 옵션입니다. 특정 모델에 대해 EU 데이터 상주(residency)가 지원됩니다.

---

## gpt-realtime, 실시간 음성 AI의 새로운 시대를 열다

이번 업데이트를 통해 OpenAI는 개발자와 기업이 프로덕션 가능한 안정적인 음성 에이전트를 대규모로 구축할 수 있도록 기반을 다졌습니다. gpt-realtime 모델은 복잡한 지침 준수, 정확한 도구 호출, 그리고 더 자연스럽고 표현력이 높은 음성 생성 능력에서 비약적인 개선을 보였습니다.

Realtime API의 새로운 기능들은 음성 에이전트의 활용 범위를 콜센터나 앱 내 대화에 국한시키지 않고 광범위한 인프라와 연결합니다. 또한 멀티 모달 기능 지원을 통해 에이전트는 시각적 컨텍스트를 기반으로 대화를 이어갈 수 있게 되어, 문제 해결이나 교육과 같은 분야에서 풍부한 상호작용을 가능하게 합니다.

OpenAI는 이 새로운 gpt-realtime 모델과 Realtime API의 개선된 안정성, 짧은 지연, 고품질 기능을 통해 개발자들이 고객 지원, 교육, 번역, 접근성 등 다양한 사용 사례 전반에서 혁신적이고 설득력 있는 음성 경험을 창출할 것이라 기대할 것입니다. 앞으로 음성 인식 지원 서비스 개발에서 gpt-realtime 모델이 얼마나 기존 음성 인식 시장을 파고들지 매우 궁금해지는 부분입니다.

::: info 참고하면 좋은 자료

<SiteInfo
  name="프로덕션 음성 에이전트의 gpt-realtime과 Realtime API 업데이트 소개"
  desc="더 발전한 음성-음성 모델과 함께 MCP 서버 지원, 이미지 입력, SIP 전화 걸기 지원을 포함한 새로운 API 기능을 릴리스합니다."
  url="https://openai.com/ko-KR/index/introducing-gpt-realtime//"
  logo="https://openai.com/favicon.svg"
  preview="https://images.ctfassets.net/kftzwdyauwt9/16qATUOZ1GSdE7JHHr0qFG/47b074ae6486a3d8f9ad14adb7812d13/RealtimeAPI_Blog_Open_Graphic_Image__1200x630_.png?w=1600&h=900&fit=fill"/>

<SiteInfo
  name="Introducing the Realtime API"
  desc="Developers can now build fast speech-to-speech experiences into their applications"
  url="https://openai.com/index/introducing-the-realtime-api//"
  logo="https://openai.com/favicon.svg"
  preview="https://images.ctfassets.net/kftzwdyauwt9/139I6Ga8xl6qTXGPL9lWyc/82838b1ef1a26a4946a27d656de0c806/01_Realtime_API.png?w=1600&h=900&fit=fill"/>

<SiteInfo
  name="Developer notes on the Realtime API"
  desc="Details worth noticing in recent realtime speech-to-speech updates"
  url="https://developers.openai.com/blog/realtime-api//"
  logo="https://developers.openai.com/favicon.png"
  preview="https://developers.openai.com/images/blog/agent-online.png"/>

<SiteInfo
  name="Realtime API - OpenAI API"
  desc="Learn how to build low-latency, multimodal LLM applications with the Realtime API."
  url="https://platform.openai.com/"
  logo="https://platform.openai.com/favicon-platform.svg"
  preview="https://cdn.openai.com/API/images/platform-opengraph.png"/>

<SiteInfo
  name="OpenAI Platform"
  desc="Explore developer resources, tutorials, API docs, and dynamic examples to get the most out of OpenAI's platform."
  url="https://platform.openai.com/"
  logo="https://platform.openai.com/favicon-platform-alt.svg"
  preview="https://cdn.openai.com/API/images/platform-opengraph.png"/>

<SiteInfo
  name="Realtime Prompting Guide | OpenAI Cookbook"
  desc="Today, we’re releasing gpt-realtime — our most capable speech-to-speech model yet in the API and announcing the general availability of t..."
  url="https://cookbook.openai.com/examples/realtime_prompting_guide/"
  logo="https://cookbook.openai.com/favicon.svg"
  preview="https://cookbook-pyicyehiq-openai.vercel.app/og?title=Realtime%20Prompting%20Guide&tags=audio,realtime,responses,speech"/>

:::

<!-- TODO: add ARTICLE CARD -->
```component VPCard
{
  "title": "더 빨라진 대화형 AI, ‘gpt-realtime’ 직접 써봤습니다",
  "desc": "지난 2025년 8월 28일, OpenAI는 음성 기반의 AI 에이전트에 사용할 수 있는 모델 ‘gpt-realtime’과 ‘Realtime API’의 최신 업데이트 버전을 공개했습니다. 이번 글에서는 gpt-realtime의 기술적 배경을 살펴보고, 직접 테스트한 경험을 바탕으로 기존 음성 인식 방식과 어떤 차이를 보이는지 분석해 보고자 합니다.",
  "link": "https://chanhi2000.github.io/bookshelf/yozm.wishket.com/3444.html",
  "logo": "https://yozm.wishket.com/favicon.ico",
  "background": "rgba(84,7,224,0.2)"
}
```
