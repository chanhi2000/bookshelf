---
lang: en-US
title: "Become an AI Researcher"
description: "Article(s) > Become an AI Researcher"
icon: fa-brands fa-python
category:
  - Python
  - NumPy
  - PyTorch
  - AI
  - LLM
  - Youtube
  - Article(s)
tag:
  - blog
  - freecodecamp.org
  - py
  - python
  - numpy
  - py-numpy
  - torch
  - pytorch
  - py-torch
  - ai
  - artificial-intelligence
  - llm
  - large-language-models
  - youtube
  - crashcourse
head:
  - - meta:
    - property: og:title
      content: "Article(s) > Become an AI Researcher"
    - property: og:description
      content: "Become an AI Researcher"
    - property: og:url
      content: https://chanhi2000.github.io/bookshelf/freecodecamp.org/become-an-ai-researcher.html
prev: /programming/py-numpy/articles/README.md
date: 2025-12-05
isOriginal: false
author:
  - name: Vuk Rosić (@vukrosic)
    url : https://youtube.com/@vukrosic
cover: https://cdn.hashnode.com/res/hashnode/image/upload/v1764879600871/035df186-2ce4-4c89-bf2d-0e52b2b44d8a.jpeg
---

# {{ $frontmatter.title }} 관련

```component VPCard
{
  "title": "NumPy > Article(s)",
  "desc": "Article(s)",
  "link": "/programming/py-numpy/articles/README.md",
  "logo": "/images/ico-wind.svg",
  "background": "rgba(10,10,10,0.2)"
}
```

```component VPCard
{
  "title": "PyTorch > Article(s)",
  "desc": "Article(s)",
  "link": "/programming/py-torch/articles/README.md",
  "logo": "/images/ico-wind.svg",
  "background": "rgba(10,10,10,0.2)"
}
```

```component VPCard
{
  "title": "LLM > Article(s)",
  "desc": "Article(s)",
  "link": "/ai/llm/articles/README.md",
  "logo": "/images/ico-wind.svg",
  "background": "rgba(10,10,10,0.2)"
}
```

[[toc]]

---

<SiteInfo
  name="Become an AI Researcher"
  desc="We just posted a course on the freeCodeCamp.org YouTube channel that will teach you how to become an AI Researcher. This course will guide you step-by-step, starting with the foundational mathematics essential for understanding modern AI, before divi..."
  url="https://freecodecamp.org/news/become-an-ai-researcher"
  logo="https://cdn.freecodecamp.org/universal/favicons/favicon.ico"
  preview="https://cdn.hashnode.com/res/hashnode/image/upload/v1764879600871/035df186-2ce4-4c89-bf2d-0e52b2b44d8a.jpeg"/>

We just posted a course on the freeCodeCamp.org YouTube channel that will teach you how to become an AI Researcher.

This course will guide you step-by-step, starting with the foundational mathematics essential for understanding modern AI, before diving into PyTorch fundamentals. You will then learn about the building blocks of AI, from simple neural networks to the complexities of multi-layer architectures. The course ends with an in-depth module on Transformers, the critical technology underpinning today's Large Language Models (LLMs) and generative AI.

Here are the sections in this course:

Introduction & Course Overview

- Welcome & Course Overview
- Requirements & Setup for the Course

**Module 1: Foundational Mathematics for AI Research**

- Math Lesson: Functions (Linear, Quadratic, Cubic, Square Root)
- Math Lesson: Derivatives (Rate of Change)
- Math Lesson: Vectors (Magnitude, Dot Product, Normalization)
- Math Lesson: Gradients (Steepest Ascent/Descent, Partial Derivatives)
- Math Lesson: Matrices (Multiplication, Transpose, Identity)
- Math Lesson: Probability (Expected Value, Conditional Probability)

**Module 2: PyTorch Fundamentals**

- START: PyTorch Fundamentals & Creating Tensors
- PyTorch Lesson: Reshaping and Viewing Tensors
- PyTorch Lesson: Squeezing and Unsqueezing Dimensions
- PyTorch Lesson: Indexing and Slicing Tensors
- PyTorch Lesson: Special Tensors (Zero, Ones, Linspace)

**Module 3: Neural Networks**

- START: Coding Neural Networks from Scratch
- Neural Networks Lesson: Single Neuron (Weights, Bias, Weighted Sum)
- Neural Networks Lesson: Activation Functions (Sigmoid, ReLU, tanh)
- Neural Networks Lesson: Multi-Layer Networks & Backpropagation

**Module 4: Transformers (for Large Language Models)**

- START: Understanding Transformers for LLMs
- Transformers Lesson: Attention Mechanism (Query, Key, Value)
- Transformers Lesson: Self-Attention & Causal Self-Attention
- Transformers Lesson: Rotary Positional Embeddings (RoPE)
- Transformers Lesson: Multi-Head Attention
- Transformers Lesson: Transformer Block (Feed-Forward, Add & Norm)
- Tokenization (for GPT Architecture)

**Conclusion**

- Conclusion & Next Steps

Watch the full course on [<VPIcon icon="fa-brands fa-youtube"/>the freeCodeCamp.org YouTube channel](https://youtu.be/wu8npoU37cI) (3-hour watch).

<VidStack src="youtube/wu8npoU37cI" />

<!-- TODO: add ARTICLE CARD -->
```component VPCard
{
  "title": "Become an AI Researcher",
  "desc": "We just posted a course on the freeCodeCamp.org YouTube channel that will teach you how to become an AI Researcher. This course will guide you step-by-step, starting with the foundational mathematics essential for understanding modern AI, before divi...",
  "link": "https://chanhi2000.github.io/bookshelf/freecodecamp.org/become-an-ai-researcher.html",
  "logo": "https://cdn.freecodecamp.org/universal/favicons/favicon.ico",
  "background": "rgba(10,10,35,0.2)"
}
```
