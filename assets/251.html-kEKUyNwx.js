import{_ as k}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as h,d as s,f as e,b as l,t as b,n as r,g as u,w as p,e as a,r as i,o as f}from"./app-BItykJLQ.js";const v="/bookshelf/assets/image/meetup.nhncloud.com/251/banner.png",y="/bookshelf/assets/image/meetup.nhncloud.com/251/1.png",w="/bookshelf/assets/image/meetup.nhncloud.com/251/2.png",S="/bookshelf/assets/image/meetup.nhncloud.com/251/3.png",x="/bookshelf/assets/image/meetup.nhncloud.com/251/4.png",C="/bookshelf/assets/image/meetup.nhncloud.com/251/5.png",I="/bookshelf/assets/image/meetup.nhncloud.com/251/6.png",T="/bookshelf/assets/image/meetup.nhncloud.com/251/7.png",_="/bookshelf/assets/image/meetup.nhncloud.com/251/8.png",E="/bookshelf/assets/image/meetup.nhncloud.com/251/9.png",B="/bookshelf/assets/image/meetup.nhncloud.com/251/10.png",L="/bookshelf/assets/image/meetup.nhncloud.com/251/11.png",D="/bookshelf/assets/image/meetup.nhncloud.com/251/12.png",P={},R={id:"frontmatter-title-관련",tabindex:"-1"},z={class:"header-anchor",href:"#frontmatter-title-관련"},j={class:"table-of-contents"},A={href:"https://youtu.be/mPg20ykAFU4",target:"_blank",rel:"noopener noreferrer"},V={href:"https://docs.aws.amazon.com/ko_kr/AmazonElastiCache/latest/mem-ug/Strategies.html",target:"_blank",rel:"noopener noreferrer"},N={href:"http://cseweb.ucsd.edu/~avattani/papers/cache_stampede.pdf",target:"_blank",rel:"noopener noreferrer"},K={href:"https://repl.it/@x0a1b/DebounceSimulator",target:"_blank",rel:"noopener noreferrer"},q={href:"https://engineering.linecorp.com/ko/blog/atomic-cache-stampede-redis-lua-script/#footnote-3",target:"_blank",rel:"noopener noreferrer"};function H(d,n){const c=i("VPCard"),t=i("router-link"),m=i("SiteInfo"),o=i("VPIcon"),g=i("VidStack");return f(),h("div",null,[s("h1",R,[s("a",z,[s("span",null,b(d.$frontmatter.title)+" 관련",1)])]),e(c,r(u({title:"JavaScript > Article(s)",desc:"Article(s)",link:"/programming/js/articles/README.md",logo:"https://chanhi2000.github.io/images/ico-wind.svg",background:"rgba(10,10,10,0.2)"})),null,16),s("nav",j,[s("ul",null,[s("li",null,[e(t,{to:"#improving-cache-speed-at-scale"},{default:p(()=>[...n[0]||(n[0]=[a("Improving Cache Speed at Scale",-1)])]),_:1}),s("ul",null,[s("li",null,[e(t,{to:"#cache-stampede"},{default:p(()=>[...n[1]||(n[1]=[a("Cache Stampede",-1)])]),_:1})]),s("li",null,[e(t,{to:"#per-probablistic-early-recomputation"},{default:p(()=>[...n[2]||(n[2]=[a("PER(Probablistic Early Recomputation)",-1)])]),_:1})]),s("li",null,[e(t,{to:"#debouncing"},{default:p(()=>[...n[3]||(n[3]=[a("Debouncing",-1)])]),_:1})])])]),s("li",null,[e(t,{to:"#typical-caching-setup"},{default:p(()=>[...n[4]||(n[4]=[a("Typical caching setup",-1)])]),_:1})]),s("li",null,[e(t,{to:"#hot-keys"},{default:p(()=>[...n[5]||(n[5]=[a("Hot Keys",-1)])]),_:1})]),s("li",null,[e(t,{to:"#compression"},{default:p(()=>[...n[6]||(n[6]=[a("Compression",-1)])]),_:1})]),s("li",null,[e(t,{to:"#cache-stampede는-실제로-어떤-영향을-끼칠까요"},{default:p(()=>[...n[7]||(n[7]=[a("Cache Stampede는 실제로 어떤 영향을 끼칠까요",-1)])]),_:1})]),s("li",null,[e(t,{to:"#출처"},{default:p(()=>[...n[8]||(n[8]=[a("출처",-1)])]),_:1})])])]),n[28]||(n[28]=s("hr",null,null,-1)),e(m,{name:"캐시 성능 향상기 (Improving Cache Speed at Scale) | NHN Cloud Meetup",desc:"캐시 성능 향상기 (Improving Cache Speed at Scale)",url:"https://meetup.nhncloud.com/posts/251",logo:"https://meetup.nhncloud.com/resources/img/favicon.ico",preview:"/assets/image/meetup.nhncloud.com/251/banner.png"}),n[29]||(n[29]=s("figure",null,[s("img",{src:v,alt:"",tabindex:"0",loading:"lazy"}),s("figcaption")],-1)),n[30]||(n[30]=s("h2",{id:"improving-cache-speed-at-scale",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#improving-cache-speed-at-scale"},[s("span",null,"Improving Cache Speed at Scale")])],-1)),s("p",null,[n[10]||(n[10]=a("안녕하세요! 데이터운영팀 김가림입니다.🙇🏻‍♀️ 올해 레디스 컨퍼런스는 코로나로 인해 온라인으로 진행되었습니다. 오늘은 그 중 제가 가장 흥미롭게 들었던 세션의 내용을 공유해보려고 합니다. 원 제목은 Improving Cache Speed at Scale 이며, 세션 영상은 ",-1)),s("a",A,[e(o,{icon:"fa-brands fa-youtube"}),n[9]||(n[9]=a("유튜브",-1))]),n[11]||(n[11]=a("에서 확인하실 수 있습니다.",-1))]),e(g,{src:"youtube/mPg20ykAFU4"}),n[31]||(n[31]=s("h3",{id:"cache-stampede",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#cache-stampede"},[s("span",null,"Cache Stampede")])],-1)),s("p",null,[n[13]||(n[13]=a("레디스를 캐시로 사용할 때 데이터의 갱신을 위해 대부분의 서비스에서는 키에 대해 ",-1)),n[14]||(n[14]=s("code",null,"Expire time(TTL)",-1)),n[15]||(n[15]=a("을 설정합니다. AWS는 ElastiCache의 캐싱 전략 ",-1)),s("a",V,[e(o,{icon:"fa-brands fa-aws"}),n[12]||(n[12]=a("문서",-1))]),n[16]||(n[16]=a("에서 데이터를 최신 상태로 유지함과 동시에 복잡성을 줄이기 위해 TTL을 추가할 것을 권장하고 있습니다.",-1))]),n[32]||(n[32]=l('<p>하지만 대규모 트래픽 환경에서 이 TTL값은 예상치 못한 문제를 발생시킬 수 있습니다.</p><figure><img src="'+y+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>이 구조에서 레디스는 캐시로, DB 앞단에서 분산된 서버들의 요청을 받고 있습니다. <strong>키가 만료되는 시점</strong>을 생각해볼까요? read-thorugh 구조에서 레디스에 데이터가 없을 때 서버들은 직접 DB에 가서 데이터를 읽어와 레디스에 저장합니다. 키가 만료되는 순간 많은 서버에서 이 키를 참조하는 시점이 겹치게 됩니다. 모든 서버들이 DB에 가서 데이터를 질의하는 <code>duplicate read</code>와 그 값을 반복적으로 레디스에 write하는 <code>duplicate write</code>가 발생하게 됩니다.</p><ul><li>초록색: 정상적인 응답</li><li>빨간색: 레디스 Key miss</li><li>파란색: 데이터베이스에 질의</li></ul><h3 id="per-probablistic-early-recomputation" tabindex="-1"><a class="header-anchor" href="#per-probablistic-early-recomputation"><span>PER(Probablistic Early Recomputation)</span></a></h3><figure><img src="'+w+`" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>이 현상을 해결하기 위해 <strong>PER(Probablistic Early Recomputation)</strong> 알고리즘을 도입할 수 있습니다. 이 알고리즘은 키의 TTL이 실제로 만료되기 전에 일정 확률로 캐시를 갱신하는 방법입니다. 데이터베이스에서 키가 완전히 만료되기 전에 데이터를 먼저 읽어오게 함으로써 Cache Stampede 현상을 막을 수 있습니다.</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code class="language-python"><span class="line"><span class="token keyword">def</span> <span class="token function">fetch_aot</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> expiry_gap_ms<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    ttl_ms <span class="token operator">=</span> redis<span class="token punctuation">.</span>pttl<span class="token punctuation">(</span>key<span class="token punctuation">)</span> <span class="token comment"># pttl은 millisecond 단위</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">if</span> ttl_ms <span class="token operator">-</span> <span class="token punctuation">(</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> expiry_gap_ms<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token keyword">return</span> redis<span class="token punctuation">.</span>get<span class="token punctuation">(</span>key<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">return</span> <span class="token boolean">None</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Usage</span></span>
<span class="line">fetch_aot<span class="token punctuation">(</span><span class="token string">&#39;foo&#39;</span><span class="token punctuation">,</span> <span class="token number">2000</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><figure><img src="`+S+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure>',9)),s("p",null,[n[18]||(n[18]=a("이 방식은 원래 VLDB라는 국제 학술대회에서 발표된 방법이며, 인터넷에 관련 ",-1)),s("a",N,[e(o,{icon:"fas fa-globe"}),n[17]||(n[17]=a("논문",-1))]),n[19]||(n[19]=a("이 공개되어 있습니다. 왜 이 확률분포가 사용되는지, beta값은 어떻게 정해야 하는지 등의 내용도 흥미로우니 관심있으신 분들은 논문을 읽어보시면 좋을 것 같습니다.",-1))]),n[33]||(n[33]=l(`<h3 id="debouncing" tabindex="-1"><a class="header-anchor" href="#debouncing"><span>Debouncing</span></a></h3><blockquote><p>We took inspiration from <strong>frontend world</strong> (debounce) and exploited promises(deferred)</p></blockquote><p>혹은, Cache Stampede 문제를 해결하기 위해서 <strong><em>프론트엔드-월드👑</em></strong> 에서 디바운싱이라는 아이디어를 채용해 올 수 있습니다.</p><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text"><pre><code class="language-text"><span class="line">❗ 디바운싱은 단위시간 내에서 호출되는 마지막 함수만 호출하는 방법입니다. </span>
<span class="line">인터벌이 100ms라면 100ms동안의 모든 이벤트는 무시되고, 마지막 이벤트만 동작하는 방법입니다. (출처: FE개발랩 한정)</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><figure><img src="`+x+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure>',5)),s("p",null,[n[21]||(n[21]=a("이 아이디어를 도입하면 어플리케이션에서 특정 키 miss가 발생해도 바로 DB에 질의하지 않습니다. 이 키 ID에 대해 debouncer를 생성해서, 첫번째 reader가 이 함수를 반환할 때까지 다른 reader들은 기다립니다. 이 디바운서의 코드는 아래와 같고, ",-1)),s("a",K,[e(o,{icon:"fas fa-globe"}),n[20]||(n[20]=a("시뮬레이터 링크",-1))]),n[22]||(n[22]=a("에서 어떤 식으로 동작하는지 확인하실 수 있습니다.",-1))]),n[34]||(n[34]=l(`<div class="language-javascript line-numbers-mode" data-highlighter="prismjs" data-ext="js"><pre><code class="language-javascript"><span class="line"><span class="token keyword">const</span> debouncer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Debouncer</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line"></span>
<span class="line"><span class="token keyword">async</span> <span class="token keyword">function</span> <span class="token function">menuItemLoader</span><span class="token punctuation">(</span><span class="token parameter">key</span><span class="token punctuation">)</span> <span class="token punctuation">{</span></span>
<span class="line">    <span class="token comment">//Read from Redis/DB</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span>
<span class="line"><span class="token keyword">const</span> menu <span class="token operator">=</span> <span class="token keyword">await</span> debouncer<span class="token punctuation">.</span><span class="token function">debounce</span><span class="token punctuation">(</span></span>
<span class="line">    <span class="token string">&#39;menu-\${id}&#39;</span><span class="token punctuation">,</span> menuItemLoader</span>
<span class="line"><span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line"></span>
<span class="line"><span class="token keyword">class</span> <span class="token class-name">Debouncer</span> <span class="token punctuation">{</span></span>
<span class="line">    <span class="token function">construnctor</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span></span>
<span class="line">        <span class="token keyword">this</span><span class="token punctuation">.</span>pendingBoard <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">;</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">async</span> <span class="token function">debounce</span><span class="token punctuation">(</span><span class="token parameter">id<span class="token punctuation">,</span> callback</span><span class="token punctuation">)</span> <span class="token punctuation">{</span></span>
<span class="line">        <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span><span class="token function">pendingBoard</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span> <span class="token operator">!==</span> <span class="token keyword">undefined</span><span class="token punctuation">)</span> <span class="token punctuation">{</span></span>
<span class="line">            <span class="token keyword">return</span> <span class="token keyword">await</span> <span class="token keyword">this</span><span class="token punctuation">.</span><span class="token function">pendingBorad</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line">        <span class="token punctuation">}</span></span>
<span class="line"></span>
<span class="line">        <span class="token keyword">this</span><span class="token punctuation">.</span><span class="token function">pendingBoard</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token function">callback</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line"></span>
<span class="line">        <span class="token keyword">try</span> <span class="token punctuation">{</span></span>
<span class="line">            <span class="token keyword">return</span> <span class="token keyword">await</span> <span class="token keyword">this</span><span class="token punctuation">.</span><span class="token function">pendingBoard</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line">        <span class="token punctuation">}</span> <span class="token keyword">finally</span> <span class="token punctuation">{</span></span>
<span class="line">            <span class="token keyword">delete</span> <span class="token keyword">this</span><span class="token punctuation">.</span><span class="token function">pendingBoard</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line">        <span class="token punctuation">}</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><figure><img src="`+C+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure>',2)),s("p",null,[n[24]||(n[24]=a("Cache Stampede 현상이 발생했을 때의 Key Miss 그래프는 위처럼 Spiky nature 합니다. (",-1)),n[25]||(n[25]=s("em",null,"👀뭔가가 expire 되어서 everybody rushes into read 했나봐!",-1)),n[26]||(n[26]=a(") 반면에 아래 그래프는 트래픽이 훨씬 감소했음을 알 수 있습니다. 쓸데없는 set을 줄이니 전체적인 round trip time이 감소됐고, latency도 줄어듭니다. 실제로 LINE에서 ",-1)),s("a",q,[e(o,{icon:"fas fa-globe"}),n[23]||(n[23]=a("성능테스트",-1))]),n[27]||(n[27]=a("를 했을 때, 이 알고리즘을 도입하면 약 세배 정도의 응답 시간 개선이 있었다고 합니다.",-1))]),n[35]||(n[35]=l('<hr><h2 id="typical-caching-setup" tabindex="-1"><a class="header-anchor" href="#typical-caching-setup"><span>Typical caching setup</span></a></h2><figure><img src="'+I+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>트래픽이 높은 서비스에서는 대부분 이런식으로 캐시를 구성하고 있습니다. L1은 어플리케이션 캐시(ex. Ehcache), L2는 레디스로 생각할 수 있겠죠? 위에서 말했던 레디스와 DB사이의 Stampede 이슈는 L1와 L2사이에서도 반복될 수 있습니다.</p><blockquote><p>Under high traffic load similar cache stampede/miss-storm can be observed between L1&amp;L2 cache (and so on)</p></blockquote><hr><h2 id="hot-keys" tabindex="-1"><a class="header-anchor" href="#hot-keys"><span>Hot Keys</span></a></h2><p>하나의 키에 대한 접근이 너무 많을 때에도 문제가 발생하며, 이 현상 또한 캐시 성능을 저하시킬 수 있습니다.</p><figure><img src="'+T+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>Hot Key 문제가 발생하면, 가장 쉽게 생각 할 수 있는 대안은 <strong>읽기 분산</strong>입니다. 하나의 마스터에 여러개의 슬레이브를 추가하고, 어플리케이션에서는 여러대의 서버에서 데이터를 읽어오는 방식입니다. 하지만 이런 구성에서 장애가 발생해서 페일오버가 발생하게 된다면 상황이 복잡해집니다. 생각지도 못한 장애와 병목이 발생할 가능성이 존재합니다.</p><figure><img src="'+_+`" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>이 세션에서는 <strong>키의 복제본</strong>을 만드는 방식을 제안하고 있습니다.</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code class="language-python"><span class="line"><span class="token keyword">def</span> <span class="token function">write_keys</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> copies<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token string">&quot;{{copy{}}}-{}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span>key<span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>copies<span class="token punctuation">)</span><span class="token punctuation">]</span></span>
<span class="line"></span>
<span class="line"><span class="token keyword">def</span> <span class="token function">read_key</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> copies<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    r <span class="token operator">=</span> randrange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> copies<span class="token punctuation">)</span></span>
<span class="line">    <span class="token keyword">return</span> <span class="token string">&quot;{{copy{}}}-{}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>r<span class="token punctuation">,</span> key<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>hot key를 저장할 때에는 앞에 prefix를 붙혀서 여러개의 키를 만들어냅니다. 키를 읽을 때에는 그 prefix를 사용해서 랜덤하게 접근하는 로직을 추가합니다.</p><hr><h2 id="compression" tabindex="-1"><a class="header-anchor" href="#compression"><span>Compression</span></a></h2><p>레디스에서 머신러닝 모델, HTTP 페이지 등을 다루거나, 메시지 큐 등으로 사용하며 크기카 큰 데이터를 저장할 때에 캐시 성능 저하가 발생할 수 있습니다. 이 때에는 압축을 고려할 수 있습니다. 압축을 할 때에는 다음 세 가지 사항을 고려해야 합니다.</p><p>첫 번째는 <strong>적절한 압축 비율(Compression Ratio)</strong> 입니다. 높은 압축률이 중요한 것이 아니라, 적절한 압축률을 찾아야 합니다. 왜냐하면 압축을 할 때의 <strong>CPU 성능</strong> 을 생각해야 하기 때문입니다. 안정성은 물론 필수입니다.</p><figure><img src="`+E+'" alt="여러 가지 압축 프로그램을 벤치마크 툴로 확인하여 적절한 프로그램을 찾는 과정 또한 필요합니다." tabindex="0" loading="lazy"><figcaption>여러 가지 압축 프로그램을 벤치마크 툴로 확인하여 적절한 프로그램을 찾는 과정 또한 필요합니다.</figcaption></figure><figure><img src="'+B+'" alt="평소 크기가 큰 데이터를 그대로 레디스에 저장했다면, 압축만 수행해도 아래처럼 두배 가까이 성능 향상을 발생시킬 수 있습니다." tabindex="0" loading="lazy"><figcaption>평소 크기가 큰 데이터를 그대로 레디스에 저장했다면, 압축만 수행해도 아래처럼 두배 가까이 성능 향상을 발생시킬 수 있습니다.</figcaption></figure><hr><h2 id="cache-stampede는-실제로-어떤-영향을-끼칠까요" tabindex="-1"><a class="header-anchor" href="#cache-stampede는-실제로-어떤-영향을-끼칠까요"><span>Cache Stampede는 실제로 어떤 영향을 끼칠까요</span></a></h2><p>글을 마치기 전 제가 담당하고 있는 한 서비스에서 Cache Stampede 현상이 발생한 사례를 공유드리고자 합니다. 이 서비스에서는 레디스에 데이터를 저장할 때 기본적으로 TTL값을 300초로 저장하고 있으며, 이는 일반적인 상황에서 아무런 문제가 되지 않고 있었습니다. 하지만 트래픽이 과도하게 몰리는 상황에서 캐시서버에 엄청난 부하가 발생했고 이를 분석하는 과정에서 아래 로그를 확인할 수 있었습니다.</p><figure><img src="'+L+'" alt="레디스에 키가 있는지  커맨드로 확인" tabindex="0" loading="lazy"><figcaption>레디스에 키가 있는지 <code>EXISTS</code> 커맨드로 확인</figcaption></figure><figure><img src="'+D+'" alt="없을 때 DB에 가서 데이터를 읽어온 뒤 레디스에 " tabindex="0" loading="lazy"><figcaption>없을 때 DB에 가서 데이터를 읽어온 뒤 레디스에 <code>SET</code></figcaption></figure><p>DB에서 데이터를 읽어온 뒤 레디스에 SET 하는 과정에서 엄청나게 오랜 시간이 소요됨을 볼 수 있고, 또한 이런 프로세스가 특정 시간대에 여러 개 발견되었습니다. 이는 분명히 레디스의 성능을 저하시킨다는 것을 예상할 수 있습니다.</p><hr><h2 id="출처" tabindex="-1"><a class="header-anchor" href="#출처"><span>출처</span></a></h2><ul><li><a href="https://www.slideshare.net/RedisLabs/redisconf17-internet-archive-preventing-cache-stampede-with-redis-and-xfetch" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/RedisLabs/redisconf17-internet-archive-preventing-cache-stampede-with-redis-and-xfetch</a></li></ul>',29)),e(c,r(u({title:"Atomic 처리와 cache stampede 대책을 위해 Redis Lua script를 활용한 이야기",desc:"안녕하세요? LINE에서 게임 플랫폼 개발을 맡고 있는 Kagaya입니다. 신입 사원 1년차였던 2016년에 마이크로 서비스용 프로젝트 생성 도구 Lazybones를 사용해 보니(일본어 글)를 포스팅한 데 이어 한번 더 기고하게 되었습니다. 반갑습니다.",link:"/engineering.linecorp.com/atomic-cache-stampede-redis-lua-script.md",logo:"https://engineering.linecorp.com/favicon-32x32.png?v=6d6085f233d02c34273fa8a8849b502a",background:"rgba(31,31,31,0.2)"})),null,16)])}const F=k(P,[["render",H]]),J=JSON.parse('{"path":"/meetup.nhncloud.com/251.html","title":"캐시 성능 향상기 (Improving Cache Speed at Scale)","lang":"ko-KR","frontmatter":{"lang":"ko-KR","title":"캐시 성능 향상기 (Improving Cache Speed at Scale)","description":"Article(s) > 캐시 성능 향상기 (Improving Cache Speed at Scale)","icon":"fa-brands fa-js","category":["JavaScript","Python","Article(s)"],"tag":["blog","meetup.nhncloud.com","py","python","js","javascript"],"head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"캐시 성능 향상기 (Improving Cache Speed at Scale)\\",\\"image\\":[\\"https://chanhi2000.github.io/bookshelf/assets/image/meetup.nhncloud.com/251/banner.png\\",\\"https://chanhi2000.github.io/bookshelf/assets/image/meetup.nhncloud.com/251/1.png\\",\\"https://chanhi2000.github.io/bookshelf/assets/image/meetup.nhncloud.com/251/2.png\\",\\"https://chanhi2000.github.io/bookshelf/assets/image/meetup.nhncloud.com/251/3.png\\",\\"https://chanhi2000.github.io/bookshelf/assets/image/meetup.nhncloud.com/251/4.png\\",\\"https://chanhi2000.github.io/bookshelf/assets/image/meetup.nhncloud.com/251/5.png\\",\\"https://chanhi2000.github.io/bookshelf/assets/image/meetup.nhncloud.com/251/6.png\\",\\"https://chanhi2000.github.io/bookshelf/assets/image/meetup.nhncloud.com/251/7.png\\",\\"https://chanhi2000.github.io/bookshelf/assets/image/meetup.nhncloud.com/251/8.png\\",\\"https://chanhi2000.github.io/bookshelf/assets/image/meetup.nhncloud.com/251/9.png\\",\\"https://chanhi2000.github.io/bookshelf/assets/image/meetup.nhncloud.com/251/10.png\\",\\"https://chanhi2000.github.io/bookshelf/assets/image/meetup.nhncloud.com/251/11.png\\",\\"https://chanhi2000.github.io/bookshelf/assets/image/meetup.nhncloud.com/251/12.png\\"],\\"datePublished\\":\\"2020-08-27T00:00:00.000Z\\",\\"dateModified\\":null,\\"author\\":[]}"],["meta",{"property":"og:url","content":"https://chanhi2000.github.io/bookshelf/meetup.nhncloud.com/251.html"}],["meta",{"property":"og:site_name","content":"📚Bookshelf"}],["meta",{"property":"og:title","content":"캐시 성능 향상기 (Improving Cache Speed at Scale)"}],["meta",{"property":"og:description","content":"Article(s) > 캐시 성능 향상기 (Improving Cache Speed at Scale)"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://chanhi2000.github.io/bookshelf/assets/image/meetup.nhncloud.com/251/banner.png"}],["meta",{"property":"og:locale","content":"ko-KR"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:image:src","content":"https://chanhi2000.github.io/bookshelf/assets/image/meetup.nhncloud.com/251/banner.png"}],["meta",{"name":"twitter:image:alt","content":"캐시 성능 향상기 (Improving Cache Speed at Scale)"}],["meta",{"property":"article:tag","content":"javascript"}],["meta",{"property":"article:tag","content":"js"}],["meta",{"property":"article:tag","content":"python"}],["meta",{"property":"article:tag","content":"py"}],["meta",{"property":"article:tag","content":"meetup.nhncloud.com"}],["meta",{"property":"article:tag","content":"blog"}],["meta",{"property":"article:published_time","content":"2020-08-27T00:00:00.000Z"}],[{"meta":null},{"property":"og:title","content":"Article(s) > 캐시 성능 향상기 (Improving Cache Speed at Scale)"},{"property":"og:description","content":"캐시 성능 향상기 (Improving Cache Speed at Scale)"},{"property":"og:url","content":"https://chanhi2000.github.io/bookshelf/meetup.nhncloud.com/251.html"}]],"prev":"/programming/js/articles/README.md","date":"2020-08-27T00:00:00.000Z","isOriginal":false,"cover":"/assets/image/meetup.nhncloud.com/251/banner.png"},"git":{},"readingTime":{"minutes":1.79,"words":538},"filePathRelative":"meetup.nhncloud.com/251.md"}');export{F as comp,J as data};
