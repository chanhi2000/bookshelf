import{_ as h}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as f,d as n,f as t,b as k,a as b,t as w,n as u,g as d,w as e,e as a,r as c,o as y}from"./app-BItykJLQ.js";const A={},x={id:"frontmatter-title-á„€á…ªá†«á„…á…§á†«",tabindex:"-1"},L={class:"header-anchor",href:"#frontmatter-title-á„€á…ªá†«á„…á…§á†«"},M={class:"table-of-contents"},I={href:"https://ollama.com/",target:"_blank",rel:"noopener noreferrer"},C={href:"https://github.com/microsoft/semantic-kernel",target:"_blank",rel:"noopener noreferrer"},T={href:"https://wandb.ai/vincenttu/blog_posts/reports/A-Survey-of-Large-Language-Models--VmlldzozOTY2MDM1",target:"_blank",rel:"noopener noreferrer"},E={href:"https://nuget.org/packages/Microsoft.Extensions.AI",target:"_blank",rel:"noopener noreferrer"},q={href:"https://datatracker.ietf.org/doc/html/rfc8259",target:"_blank",rel:"noopener noreferrer"};function O(m,s){const r=c("VPCard"),o=c("router-link"),g=c("SiteInfo"),i=c("VPIcon"),v=c("Tabs");return y(),f("div",null,[n("h1",x,[n("a",L,[n("span",null,w(m.$frontmatter.title)+" ê´€ë ¨",1)])]),t(r,u(d({title:"C# > Article(s)",desc:"Article(s)",link:"/programming/cs/articles/README.md",logo:"/images/ico-wind.svg",background:"rgba(10,10,10,0.2)"})),null,16),t(r,u(d({title:"Llama > Article(s)",desc:"Article(s)",link:"/ai/llama/articles/README.md",logo:"/images/ico-wind.svg",background:"rgba(10,10,10,0.2)"})),null,16),n("nav",M,[n("ul",null,[n("li",null,[t(o,{to:"#understanding-the-building-blocks"},{default:e(()=>[...s[0]||(s[0]=[a("Understanding the Building Blocks",-1)])]),_:1}),n("ul",null,[n("li",null,[t(o,{to:"#large-language-models-llms"},{default:e(()=>[...s[1]||(s[1]=[a("Large Language Models (LLMs)",-1)])]),_:1})]),n("li",null,[t(o,{to:"#ollama"},{default:e(()=>[...s[2]||(s[2]=[a("Ollama",-1)])]),_:1})]),n("li",null,[t(o,{to:"#microsoft-extensions-ai"},{default:e(()=>[...s[3]||(s[3]=[a("Microsoft.Extensions.AI",-1)])]),_:1})])])]),n("li",null,[t(o,{to:"#getting-started"},{default:e(()=>[...s[4]||(s[4]=[a("Getting Started",-1)])]),_:1})]),n("li",null,[t(o,{to:"#simple-chat-completion"},{default:e(()=>[...s[5]||(s[5]=[a("Simple Chat Completion",-1)])]),_:1})]),n("li",null,[t(o,{to:"#implementing-chat-with-history"},{default:e(()=>[...s[6]||(s[6]=[a("Implementing Chat with History",-1)])]),_:1})]),n("li",null,[t(o,{to:"#getting-practical-article-summarization"},{default:e(()=>[...s[7]||(s[7]=[a("Getting Practical: Article Summarization",-1)])]),_:1})]),n("li",null,[t(o,{to:"#taking-it-further-smart-categorization"},{default:e(()=>[...s[8]||(s[8]=[a("Taking It Further: Smart Categorization",-1)])]),_:1})]),n("li",null,[t(o,{to:"#flexibility-with-different-llm-providers"},{default:e(()=>[...s[9]||(s[9]=[a("Flexibility with Different LLM Providers",-1)])]),_:1})]),n("li",null,[t(o,{to:"#takeaway"},{default:e(()=>[...s[10]||(s[10]=[a("Takeaway",-1)])]),_:1})])])]),s[37]||(s[37]=n("hr",null,null,-1)),t(g,{name:"Working with LLMs in .NET using Microsoft.Extensions.AI",desc:"Microsoft.Extensions.AI provides a unified interface for integrating LLMs into .NET applications, allowing developers to switch between providers like Ollama, Azure, or OpenAI without changing application code. Through practical examples of chat completion, article summarization, and smart categorization, this article demonstrates how to leverage the library's features while running LLMs locally using Ollama.",url:"https://milanjovanovic.tech/blog/working-with-llms-in-dotnet-using-microsoft-extensions-ai",logo:"https://milanjovanovic.tech/profile_favicon.png",preview:"https://milanjovanovic.tech/blog-covers/mnw_124.png"}),s[38]||(s[38]=n("p",null,[a("I've been experimenting with different approaches to integrating LLMs into .NET apps, and I want to share what I've learned about using "),n("code",null,"Microsoft.Extensions.AI"),a(".")],-1)),n("p",null,[s[12]||(s[12]=a("Large Language Models (LLMs) have revolutionized how we approach AI-powered applications. While many developers are familiar with cloud-based solutions like OpenAI's GPT models, running LLMs locally has become increasingly accessible thanks to projects like ",-1)),n("a",I,[t(i,{icon:"fa-brands fa-meta"}),s[11]||(s[11]=a("Ollama",-1))]),s[13]||(s[13]=a(".",-1))]),n("p",null,[s[17]||(s[17]=a("In this article, we'll explore how to use LLMs in .NET applications using ",-1)),s[18]||(s[18]=n("code",null,"Microsoft.Extensions.AI",-1)),s[19]||(s[19]=a(", a powerful abstraction that extends the ",-1)),n("a",C,[s[14]||(s[14]=a("Semantic Kernel (",-1)),t(i,{icon:"iconfont icon-github"}),s[15]||(s[15]=n("code",null,"microsoft/semantic-kernel",-1)),s[16]||(s[16]=a(")",-1))]),s[20]||(s[20]=a(" SDK.",-1))]),s[39]||(s[39]=n("hr",null,null,-1)),s[40]||(s[40]=n("h2",{id:"understanding-the-building-blocks",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#understanding-the-building-blocks"},[n("span",null,"Understanding the Building Blocks")])],-1)),s[41]||(s[41]=n("h3",{id:"large-language-models-llms",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#large-language-models-llms"},[n("span",null,"Large Language Models (LLMs)")])],-1)),s[42]||(s[42]=n("p",null,"LLMs are deep learning models trained on vast amounts of data, capable of understanding and generating human-like text. These models can perform various tasks such as text completion, summarization, classification, and engaging in conversation. While traditionally accessed through cloud APIs, recent advances have made it possible to run them locally on standard hardware.",-1)),n("figure",null,[s[25]||(s[25]=n("img",{src:"https://milanjovanovic.tech/blogs/mnw_124/large_language_models.png?imwidth=3840",alt:'Timeline of large language models.<br/>Source: <VPIcon icon="fas fa-globe"/>Weights & Biases',tabindex:"0",loading:"lazy"},null,-1)),n("figcaption",null,[s[22]||(s[22]=a("Timeline of large language models.",-1)),s[23]||(s[23]=n("br",null,null,-1)),s[24]||(s[24]=a("Source: ",-1)),n("a",T,[t(i,{icon:"fas fa-globe"}),s[21]||(s[21]=a("Weights & Biases",-1))])])]),s[43]||(s[43]=n("h3",{id:"ollama",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#ollama"},[n("span",null,"Ollama")])],-1)),s[44]||(s[44]=n("p",null,"Ollama is an open-source project that simplifies running LLMs locally. It provides a Docker container that can run various open-source models like Llama, making it easy to experiment with AI without depending on cloud services. Ollama handles model management and optimization and provides a simple API for interactions.",-1)),s[45]||(s[45]=n("h3",{id:"microsoft-extensions-ai",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#microsoft-extensions-ai"},[n("span",null,"Microsoft.Extensions.AI")])],-1)),n("p",null,[n("a",E,[t(i,{icon:"fas fa-globe"}),s[26]||(s[26]=a("Microsoft.Extensions.AI",-1))]),s[27]||(s[27]=a(" is a library that provides a unified interface for working with LLMs in .NET applications. Built on top of Microsoft's Semantic Kernel, it abstracts away the complexity of different LLM implementations, allowing developers to switch between providers (like Ollama, Azure, or OpenAI) without changing application code.",-1))]),s[46]||(s[46]=n("hr",null,null,-1)),s[47]||(s[47]=n("h2",{id:"getting-started",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#getting-started"},[n("span",null,"Getting Started")])],-1)),s[48]||(s[48]=n("p",null,"Before diving into the examples, here's what you need to run LLMs locally:",-1)),t(v,{data:[{id:"1."},{id:"2."},{id:"3."}],active:0},{title0:e(({value:l,isActive:p})=>[...s[28]||(s[28]=[a("1.",-1)])]),title1:e(({value:l,isActive:p})=>[...s[29]||(s[29]=[a("2.",-1)])]),title2:e(({value:l,isActive:p})=>[...s[30]||(s[30]=[a("3.",-1)])]),tab0:e(({value:l,isActive:p})=>[...s[31]||(s[31]=[n("p",null,"Docker running on your machine",-1)])]),tab1:e(({value:l,isActive:p})=>[...s[32]||(s[32]=[n("p",null,[a("Ollama container running with the "),n("code",null,"llama3"),a(" model:")],-1),n("div",{class:"language-bash line-numbers-mode","data-highlighter":"prismjs","data-ext":"sh"},[n("pre",null,[n("code",{class:"language-bash"},[n("span",{class:"line"},[n("span",{class:"token comment"},"# Pull the Ollama container")]),a(`
`),n("span",{class:"line"},[n("span",{class:"token function"},"docker"),a(" run "),n("span",{class:"token parameter variable"},"--gpus"),a(" all "),n("span",{class:"token parameter variable"},"-d"),a(),n("span",{class:"token parameter variable"},"-v"),a(" ollama_data:/root/.ollama "),n("span",{class:"token punctuation"},"\\")]),a(`
`),n("span",{class:"line"},[n("span",{class:"token parameter variable"},"-p"),a(),n("span",{class:"token number"},"11434"),a(":11434 "),n("span",{class:"token punctuation"},"\\")]),a(`
`),n("span",{class:"line"},[n("span",{class:"token parameter variable"},"--name"),a(" ollama ollama/ollama")]),a(`
`),n("span",{class:"line"}),a(`
`),n("span",{class:"line"},[n("span",{class:"token comment"},"# Pull the llama3 model")]),a(`
`),n("span",{class:"line"},[n("span",{class:"token function"},"docker"),a(),n("span",{class:"token builtin class-name"},"exec"),a(),n("span",{class:"token parameter variable"},"-it"),a(" ollama ollama pull llama3")]),a(`
`),n("span",{class:"line"})])]),n("div",{class:"line-numbers","aria-hidden":"true",style:{"counter-reset":"line-number 0"}},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1)])]),tab2:e(({value:l,isActive:p})=>[...s[33]||(s[33]=[n("p",null,"A few NuGet packages (I built this using a .NET 9 console application):",-1),n("div",{class:"language-powershell line-numbers-mode","data-highlighter":"prismjs","data-ext":"powershell"},[n("pre",null,[n("code",{class:"language-powershell"},[n("span",{class:"line"},[n("span",{class:"token function"},"Install-Package"),a(" Microsoft"),n("span",{class:"token punctuation"},"."),a("Extensions"),n("span",{class:"token punctuation"},"."),a("AI "),n("span",{class:"token comment"},"# The base AI library")]),a(`
`),n("span",{class:"line"},[n("span",{class:"token function"},"Install-Package"),a(" Microsoft"),n("span",{class:"token punctuation"},"."),a("Extensions"),n("span",{class:"token punctuation"},"."),a("AI"),n("span",{class:"token punctuation"},"."),a("Ollama "),n("span",{class:"token comment"},"# Ollama provider implementation")]),a(`
`),n("span",{class:"line"},[n("span",{class:"token function"},"Install-Package"),a(" Microsoft"),n("span",{class:"token punctuation"},"."),a("Extensions"),n("span",{class:"token punctuation"},"."),a("Hosting "),n("span",{class:"token comment"},"# For building the DI container")]),a(`
`),n("span",{class:"line"})])]),n("div",{class:"line-numbers","aria-hidden":"true",style:{"counter-reset":"line-number 0"}},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1)])]),_:1}),s[49]||(s[49]=k(`<hr><h2 id="simple-chat-completion" tabindex="-1"><a class="header-anchor" href="#simple-chat-completion"><span>Simple Chat Completion</span></a></h2><p>Let&#39;s start with a basic example of chat completion. Here&#39;s the minimal setup:</p><div class="language-csharp line-numbers-mode" data-highlighter="prismjs" data-ext="cs"><pre><code class="language-csharp"><span class="line"><span class="token class-name"><span class="token keyword">var</span></span> builder <span class="token operator">=</span> Host<span class="token punctuation">.</span><span class="token function">CreateApplicationBuilder</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line"></span>
<span class="line">builder<span class="token punctuation">.</span>Services<span class="token punctuation">.</span><span class="token function">AddChatClient</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token constructor-invocation class-name">OllamaChatClient</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token constructor-invocation class-name">Uri</span><span class="token punctuation">(</span><span class="token string">&quot;http://localhost:11434&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&quot;llama3&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line"></span>
<span class="line"><span class="token class-name"><span class="token keyword">var</span></span> app <span class="token operator">=</span> builder<span class="token punctuation">.</span><span class="token function">Build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line"></span>
<span class="line"><span class="token class-name"><span class="token keyword">var</span></span> chatClient <span class="token operator">=</span> app<span class="token punctuation">.</span>Services<span class="token punctuation">.</span><span class="token generic-method"><span class="token function">GetRequiredService</span><span class="token generic class-name"><span class="token punctuation">&lt;</span>IChatClient<span class="token punctuation">&gt;</span></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line"></span>
<span class="line"><span class="token class-name"><span class="token keyword">var</span></span> chatCompletion <span class="token operator">=</span> <span class="token keyword">await</span> chatClient<span class="token punctuation">.</span><span class="token function">CompleteAsync</span><span class="token punctuation">(</span><span class="token string">&quot;What is .NET? Reply in 50 words max.&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line"></span>
<span class="line">Console<span class="token punctuation">.</span><span class="token function">WriteLine</span><span class="token punctuation">(</span>chatCompletion<span class="token punctuation">.</span>Message<span class="token punctuation">.</span>Text<span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Nothing fancy here - we&#39;re just setting up dependency injection and asking a simple question. If you&#39;re used to using raw API calls, you&#39;ll notice how clean this feels.</p><p>The <code>AddChatClient</code> extension method registers the chat client with the DI container. This allows you to inject <code>IChatClient</code> into your services and interact with LLMs using a simple API. The implementation uses the <code>OllamaChatClient</code> to communicate with the Ollama container running locally.</p><hr><h2 id="implementing-chat-with-history" tabindex="-1"><a class="header-anchor" href="#implementing-chat-with-history"><span>Implementing Chat with History</span></a></h2><p>Building on the previous example, we can create an interactive chat that maintains conversation history. This is useful for context-aware interactions and real-time chat applications. All we need is a <code>List&lt;ChatMessage</code> to store the chat history:</p><div class="language-csharp line-numbers-mode" data-highlighter="prismjs" data-ext="cs"><pre><code class="language-csharp"><span class="line"><span class="token class-name"><span class="token keyword">var</span></span> chatHistory <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token constructor-invocation class-name">List<span class="token punctuation">&lt;</span>ChatMessage<span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line"></span>
<span class="line"><span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token punctuation">{</span></span>
<span class="line">   Console<span class="token punctuation">.</span><span class="token function">WriteLine</span><span class="token punctuation">(</span><span class="token string">&quot;Enter your prompt:&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line">   <span class="token class-name"><span class="token keyword">var</span></span> userPrompt <span class="token operator">=</span> Console<span class="token punctuation">.</span><span class="token function">ReadLine</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line">   chatHistory<span class="token punctuation">.</span><span class="token function">Add</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token constructor-invocation class-name">ChatMessage</span><span class="token punctuation">(</span>ChatRole<span class="token punctuation">.</span>User<span class="token punctuation">,</span> userPrompt<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line"></span>
<span class="line">   Console<span class="token punctuation">.</span><span class="token function">WriteLine</span><span class="token punctuation">(</span><span class="token string">&quot;Response from AI:&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line">   <span class="token class-name"><span class="token keyword">var</span></span> chatResponse <span class="token operator">=</span> <span class="token string">&quot;&quot;</span><span class="token punctuation">;</span></span>
<span class="line">   <span class="token keyword">await</span> <span class="token keyword">foreach</span> <span class="token punctuation">(</span><span class="token class-name"><span class="token keyword">var</span></span> item <span class="token keyword">in</span> chatClient<span class="token punctuation">.</span><span class="token function">CompleteStreamingAsync</span><span class="token punctuation">(</span>chatHistory<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">   <span class="token punctuation">{</span></span>
<span class="line">       <span class="token comment">// We&#39;re streaming the response, so we get each message as it arrives</span></span>
<span class="line">       Console<span class="token punctuation">.</span><span class="token function">Write</span><span class="token punctuation">(</span>item<span class="token punctuation">.</span>Text<span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line">       chatResponse <span class="token operator">+=</span> item<span class="token punctuation">.</span>Text<span class="token punctuation">;</span></span>
<span class="line">   <span class="token punctuation">}</span></span>
<span class="line">   chatHistory<span class="token punctuation">.</span><span class="token function">Add</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token constructor-invocation class-name">ChatMessage</span><span class="token punctuation">(</span>ChatRole<span class="token punctuation">.</span>Assistant<span class="token punctuation">,</span> chatResponse<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line">   Console<span class="token punctuation">.</span><span class="token function">WriteLine</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>The cool part here is the streaming response - you get that nice, gradual text appearance like in ChatGPT. We&#39;re also maintaining chat history, which lets the model understand context from previous messages, making conversations feel more natural.</p><hr><h2 id="getting-practical-article-summarization" tabindex="-1"><a class="header-anchor" href="#getting-practical-article-summarization"><span>Getting Practical: Article Summarization</span></a></h2><p>Let&#39;s try something more useful - automatically summarizing articles. I&#39;ve been using this to process blog posts:</p><div class="language-csharp line-numbers-mode" data-highlighter="prismjs" data-ext="cs"><pre><code class="language-csharp"><span class="line"><span class="token class-name"><span class="token keyword">var</span></span> posts <span class="token operator">=</span> Directory<span class="token punctuation">.</span><span class="token function">GetFiles</span><span class="token punctuation">(</span><span class="token string">&quot;posts&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Take</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">ToArray</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line"><span class="token keyword">foreach</span> <span class="token punctuation">(</span><span class="token class-name"><span class="token keyword">var</span></span> post <span class="token keyword">in</span> posts<span class="token punctuation">)</span></span>
<span class="line"><span class="token punctuation">{</span></span>
<span class="line">   <span class="token class-name"><span class="token keyword">string</span></span> prompt <span class="token operator">=</span> $<span class="token interpolation-string"><span class="token string">$&quot;&quot;</span></span>&quot;</span>
<span class="line">         You will receive an input text <span class="token keyword">and</span> the desired output format<span class="token punctuation">.</span></span>
<span class="line">         You need to analyze the text <span class="token keyword">and</span> produce the desired output format<span class="token punctuation">.</span></span>
<span class="line">         You <span class="token keyword">not</span> allow to <span class="token class-name">change</span> code<span class="token punctuation">,</span> text<span class="token punctuation">,</span> <span class="token keyword">or</span> other references<span class="token punctuation">.</span></span>
<span class="line"></span>
<span class="line">         <span class="token preprocessor property"># Desired response</span></span>
<span class="line"></span>
<span class="line">         Only provide a RFC8259 compliant JSON response following <span class="token keyword">this</span> format without deviation<span class="token punctuation">.</span></span>
<span class="line"></span>
<span class="line">         <span class="token punctuation">{</span></span>
<span class="line">            <span class="token string">&quot;title&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;Title pulled from the front matter section&quot;</span><span class="token punctuation">,</span></span>
<span class="line">            <span class="token string">&quot;summary&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;Summarize the article in no more than 100 words&quot;</span></span>
<span class="line">         <span class="token punctuation">}</span></span>
<span class="line"></span>
<span class="line">         <span class="token preprocessor property"># Article content:</span></span>
<span class="line"></span>
<span class="line">         <span class="token punctuation">{</span><span class="token punctuation">{</span>File<span class="token punctuation">.</span><span class="token function">ReadAllText</span><span class="token punctuation">(</span>post<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">}</span></span>
<span class="line">         <span class="token string">&quot;&quot;</span>&quot;<span class="token punctuation">;</span></span>
<span class="line"></span>
<span class="line">   <span class="token class-name"><span class="token keyword">var</span></span> chatCompletion <span class="token operator">=</span> <span class="token keyword">await</span> chatClient<span class="token punctuation">.</span><span class="token function">CompleteAsync</span><span class="token punctuation">(</span>prompt<span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line">   Console<span class="token punctuation">.</span><span class="token function">WriteLine</span><span class="token punctuation">(</span>chatCompletion<span class="token punctuation">.</span>Message<span class="token punctuation">.</span>Text<span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line">   Console<span class="token punctuation">.</span><span class="token function">WriteLine</span><span class="token punctuation">(</span>Environment<span class="token punctuation">.</span>NewLine<span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,15)),n("p",null,[s[35]||(s[35]=a("Pro tip: Being specific about the output format (like requesting ",-1)),n("a",q,[t(i,{icon:"fas fa-globe"}),s[34]||(s[34]=a("RFC8259",-1))]),s[36]||(s[36]=a(" compliant JSON) helps get consistent results. I learned this the hard way after dealing with occasionally malformed responses!",-1))]),s[50]||(s[50]=k(`<hr><h2 id="taking-it-further-smart-categorization" tabindex="-1"><a class="header-anchor" href="#taking-it-further-smart-categorization"><span>Taking It Further: Smart Categorization</span></a></h2><p>Here&#39;s where it gets really interesting - we can get strongly typed responses directly from our LLM:</p><div class="language-csharp line-numbers-mode" data-highlighter="prismjs" data-ext="cs"><pre><code class="language-csharp"><span class="line"><span class="token keyword">class</span> <span class="token class-name">PostCategory</span></span>
<span class="line"><span class="token punctuation">{</span></span>
<span class="line">    <span class="token keyword">public</span> <span class="token return-type class-name"><span class="token keyword">string</span></span> Title <span class="token punctuation">{</span> <span class="token keyword">get</span><span class="token punctuation">;</span> <span class="token keyword">set</span><span class="token punctuation">;</span> <span class="token punctuation">}</span> <span class="token operator">=</span> <span class="token keyword">string</span><span class="token punctuation">.</span>Empty<span class="token punctuation">;</span></span>
<span class="line">    <span class="token keyword">public</span> <span class="token return-type class-name"><span class="token keyword">string</span><span class="token punctuation">[</span><span class="token punctuation">]</span></span> Tags <span class="token punctuation">{</span> <span class="token keyword">get</span><span class="token punctuation">;</span> <span class="token keyword">set</span><span class="token punctuation">;</span> <span class="token punctuation">}</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">;</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span>
<span class="line"><span class="token class-name"><span class="token keyword">var</span></span> posts <span class="token operator">=</span> Directory<span class="token punctuation">.</span><span class="token function">GetFiles</span><span class="token punctuation">(</span><span class="token string">&quot;posts&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Take</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">ToArray</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line"><span class="token keyword">foreach</span> <span class="token punctuation">(</span><span class="token class-name"><span class="token keyword">var</span></span> post <span class="token keyword">in</span> posts<span class="token punctuation">)</span></span>
<span class="line"><span class="token punctuation">{</span></span>
<span class="line">    <span class="token class-name"><span class="token keyword">string</span></span> prompt <span class="token operator">=</span> $<span class="token interpolation-string"><span class="token string">$&quot;&quot;</span></span>&quot;</span>
<span class="line">          You will receive an input text <span class="token keyword">and</span> the desired output format<span class="token punctuation">.</span></span>
<span class="line">          You need to analyze the text <span class="token keyword">and</span> produce the desired output format<span class="token punctuation">.</span></span>
<span class="line">          You <span class="token keyword">not</span> allow to <span class="token class-name">change</span> code<span class="token punctuation">,</span> text<span class="token punctuation">,</span> <span class="token keyword">or</span> other references<span class="token punctuation">.</span></span>
<span class="line"></span>
<span class="line">          <span class="token preprocessor property"># Desired response</span></span>
<span class="line"></span>
<span class="line">          Only provide a RFC8259 compliant JSON response following <span class="token keyword">this</span> format without deviation<span class="token punctuation">.</span></span>
<span class="line"></span>
<span class="line">          <span class="token punctuation">{</span></span>
<span class="line">             <span class="token string">&quot;title&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;Title pulled from the front matter section&quot;</span><span class="token punctuation">,</span></span>
<span class="line">             <span class="token string">&quot;tags&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;Array of tags based on analyzing the article content. Tags should be lowercase.&quot;</span></span>
<span class="line">          <span class="token punctuation">}</span></span>
<span class="line"></span>
<span class="line">          <span class="token preprocessor property"># Article content:</span></span>
<span class="line"></span>
<span class="line">          <span class="token punctuation">{</span><span class="token punctuation">{</span>File<span class="token punctuation">.</span><span class="token function">ReadAllText</span><span class="token punctuation">(</span>post<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">}</span></span>
<span class="line">          <span class="token string">&quot;&quot;</span>&quot;<span class="token punctuation">;</span></span>
<span class="line"></span>
<span class="line">    <span class="token class-name"><span class="token keyword">var</span></span> chatCompletion <span class="token operator">=</span> <span class="token keyword">await</span> chatClient<span class="token punctuation">.</span><span class="token generic-method"><span class="token function">CompleteAsync</span><span class="token generic class-name"><span class="token punctuation">&lt;</span>PostCategory<span class="token punctuation">&gt;</span></span></span><span class="token punctuation">(</span>prompt<span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line"></span>
<span class="line">    Console<span class="token punctuation">.</span><span class="token function">WriteLine</span><span class="token punctuation">(</span></span>
<span class="line">      <span class="token interpolation-string"><span class="token string">$&quot;</span><span class="token interpolation"><span class="token punctuation">{</span><span class="token expression language-csharp">chatCompletion<span class="token punctuation">.</span>Result<span class="token punctuation">.</span>Title</span><span class="token punctuation">}</span></span><span class="token string">. Tags: </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token expression language-csharp"><span class="token keyword">string</span><span class="token punctuation">.</span><span class="token function">Join</span><span class="token punctuation">(</span><span class="token string">&quot;,&quot;</span><span class="token punctuation">,</span>chatCompletion<span class="token punctuation">.</span>Result<span class="token punctuation">.</span>Tags<span class="token punctuation">)</span></span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>The strongly typed approach provides compile-time safety and better IDE support, making it easier to maintain and refactor code that interacts with LLM responses.</p><hr><h2 id="flexibility-with-different-llm-providers" tabindex="-1"><a class="header-anchor" href="#flexibility-with-different-llm-providers"><span>Flexibility with Different LLM Providers</span></a></h2><p>One of the key advantages of <code>Microsoft.Extensions.AI</code> is support for different providers. While our examples use Ollama, you can easily switch to other providers:</p><div class="language-csharp line-numbers-mode" data-highlighter="prismjs" data-ext="cs"><pre><code class="language-csharp"><span class="line"><span class="token comment">// Using Azure OpenAI</span></span>
<span class="line">builder<span class="token punctuation">.</span>Services<span class="token punctuation">.</span><span class="token function">AddChatClient</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token constructor-invocation class-name">AzureOpenAIClient</span><span class="token punctuation">(</span></span>
<span class="line">        <span class="token keyword">new</span> <span class="token constructor-invocation class-name">Uri</span><span class="token punctuation">(</span><span class="token string">&quot;AZURE_OPENAI_ENDPOINT&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token keyword">new</span> <span class="token constructor-invocation class-name">DefaultAzureCredential</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">            <span class="token punctuation">.</span><span class="token function">AsChatClient</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line"></span>
<span class="line"><span class="token comment">// Using OpenAI</span></span>
<span class="line">builder<span class="token punctuation">.</span>Services<span class="token punctuation">.</span><span class="token function">AddChatClient</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token constructor-invocation class-name">OpenAIClient</span><span class="token punctuation">(</span><span class="token string">&quot;OPENAI_API_KEY&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">AsChatClient</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container note"><p class="hint-container-title">This flexibility allows you to:</p><ul><li>Start development with local models</li><li>Move to production with cloud providers</li><li>Switch between providers without changing application code</li><li>Mix different providers for different use cases (categorization, image recognition, etc.)</li></ul></div><hr><h2 id="takeaway" tabindex="-1"><a class="header-anchor" href="#takeaway"><span>Takeaway</span></a></h2><p><code>Microsoft.Extensions.AI</code> makes it very simple to integrate LLMs into .NET applications. Whether you&#39;re building a chat interface, processing documents, or adding AI-powered features to your application, the library provides a clean, consistent API that works across different LLM providers.</p><p>I&#39;ve only scratched the surface here. Since integrating this into my projects, I&#39;ve found countless uses:</p><ul><li>Automated content moderation for user submissions</li><li>Automated support ticket categorization</li><li>Content summarization for newsletters</li></ul><p>I&#39;m also planning a small side project that will use LLMs to process images from a camera feed. The idea is to detect anything unusual and trigger alerts in real-time.</p><p>What are you planning to build with this? I&#39;d love to hear about your projects and experiences. The AI space is moving fast, but with tools like <code>Microsoft.Extensions.AI</code>, we can focus on building features rather than wrestling with infrastructure.</p><p>Good luck out there, and see you next week.</p><hr>`,19)),b(" TODO: add ARTICLE CARD "),t(r,u(d({title:"Working with LLMs in .NET using Microsoft.Extensions.AI",desc:"Microsoft.Extensions.AI provides a unified interface for integrating LLMs into .NET applications, allowing developers to switch between providers like Ollama, Azure, or OpenAI without changing application code. Through practical examples of chat completion, article summarization, and smart categorization, this article demonstrates how to leverage the library's features while running LLMs locally using Ollama.",link:"https://chanhi2000.github.io/bookshelf/milanjovanovic.tech/working-with-llms-in-dotnet-using-microsoft-extensions-ai.html",logo:"https://milanjovanovic.tech/profile_favicon.png",background:"rgba(79,70,229,0.2)"})),null,16)])}const S=h(A,[["render",O]]),P=JSON.parse('{"path":"/milanjovanovic.tech/working-with-llms-in-dotnet-using-microsoft-extensions-ai.html","title":"Working with LLMs in .NET using Microsoft.Extensions.AI","lang":"en-US","frontmatter":{"lang":"en-US","title":"Working with LLMs in .NET using Microsoft.Extensions.AI","description":"Article(s) > Working with LLMs in .NET using Microsoft.Extensions.AI","icon":"iconfont icon-csharp","category":["C#","DotNet","AI","LLM","Llama","Article(s)"],"tag":["blog","milanjovanovic.tech","cs","c#","csharp","dotnet","ai","artificial-intelligence","llm","large-language-models","meta","llama"],"head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Working with LLMs in .NET using Microsoft.Extensions.AI\\",\\"image\\":[\\"https://wandb.ai/vincenttu/blog_posts/reports/A-Survey-of-Large-Language-Models--VmlldzozOTY2MDM1\\"],\\"datePublished\\":\\"2025-01-11T00:00:00.000Z\\",\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Milan JovanoviÄ‡\\"}]}"],["meta",{"property":"og:url","content":"https://chanhi2000.github.io/bookshelf/milanjovanovic.tech/working-with-llms-in-dotnet-using-microsoft-extensions-ai.html"}],["meta",{"property":"og:site_name","content":"ðŸ“šBookshelf"}],["meta",{"property":"og:title","content":"Working with LLMs in .NET using Microsoft.Extensions.AI"}],["meta",{"property":"og:description","content":"Article(s) > Working with LLMs in .NET using Microsoft.Extensions.AI"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://milanjovanovic.tech/blog-covers/mnw_124.png"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:image:src","content":"https://milanjovanovic.tech/blog-covers/mnw_124.png"}],["meta",{"name":"twitter:image:alt","content":"Working with LLMs in .NET using Microsoft.Extensions.AI"}],["meta",{"property":"article:author","content":"Milan JovanoviÄ‡"}],["meta",{"property":"article:tag","content":"llama"}],["meta",{"property":"article:tag","content":"meta"}],["meta",{"property":"article:tag","content":"large-language-models"}],["meta",{"property":"article:tag","content":"llm"}],["meta",{"property":"article:tag","content":"artificial-intelligence"}],["meta",{"property":"article:tag","content":"ai"}],["meta",{"property":"article:tag","content":"dotnet"}],["meta",{"property":"article:tag","content":"csharp"}],["meta",{"property":"article:tag","content":"c#"}],["meta",{"property":"article:tag","content":"cs"}],["meta",{"property":"article:tag","content":"milanjovanovic.tech"}],["meta",{"property":"article:tag","content":"blog"}],["meta",{"property":"article:published_time","content":"2025-01-11T00:00:00.000Z"}],[{"meta":null},{"property":"og:title","content":"Article(s) > Working with LLMs in .NET using Microsoft.Extensions.AI"},{"property":"og:description","content":"Working with LLMs in .NET using Microsoft.Extensions.AI"},{"property":"og:url","content":"https://chanhi2000.github.io/bookshelf/milanjovanovic.tech/working-with-llms-in-dotnet-using-microsoft-extensions-ai.html"}]],"prev":"/programming/cs/articles/README.md","date":"2025-01-11T00:00:00.000Z","isOriginal":false,"author":"Milan JovanoviÄ‡","cover":"https://milanjovanovic.tech/blog-covers/mnw_124.png"},"git":{},"readingTime":{"minutes":5.16,"words":1547},"filePathRelative":"milanjovanovic.tech/working-with-llms-in-dotnet-using-microsoft-extensions-ai.md","copyright":{"author":"Milan JovanoviÄ‡"}}');export{S as comp,P as data};
